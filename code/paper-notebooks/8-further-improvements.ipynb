{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337221df",
   "metadata": {},
   "source": [
    "# Further improvements\n",
    "\n",
    "This notebook performs pilot studies into possible routes for further improving the classification results obtained from the offline experiments.\n",
    "This includes:\n",
    "   - Calibration on 5 minutes worth of data\n",
    "   - Subsampling electrodes\n",
    "\n",
    "Instructions on where to get the data are available on [the GitHub repository of the BCI master thesis project](https://www.github.com/pikawika/bci-master-thesis). These instructions are under `bci-master-thesis/code/data/CLA/README.md`. We will use the utility file `bci-master-thesis/code/utils/CLA_dataset.py` to work with this data. The data was stored as FIF files, which are included in [the GitHub repository of the BCI master thesis project](https://www.github.com/pikawika/bci-master-thesis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5341c6d",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- Checking requirements\n",
    "   - Correct Anaconda environment\n",
    "   - Correct module access\n",
    "   - Correct file access\n",
    "   - Checking TensorFlow support\n",
    "- Calibrating on 5 minutes of training\n",
    "   - EEGNet: new session\n",
    "   - EEGNet: new subject\n",
    "   - LSTM EEGNet\n",
    "      - Results\n",
    "- Subsampling electrodes\n",
    "   - CSP + LDA\n",
    "      - Same session\n",
    "      - New session\n",
    "      - New subject\n",
    "- Using more training data\n",
    "   - EEGNet: new subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292165d3",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Checking requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f55ad17",
   "metadata": {},
   "source": [
    "### Correct Anaconda environment\n",
    "\n",
    "The `bci-master-thesis` Anaconda environment should be active to ensure proper support. Installation instructions are available on [the GitHub repository of the BCI master thesis project](https://www.github.com/pikawika/bci-master-thesis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334d5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active environment: bci-master-thesis\n",
      "Correct environment: True\n",
      "\n",
      "Python version: 3.8.10\n",
      "Correct Python version: True\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CHECKING FOR RIGHT ANACONDA ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "import os\n",
    "from platform import python_version\n",
    "from pathlib import Path\n",
    "from copy import copy\n",
    "\n",
    "print(f\"Active environment: {os.environ['CONDA_DEFAULT_ENV']}\")\n",
    "print(f\"Correct environment: {os.environ['CONDA_DEFAULT_ENV'] == 'bci-master-thesis'}\")\n",
    "print(f\"\\nPython version: {python_version()}\")\n",
    "print(f\"Correct Python version: {python_version() == '3.8.10'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22166668",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Correct module access\n",
    "\n",
    "The following code block will load in all required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab632204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNE version (1.0.2 recommended): 1.0.2\n",
      "Numpy version (1.21.5 recommended): 1.21.5\n",
      "Pandas version (1.4.1 recommended): 1.4.1\n",
      "Scikit-learn version (1.0.2 recommended): 1.0.2\n",
      "TensorFlow version (2.8.0 recommended): 2.8.0\n",
      "Keras version (2.8.0 recommended): 2.8.0\n",
      "Pickle version (4.0 recommended): 4.0\n",
      "Matplotlib version (3.5.1 recommended): 3.5.1\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# LOADING MODULES\n",
    "####################################################\n",
    "\n",
    "# allow reloading of libraries\n",
    "import importlib\n",
    "\n",
    "# Load util function file\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "import CLA_dataset\n",
    "import TF_tools\n",
    "importlib.reload(CLA_dataset)\n",
    "importlib.reload(TF_tools)\n",
    "\n",
    "# IO functions\n",
    "from IPython.utils import io\n",
    "\n",
    "# Set logging level for MNE before loading MNE\n",
    "os.environ['MNE_LOGGING_LEVEL'] = 'WARNING'\n",
    "\n",
    "# Modules tailored for EEG data\n",
    "import mne; print(f\"MNE version (1.0.2 recommended): {mne.__version__}\")\n",
    "from mne.decoding import CSP\n",
    "\n",
    "# EEGNet model\n",
    "import EEGModels\n",
    "from EEGModels import EEGNet\n",
    "\n",
    "# EEGNet model with LSTM\n",
    "import EEGNet_with_lstm\n",
    "from EEGNet_with_lstm import EEGNet_bidirectional_lstm, EEGNet_lstm_1Dconv\n",
    "\n",
    "# Data manipulation modules\n",
    "import numpy as np; print(f\"Numpy version (1.21.5 recommended): {np.__version__}\")\n",
    "import pandas as pd; print(f\"Pandas version (1.4.1 recommended): {pd.__version__}\")\n",
    "import copy\n",
    "\n",
    "# ML libraries\n",
    "import sklearn;  print(f\"Scikit-learn version (1.0.2 recommended): {sklearn.__version__}\")\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Deep Learning libraries\n",
    "import tensorflow as tf;  print(f\"TensorFlow version (2.8.0 recommended): {tf.__version__}\")\n",
    "\n",
    "import keras; print(f\"Keras version (2.8.0 recommended): {keras.__version__}\")\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "# Storing files\n",
    "import pickle;  print(f\"Pickle version (4.0 recommended): {pickle.format_version}\")\n",
    "\n",
    "# Plotting\n",
    "import matplotlib; print(f\"Matplotlib version (3.5.1 recommended): {matplotlib.__version__}\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813bb5de",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Correct file access\n",
    "\n",
    "As mentioned, this notebook uses a database provided by [Kaya et al](https://doi.org/10.1038/sdata.2018.211). The CLA dataset in particular. Instructions on where to get the data are available on [the GitHub repository of the BCI master thesis project](https://www.github.com/pikawika/bci-master-thesis). These instructions are under `bci-master-thesis/code/data/CLA/README.md`. The following code block checks if all required files are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caa1d182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Matlab CLA file access: True\n",
      "Full MNE CLA file access: True\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CHECKING FILE ACCESS\n",
    "####################################################\n",
    "\n",
    "# Use util to determine if we have access\n",
    "print(\"Full Matlab CLA file access: \" + str(CLA_dataset.check_matlab_files_availability()))\n",
    "print(\"Full MNE CLA file access: \" + str(CLA_dataset.check_mne_files_availability()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a71dde",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Checking TensorFlow support\n",
    "\n",
    "If you want to use TensorFlow with GPU acceleration, the below codeblock can help you gather insight.\n",
    "\n",
    "To launch the tensorboard use the following command in the `paper-notebooks` folder, be sure to have the right environments active:\n",
    "- Windows: `tensorboard --logdir=./logs/`\n",
    "- MacOS: `tensorboard --logdir='./logs/'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8d50f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 CPUs available under the names:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "\n",
      "\n",
      "There are 1 GPUs available under the names:\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "TF_tools.check_tf_cpu_gpu_presence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdad109",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Calibrating on 5 minutes of training\n",
    "\n",
    "In the data collection setup the marker stayed on the screen for one singular second and was followed by a 1.5 â€“ 2.5 second pause after which the next signal was shown.\n",
    "This totals 3.5 seconds per sample taken.\n",
    "As such, in 5 minutes, or 300 seconds, 85 samples should be obtainable.\n",
    "This is reduced to 75 samples in order to obtain 25 samples per class.\n",
    "These 25 samples per class are then used for calibration of both the EEGNet model and the EEGNet model extension with LSTM provided by us to compare both.\n",
    "Different layers are frozen to test different setups.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### EEGNet: new session\n",
    "\n",
    "Results for EEGNet base were:\n",
    "\n",
    "| **Subject** | **EEGNet: best validation accuracy** | **EEGNet: best validation loss** | **EEGNet: test split accuracy (best acc model)** | **EEGNet: test split accuracy (best loss model)** |\n",
    "|-------------|--------------------------------------|----------------------------------|--------------------------------------------------|---------------------------------------------------|\n",
    "| B           | 0.6927 @ epoch 1473                  | 0.761 @ epoch 1472               | 0.65                                             | 0.6573                                            |\n",
    "| C           | 0.8837 @ epoch 1159                  | 0.3827 @ epoch 584               | 0.7132                                           | 0.6986                                            |\n",
    "| E           | 0.7674 @ epoch 782                   | 0.5884 @ epoch 1028              | 0.7068                                           | 0.7246                                            |\n",
    "\n",
    "Result after calibration are:\n",
    "\n",
    "| **Subject** | **EEGNet: best validation accuracy** | **EEGNet: best validation loss** | **EEGNet: test split accuracy (best acc model)** | **EEGNet: test split accuracy (best loss model)** |\n",
    "|-------------|--------------------------------------|----------------------------------|--------------------------------------------------|---------------------------------------------------|\n",
    "| B           | 0.6667 @ epoch 459                   | 0.8669 @ epoch 1846              | 0.6429                                           | 0.6181                                            |\n",
    "| C           | 0.8 @ epoch 39                       | 0.798 @ epoch 2486               | 0.7104                                           | 0.7387                                            |\n",
    "| E           | 0.7667 @ epoch 56                    | 0.597 @ epoch 2500               | 0.7568                                           | 0.758                                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf624836",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEGNet(\n",
    "    nb_classes = 3, # int, number of classes to classify. \n",
    "    Chans = 21, # number of channels in the EEG data. \n",
    "    Samples = 100, # number of time points in the EEG data. (default: 128)\n",
    "    dropoutRate = 0.5, # dropout fraction. (default: 0.5)\n",
    "    kernLength = 50, # length of temporal convolution in first layer. Suggested: half the sampling rate. (default: 64)\n",
    "    F1 = 8, # number of temporal filters. (default: 8)\n",
    "    F2 = 16, # number of pointwise filters. (default: 16)\n",
    "    D = 2, # number of spatial filters to learn within each temporal convolution. (default: 2)\n",
    "    norm_rate = 0.25, # Normalisation rate. (default: 0.25)\n",
    "    dropoutType = 'SpatialDropout2D' # Either SpatialDropout2D or Dropout, passed as a string. (default: Dropout)\n",
    ").layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# CALIBRATE EEGNET ON NEW SESSION\n",
    "####################################################\n",
    "\n",
    "# Configure global parameters for all experiments\n",
    "subject_ids_to_test = [\"B\", \"C\", \"E\"] # Subjects with three recordings\n",
    "start_offset = -1 # One second before visual queue\n",
    "end_offset = 1 # One second after visual queue\n",
    "baseline = None # Baseline correction using data before the visual queue\n",
    "do_experiment = False\n",
    "\n",
    "keras_eegnet_model = EEGNet(\n",
    "        nb_classes = 3, # int, number of classes to classify. \n",
    "        Chans = 21, # number of channels in the EEG data. \n",
    "        Samples = 100, # number of time points in the EEG data. (default: 128)\n",
    "        dropoutRate = 0.5, # dropout fraction. (default: 0.5)\n",
    "        kernLength = 50, # length of temporal convolution in first layer. Suggested: half the sampling rate. (default: 64)\n",
    "        F1 = 8, # number of temporal filters. (default: 8)\n",
    "        F2 = 16, # number of pointwise filters. (default: 16)\n",
    "        D = 2, # number of spatial filters to learn within each temporal convolution. (default: 2)\n",
    "        norm_rate = 0.25, # Normalisation rate. (default: 0.25)\n",
    "        dropoutType = 'SpatialDropout2D' # Either SpatialDropout2D or Dropout, passed as a string. (default: Dropout)\n",
    "        )\n",
    "\n",
    "if do_experiment:\n",
    "        # Loop over all found results\n",
    "        for subject_id in subject_ids_to_test:\n",
    "                print()\n",
    "                print(\"####################################################\")\n",
    "                print(f\"# RESULTS FOR SUBJECT {subject_id}\")\n",
    "                print(\"####################################################\")\n",
    "                print()\n",
    "                \n",
    "                ################### LOAD DATA ###################\n",
    "                # Names for model\n",
    "                pretrained_model_name = f\"saved_variables/4/samesubject_differentsession/subject{subject_id}/trained_model\"\n",
    "                \n",
    "                tensorboard_name = f\"paper-notebook8_eegnet_calibration_newsession_subject{subject_id}\"\n",
    "                best_base_model_filename =  f\"saved_variables/8/calibration/EEGNet/samesubject_differentsession/subject{subject_id}/trained_model\"\n",
    "                \n",
    "                # Open lowest loss model from file, lowest loss is chosen as it likely needs \"least calibration\"\n",
    "                pretrained_model = TF_tools.load_lowest_loss_model(filepath= pretrained_model_name)\n",
    "                \n",
    "                # Get train and test split\n",
    "                with io.capture_output():\n",
    "                        # Get new session data\n",
    "                        mne_raw = CLA_dataset.get_last_raw_mne_data_for_subject(subject_id)\n",
    "                        \n",
    "                        # Get epochs for new session\n",
    "                        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                                             start_offset= start_offset,\n",
    "                                                                             end_offset= end_offset,\n",
    "                                                                             baseline= baseline)\n",
    "                        \n",
    "                        # Only keep epochs from the MI tasks\n",
    "                        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "                        \n",
    "                        # Fix the indexing\n",
    "                        # NOTE: this is some weird MNE behaviour, the index retreived is not the actual index if not reset due to filtering done\n",
    "                        mne_epochs.reset_drop_log_selection()\n",
    "                        \n",
    "                        # Load epochs into memory\n",
    "                        mne_epochs.load_data()\n",
    "                        \n",
    "                        # Get calibration test split\n",
    "                        calibration_items, test_items = CLA_dataset.get_calibration_test_split_from_epochs(epochs= mne_epochs,\n",
    "                                                                                                           amount_of_samples_in_calibration_per_class = 25)\n",
    "                        \n",
    "                        \n",
    "                # Get OHE from file\n",
    "                with open(f\"saved_variables/4/samesubject_differentsession/subject{subject_id}/ohe-encoder.pickle\", 'rb') as f:\n",
    "                        ohe = pickle.load(f)\n",
    "                        \n",
    "                        \n",
    "                calibration_epochs = mne_epochs[calibration_items]\n",
    "                test_epochs = mne_epochs[test_items]\n",
    "\n",
    "                # Get labels\n",
    "                y_train = calibration_epochs.events[:, -1]\n",
    "                y_test = test_epochs.events[:, -1]\n",
    "\n",
    "                # Get train and test data\n",
    "                X_train = calibration_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "                X_test = test_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "\n",
    "                # Fix scaling sensitivity as MNE stores as data * 10e-6\n",
    "                X_train = X_train * 1000000\n",
    "                X_test = X_test * 1000000\n",
    "                \n",
    "                # Further devide the calibration split in train and eval samples\n",
    "                X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                                  y_train,\n",
    "                                                                  test_size = 0.4, # Use 5 samples per class for validation\n",
    "                                                                  shuffle= True,\n",
    "                                                                  stratify= y_train,                                                    \n",
    "                                                                  random_state= 1998)\n",
    "                \n",
    "                # Convert labels with OHE for Keras\n",
    "                y_train = ohe.transform(y_train.reshape(-1, 1)).toarray()\n",
    "                y_test = ohe.transform(y_test.reshape(-1, 1)).toarray()\n",
    "                y_val = ohe.transform(y_val.reshape(-1, 1)).toarray()\n",
    "                \n",
    "                # Print stats\n",
    "                print(f\"Calibrating with {np.shape(X_train)} windows\")\n",
    "                print(f\"Testing with {np.shape(X_test)} windows\")\n",
    "                \n",
    "                print(\"Calibrating epochs\")\n",
    "                display(calibration_epochs)\n",
    "                \n",
    "                print(\"test epochs\")\n",
    "                display(test_epochs)\n",
    "                        \n",
    "                ################### CALIBRATE MODEL ###################\n",
    "                # Make a calibration model\n",
    "                calibration_model = keras.models.clone_model(keras_eegnet_model)\n",
    "\n",
    "                \n",
    "                # Copy weights from pretrained model\n",
    "                calibration_model.set_weights(pretrained_model.get_weights())\n",
    "                \n",
    "                for layer in calibration_model.layers:\n",
    "                        layer.trainable = False\n",
    "                \n",
    "                # Allow last conv layer to learn\n",
    "                #calibration_model.layers[8].trainable = True # Overfits\n",
    "                \n",
    "                # Allow last layers to train (softmax)\n",
    "                calibration_model.layers[14].trainable = True\n",
    "                calibration_model.layers[15].trainable = True\n",
    "                \n",
    "                # Allow batch norm to train due to weird behaviour\n",
    "                calibration_model.layers[2].trainable = True\n",
    "                calibration_model.layers[4].trainable = True\n",
    "                calibration_model.layers[9].trainable = True\n",
    "                \n",
    "                \n",
    "                # Change dropout\n",
    "                calibration_model.layers[7].rate = 0\n",
    "                calibration_model.layers[12].rate = 0.2\n",
    "                \n",
    "                # Compile the model so it can be fitted, note a lower learning rate is set\n",
    "                calibration_model.compile(loss = 'categorical_crossentropy', optimizer = tf.optimizers.Adam(learning_rate= 0.0001), metrics=[\"accuracy\"])\n",
    "                \n",
    "                # Train model with GPU as means of recalibrating\n",
    "                # NOTE: change GPU to CPU if no GPU present\n",
    "                with tf.device('/gpu:0'):\n",
    "                        history = calibration_model.fit(\n",
    "                                x= X_train,\n",
    "                                y= y_train,\n",
    "                                batch_size= 128, # All calibration data at once\n",
    "                                epochs= 2500, # Very small due to direct overfit expected\n",
    "                                verbose= 1, # 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                                callbacks= [TF_tools.tensorboard_callback(log_name= tensorboard_name),\n",
    "                                        TF_tools.lowest_loss_model_save_callback(filepath= best_base_model_filename),\n",
    "                                        TF_tools.highest_accuracy_model_save_callback(filepath= best_base_model_filename)],\n",
    "                                validation_data= (X_val, y_val),\n",
    "                                shuffle= True,\n",
    "                                use_multiprocessing= True, # Done for faster speed\n",
    "                                workers= 4 # Done for faster speed\n",
    "                                )\n",
    "                        \n",
    "                # Store the fitting history\n",
    "                with open(f\"saved_variables/8/calibration/EEGNet/samesubject_differentsession/subject{subject_id}/fitting_history.pickle\", 'wb') as file:\n",
    "                        pickle.dump(history.history, file)\n",
    "                        \n",
    "                # Store the test data\n",
    "                with open(f\"saved_variables/8/calibration/EEGNet/samesubject_differentsession/subject{subject_id}/X_test.pickle\", 'wb') as file:\n",
    "                        pickle.dump(X_test, file)\n",
    "                        \n",
    "                with open(f\"saved_variables/8/calibration/EEGNet/samesubject_differentsession/subject{subject_id}/y_test.pickle\", 'wb') as file:\n",
    "                        pickle.dump(y_test, file)\n",
    "        \n",
    "                # remove unused vars\n",
    "                del mne_raw\n",
    "                del mne_epochs\n",
    "                del pretrained_model_name\n",
    "                del pretrained_model\n",
    "                del f\n",
    "                del X_test\n",
    "                del y_test\n",
    "                del ohe\n",
    "                del calibration_epochs\n",
    "                del calibration_items\n",
    "                del test_epochs\n",
    "                del test_items\n",
    "                del X_train\n",
    "                del y_train\n",
    "                del X_val\n",
    "                del y_val\n",
    "                del tensorboard_name\n",
    "                del history\n",
    "                del best_base_model_filename\n",
    "                del calibration_model\n",
    "                del file\n",
    "                del layer\n",
    "        \n",
    "        del subject_id\n",
    "        \n",
    "# Remove unsused variables\n",
    "del subject_ids_to_test\n",
    "del baseline\n",
    "del end_offset\n",
    "del start_offset\n",
    "del keras_eegnet_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efb0936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# RESULTS\n",
    "####################################################\n",
    "\n",
    "# Configure global parameters for all experiments\n",
    "subject_ids_to_test = [\"B\", \"C\", \"E\"] # Subjects with three recordings\n",
    "start_offset = -1 # One second before visual queue\n",
    "end_offset = 1 # One second after visual queue\n",
    "baseline = None # Baseline correction using data before the visual queue\n",
    "\n",
    "# Loop over all found results\n",
    "for subject_id in subject_ids_to_test:\n",
    "    print()\n",
    "    print(\"####################################################\")\n",
    "    print(f\"# RESULTS FOR SUBJECT {subject_id}\")\n",
    "    print(\"####################################################\")\n",
    "    print()\n",
    "    \n",
    "    ################### load data ###################\n",
    "    # Names for model\n",
    "    best_base_model_filename = f\"saved_variables/8/calibration/EEGNet/samesubject_differentsession/subject{subject_id}/trained_model\"\n",
    "    \n",
    "    # Open models from file\n",
    "    lowest_loss_model = TF_tools.load_lowest_loss_model(filepath= best_base_model_filename)\n",
    "    highest_accuracy_model = TF_tools.load_highest_accuracy_model(filepath= best_base_model_filename)\n",
    "    \n",
    "    # Get test data session\n",
    "    with io.capture_output():\n",
    "        # Get test data\n",
    "        mne_raw = CLA_dataset.get_last_raw_mne_data_for_subject(subject_id)\n",
    "        \n",
    "        # Get epochs for test MNE raw\n",
    "        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                             start_offset= start_offset,\n",
    "                                                             end_offset= end_offset,\n",
    "                                                             baseline= baseline)\n",
    "        \n",
    "        # Only keep epochs from the MI tasks\n",
    "        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "\n",
    "        # Load epochs into memory\n",
    "        mne_epochs.load_data()\n",
    "        \n",
    "        # Get the test labels\n",
    "        with open(f\"saved_variables/8/calibration/EEGNet/samesubject_differentsession/subject{subject_id}/y_test.pickle\", 'rb') as f:\n",
    "            y_test = pickle.load(f)\n",
    "            \n",
    "        # Get the test data\n",
    "        with open(f\"saved_variables/8/calibration/EEGNet/samesubject_differentsession/subject{subject_id}/X_test.pickle\", 'rb') as f:\n",
    "            X_test = pickle.load(f)\n",
    "        \n",
    "        # Delete resedual vars for training data\n",
    "        del mne_raw\n",
    "        del mne_epochs\n",
    "        \n",
    "    # Get OHE from file\n",
    "    with open(f\"saved_variables/4/samesubject_differentsession/subject{subject_id}/ohe-encoder.pickle\", 'rb') as f:\n",
    "        ohe = pickle.load(f)\n",
    "        \n",
    "    # Get history from file\n",
    "    with open(f\"saved_variables/8/calibration/EEGNet/samesubject_differentsession/subject{subject_id}/fitting_history.pickle\", 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "        \n",
    "    # Inverse y_test to label\n",
    "    y_test = ohe.inverse_transform(y_test)\n",
    "    \n",
    "    ################### history stats ###################\n",
    "    print(\"#### results of training ####\")\n",
    "    print(f\"Best training accuracy (max) {np.round(np.max(history['accuracy']), 4)} @ epoch {np.argmax(history['accuracy']) + 1}\")\n",
    "    print(f\"Best training loss (min) {np.round(np.min(history['loss']), 4)} @ epoch {np.argmin(history['loss']) + 1}\")\n",
    "    print()\n",
    "    print(f\"Best validation accuracy (max) {np.round(np.max(history['val_accuracy']), 4)} @ epoch {np.argmax(history['val_accuracy']) + 1}\")\n",
    "    print(f\"Best validation loss (min) {np.round(np.min(history['val_loss']), 4)} @ epoch {np.argmin(history['val_loss']) + 1}\")\n",
    "    \n",
    "    ################### highest accuracy model ###################\n",
    "    print(\"\\n#### results for highest accuracy model ####\")\n",
    "    # Get predictions from lowest loss model and convert back to labels\n",
    "    y_pred = highest_accuracy_model.predict(X_test)\n",
    "    y_pred = ohe.inverse_transform(y_pred)\n",
    "    \n",
    "    # Get accuracy score and print it\n",
    "    accuracy =  accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy of: {np.round(accuracy, 4)}\")\n",
    "    \n",
    "    # Show CM\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    ################### lowest loss model ###################\n",
    "    print(\"\\n#### results for lowest loss model ####\")\n",
    "    # Get predictions from lowest loss model and convert back to labels\n",
    "    y_pred = lowest_loss_model.predict(X_test)\n",
    "    y_pred = ohe.inverse_transform(y_pred)\n",
    "    \n",
    "    # Get accuracy score and print it\n",
    "    accuracy =  accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy of: {np.round(accuracy, 4)}\")\n",
    "    \n",
    "    # Show CM\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    ################### cleanup ###################\n",
    "    # remove unused vars\n",
    "    del best_base_model_filename\n",
    "    del lowest_loss_model\n",
    "    del highest_accuracy_model\n",
    "    del f\n",
    "    del X_test\n",
    "    del y_test\n",
    "    del history\n",
    "    del ohe\n",
    "    del y_pred\n",
    "    del accuracy\n",
    "\n",
    "# Remove unsused variables\n",
    "del subject_ids_to_test\n",
    "del subject_id\n",
    "del baseline\n",
    "del end_offset\n",
    "del start_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6102d0",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### EEGNet: new subject\n",
    "\n",
    "Results for EEGNet base were:\n",
    "\n",
    "| **Subject**   | **EEGNet: best validation accuracy** | **EEGNet: best validation loss** | **EEGNet: test split accuracy (best acc model)** | **EEGNet: test split accuracy (best loss model)** |\n",
    "|---------------|--------------------------------------|----------------------------------|--------------------------------------------------|---------------------------------------------------|\n",
    "| B (Train C&E) | 0.7654 @ epoch 92                    | 0.5768 @ epoch 135               | 0.6469                                           | 0.6479                                            |\n",
    "| C (Train B&E) | 0.6993 @ epoch 458                   | 0.6921 @ epoch 344               | 0.5892                                           | 0.5996                                            |\n",
    "| E (Train B&C) | 0.7454 @ epoch 889                   | 0.6425 @ epoch 1196              | 0.6419                                           | 0.6262                                            |\n",
    "\n",
    "Result after calibration are:\n",
    "\n",
    "| **Subject**   | **EEGNet: best validation accuracy** | **EEGNet: best validation loss** | **EEGNet: test split accuracy (best acc model)** | **EEGNet: test split accuracy (best loss model)** |\n",
    "|---------------|--------------------------------------|----------------------------------|--------------------------------------------------|---------------------------------------------------|\n",
    "| B (Train C&E) | 0.6 @ epoch 193                      | 0.8591 @ epoch 194               | 0.6373                                           | 0.6373                                            |\n",
    "| C (Train B&E) | 0.7667 @ epoch 304                   | 0.6773 @ epoch 2486              | 0.6233                                           | 0.6188                                            |\n",
    "| E (Train B&C) | 0.7333 @ epoch 85                    | 0.6853 @ epoch 2374              | 0.6432                                           | 0.6602                                            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ffa456",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# CALIBRATE EEGNET ON NEW SESSION\n",
    "####################################################\n",
    "\n",
    "# Configure global parameters for all experiments\n",
    "subject_ids_to_test = [\"B\", \"C\", \"E\"] # Subjects with three recordings\n",
    "start_offset = -1 # One second before visual queue\n",
    "end_offset = 1 # One second after visual queue\n",
    "baseline = None # Baseline correction using data before the visual queue\n",
    "do_experiment = False\n",
    "\n",
    "keras_eegnet_model = EEGNet(\n",
    "        nb_classes = 3, # int, number of classes to classify. \n",
    "        Chans = 21, # number of channels in the EEG data. \n",
    "        Samples = 100, # number of time points in the EEG data. (default: 128)\n",
    "        dropoutRate = 0.5, # dropout fraction. (default: 0.5)\n",
    "        kernLength = 50, # length of temporal convolution in first layer. Suggested: half the sampling rate. (default: 64)\n",
    "        F1 = 8, # number of temporal filters. (default: 8)\n",
    "        F2 = 16, # number of pointwise filters. (default: 16)\n",
    "        D = 2, # number of spatial filters to learn within each temporal convolution. (default: 2)\n",
    "        norm_rate = 0.25, # Normalisation rate. (default: 0.25)\n",
    "        dropoutType = 'SpatialDropout2D' # Either SpatialDropout2D or Dropout, passed as a string. (default: Dropout)\n",
    "        )\n",
    "\n",
    "if do_experiment:\n",
    "        # Loop over all found results\n",
    "        for subject_id in subject_ids_to_test:\n",
    "                print()\n",
    "                print(\"####################################################\")\n",
    "                print(f\"# RESULTS FOR SUBJECT {subject_id}\")\n",
    "                print(\"####################################################\")\n",
    "                print()\n",
    "                \n",
    "                ################### LOAD DATA ###################\n",
    "                # Names for model\n",
    "                pretrained_model_name = f\"saved_variables/4/newsubject/subject{subject_id}/trained_model\"\n",
    "                \n",
    "                tensorboard_name = f\"paper-notebook8_eegnet_calibration_newsubject_subject{subject_id}\"\n",
    "                best_base_model_filename =  f\"saved_variables/8/calibration/EEGNet/newsubject/subject{subject_id}/trained_model\"\n",
    "                \n",
    "                # Open lowest loss model from file, lowest loss is chosen as it likely needs \"least calibration\"\n",
    "                pretrained_model = TF_tools.load_lowest_loss_model(filepath= pretrained_model_name)\n",
    "                \n",
    "                # Get train and test split\n",
    "                with io.capture_output():\n",
    "                        # Get new session data\n",
    "                        mne_raw = CLA_dataset.get_last_raw_mne_data_for_subject(subject_id)\n",
    "                        \n",
    "                        # Get epochs for new session\n",
    "                        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                                             start_offset= start_offset,\n",
    "                                                                             end_offset= end_offset,\n",
    "                                                                             baseline= baseline)\n",
    "                        \n",
    "                        # Only keep epochs from the MI tasks\n",
    "                        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "                        \n",
    "                        # Fix the indexing\n",
    "                        # NOTE: this is some weird MNE behaviour, the index retreived is not the actual index if not reset due to filtering done\n",
    "                        mne_epochs.reset_drop_log_selection()\n",
    "                        \n",
    "                        # Load epochs into memory\n",
    "                        mne_epochs.load_data()\n",
    "                        \n",
    "                        # Get calibration test split\n",
    "                        calibration_items, test_items = CLA_dataset.get_calibration_test_split_from_epochs(epochs= mne_epochs,\n",
    "                                                                                                           amount_of_samples_in_calibration_per_class = 25)\n",
    "                        \n",
    "                        \n",
    "                # Get OHE from file\n",
    "                with open(f\"saved_variables/4/newsubject/subject{subject_id}/ohe-encoder.pickle\", 'rb') as f:\n",
    "                        ohe = pickle.load(f)\n",
    "                        \n",
    "                        \n",
    "                calibration_epochs = mne_epochs[calibration_items]\n",
    "                test_epochs = mne_epochs[test_items]\n",
    "\n",
    "                # Get labels\n",
    "                y_train = calibration_epochs.events[:, -1]\n",
    "                y_test = test_epochs.events[:, -1]\n",
    "\n",
    "                # Get train and test data\n",
    "                X_train = calibration_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "                X_test = test_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "\n",
    "                # Fix scaling sensitivity as MNE stores as data * 10e-6\n",
    "                X_train = X_train * 1000000\n",
    "                X_test = X_test * 1000000\n",
    "                \n",
    "                # Further devide the calibration split in train and eval samples\n",
    "                X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                                  y_train,\n",
    "                                                                  test_size = 0.4, # Use 5 samples per class for validation\n",
    "                                                                  shuffle= True,\n",
    "                                                                  stratify= y_train,                                                    \n",
    "                                                                  random_state= 1998)\n",
    "                \n",
    "                # Convert labels with OHE for Keras\n",
    "                y_train = ohe.transform(y_train.reshape(-1, 1)).toarray()\n",
    "                y_test = ohe.transform(y_test.reshape(-1, 1)).toarray()\n",
    "                y_val = ohe.transform(y_val.reshape(-1, 1)).toarray()\n",
    "                \n",
    "                # Print stats\n",
    "                print(f\"Calibrating with {np.shape(X_train)} windows\")\n",
    "                print(f\"Testing with {np.shape(X_test)} windows\")\n",
    "                \n",
    "                print(\"Calibrating epochs\")\n",
    "                display(calibration_epochs)\n",
    "                \n",
    "                print(\"test epochs\")\n",
    "                display(test_epochs)\n",
    "                        \n",
    "                ################### CALIBRATE MODEL ###################\n",
    "                # Make a calibration model\n",
    "                calibration_model = keras.models.clone_model(keras_eegnet_model)\n",
    "\n",
    "                \n",
    "                # Copy weights from pretrained model\n",
    "                calibration_model.set_weights(pretrained_model.get_weights())\n",
    "                \n",
    "                for layer in calibration_model.layers:\n",
    "                        layer.trainable = False\n",
    "                \n",
    "                # Allow last conv layer to learn\n",
    "                #calibration_model.layers[8].trainable = True # Overfits\n",
    "                \n",
    "                # Allow last layers to train (softmax)\n",
    "                calibration_model.layers[14].trainable = True\n",
    "                calibration_model.layers[15].trainable = True\n",
    "                \n",
    "                # Allow batch norm to train due to weird behaviour\n",
    "                calibration_model.layers[2].trainable = True\n",
    "                calibration_model.layers[4].trainable = True\n",
    "                calibration_model.layers[9].trainable = True\n",
    "                \n",
    "                \n",
    "                # Change dropout\n",
    "                calibration_model.layers[7].rate = 0\n",
    "                calibration_model.layers[12].rate = 0.2\n",
    "                \n",
    "                # Compile the model so it can be fitted, note a lower learning rate is set\n",
    "                calibration_model.compile(loss = 'categorical_crossentropy', optimizer = tf.optimizers.Adam(learning_rate= 0.0001), metrics=[\"accuracy\"])\n",
    "                \n",
    "                # Train model with GPU as means of recalibrating\n",
    "                # NOTE: change GPU to CPU if no GPU present\n",
    "                with tf.device('/gpu:0'):\n",
    "                        history = calibration_model.fit(\n",
    "                                x= X_train,\n",
    "                                y= y_train,\n",
    "                                batch_size= 128, # All calibration data at once\n",
    "                                epochs= 2500, # Very small due to direct overfit expected\n",
    "                                verbose= 1, # 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                                callbacks= [TF_tools.tensorboard_callback(log_name= tensorboard_name),\n",
    "                                        TF_tools.lowest_loss_model_save_callback(filepath= best_base_model_filename),\n",
    "                                        TF_tools.highest_accuracy_model_save_callback(filepath= best_base_model_filename)],\n",
    "                                validation_data= (X_val, y_val),\n",
    "                                shuffle= True,\n",
    "                                use_multiprocessing= True, # Done for faster speed\n",
    "                                workers= 4 # Done for faster speed\n",
    "                                )\n",
    "                        \n",
    "                # Store the fitting history\n",
    "                with open(f\"saved_variables/8/calibration/EEGNet/newsubject/subject{subject_id}/fitting_history.pickle\", 'wb') as file:\n",
    "                        pickle.dump(history.history, file)\n",
    "                        \n",
    "                # Store the test data\n",
    "                with open(f\"saved_variables/8/calibration/EEGNet/newsubject/subject{subject_id}/X_test.pickle\", 'wb') as file:\n",
    "                        pickle.dump(X_test, file)\n",
    "                        \n",
    "                with open(f\"saved_variables/8/calibration/EEGNet/newsubject/subject{subject_id}/y_test.pickle\", 'wb') as file:\n",
    "                        pickle.dump(y_test, file)\n",
    "        \n",
    "                # remove unused vars\n",
    "                del mne_raw\n",
    "                del mne_epochs\n",
    "                del pretrained_model_name\n",
    "                del pretrained_model\n",
    "                del f\n",
    "                del X_test\n",
    "                del y_test\n",
    "                del ohe\n",
    "                del calibration_epochs\n",
    "                del calibration_items\n",
    "                del test_epochs\n",
    "                del test_items\n",
    "                del X_train\n",
    "                del y_train\n",
    "                del X_val\n",
    "                del y_val\n",
    "                del tensorboard_name\n",
    "                del history\n",
    "                del best_base_model_filename\n",
    "                del calibration_model\n",
    "                del file\n",
    "                del layer\n",
    "        \n",
    "        del subject_id\n",
    "        \n",
    "# Remove unsused variables\n",
    "del subject_ids_to_test\n",
    "del baseline\n",
    "del end_offset\n",
    "del start_offset\n",
    "del keras_eegnet_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1f8bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# RESULTS\n",
    "####################################################\n",
    "\n",
    "# Configure global parameters for all experiments\n",
    "subject_ids_to_test = [\"B\", \"C\", \"E\"] # Subjects with three recordings\n",
    "start_offset = -1 # One second before visual queue\n",
    "end_offset = 1 # One second after visual queue\n",
    "baseline = None # Baseline correction using data before the visual queue\n",
    "\n",
    "# Loop over all found results\n",
    "for subject_id in subject_ids_to_test:\n",
    "    print()\n",
    "    print(\"####################################################\")\n",
    "    print(f\"# RESULTS FOR SUBJECT {subject_id}\")\n",
    "    print(\"####################################################\")\n",
    "    print()\n",
    "    \n",
    "    ################### load data ###################\n",
    "    # Names for model\n",
    "    best_base_model_filename = f\"saved_variables/8/calibration/EEGNet/newsubject/subject{subject_id}/trained_model\"\n",
    "    \n",
    "    # Open models from file\n",
    "    lowest_loss_model = TF_tools.load_lowest_loss_model(filepath= best_base_model_filename)\n",
    "    highest_accuracy_model = TF_tools.load_highest_accuracy_model(filepath= best_base_model_filename)\n",
    "    \n",
    "    # Get test data session\n",
    "    with io.capture_output():\n",
    "        # Get test data\n",
    "        mne_raw = CLA_dataset.get_last_raw_mne_data_for_subject(subject_id)\n",
    "        \n",
    "        # Get epochs for test MNE raw\n",
    "        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                             start_offset= start_offset,\n",
    "                                                             end_offset= end_offset,\n",
    "                                                             baseline= baseline)\n",
    "        \n",
    "        # Only keep epochs from the MI tasks\n",
    "        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "\n",
    "        # Load epochs into memory\n",
    "        mne_epochs.load_data()\n",
    "        \n",
    "        # Get the test labels\n",
    "        with open(f\"saved_variables/8/calibration/EEGNet/newsubject/subject{subject_id}/y_test.pickle\", 'rb') as f:\n",
    "            y_test = pickle.load(f)\n",
    "            \n",
    "        # Get the test data\n",
    "        with open(f\"saved_variables/8/calibration/EEGNet/newsubject/subject{subject_id}/X_test.pickle\", 'rb') as f:\n",
    "            X_test = pickle.load(f)\n",
    "        \n",
    "        # Delete resedual vars for training data\n",
    "        del mne_raw\n",
    "        del mne_epochs\n",
    "        \n",
    "    # Get OHE from file\n",
    "    with open(f\"saved_variables/4/newsubject/subject{subject_id}/ohe-encoder.pickle\", 'rb') as f:\n",
    "        ohe = pickle.load(f)\n",
    "        \n",
    "    # Get history from file\n",
    "    with open(f\"saved_variables/8/calibration/EEGNet/newsubject/subject{subject_id}/fitting_history.pickle\", 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "        \n",
    "    # Inverse y_test to label\n",
    "    y_test = ohe.inverse_transform(y_test)\n",
    "    \n",
    "    ################### history stats ###################\n",
    "    print(\"#### results of training ####\")\n",
    "    print(f\"Best training accuracy (max) {np.round(np.max(history['accuracy']), 4)} @ epoch {np.argmax(history['accuracy']) + 1}\")\n",
    "    print(f\"Best training loss (min) {np.round(np.min(history['loss']), 4)} @ epoch {np.argmin(history['loss']) + 1}\")\n",
    "    print()\n",
    "    print(f\"Best validation accuracy (max) {np.round(np.max(history['val_accuracy']), 4)} @ epoch {np.argmax(history['val_accuracy']) + 1}\")\n",
    "    print(f\"Best validation loss (min) {np.round(np.min(history['val_loss']), 4)} @ epoch {np.argmin(history['val_loss']) + 1}\")\n",
    "    \n",
    "    ################### highest accuracy model ###################\n",
    "    print(\"\\n#### results for highest accuracy model ####\")\n",
    "    # Get predictions from lowest loss model and convert back to labels\n",
    "    y_pred = highest_accuracy_model.predict(X_test)\n",
    "    y_pred = ohe.inverse_transform(y_pred)\n",
    "    \n",
    "    # Get accuracy score and print it\n",
    "    accuracy =  accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy of: {np.round(accuracy, 4)}\")\n",
    "    \n",
    "    # Show CM\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    ################### lowest loss model ###################\n",
    "    print(\"\\n#### results for lowest loss model ####\")\n",
    "    # Get predictions from lowest loss model and convert back to labels\n",
    "    y_pred = lowest_loss_model.predict(X_test)\n",
    "    y_pred = ohe.inverse_transform(y_pred)\n",
    "    \n",
    "    # Get accuracy score and print it\n",
    "    accuracy =  accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy of: {np.round(accuracy, 4)}\")\n",
    "    \n",
    "    # Show CM\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    ################### cleanup ###################\n",
    "    # remove unused vars\n",
    "    del best_base_model_filename\n",
    "    del lowest_loss_model\n",
    "    del highest_accuracy_model\n",
    "    del f\n",
    "    del X_test\n",
    "    del y_test\n",
    "    del history\n",
    "    del ohe\n",
    "    del y_pred\n",
    "    del accuracy\n",
    "\n",
    "# Remove unsused variables\n",
    "del subject_ids_to_test\n",
    "del subject_id\n",
    "del baseline\n",
    "del end_offset\n",
    "del start_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649937f",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### EEGNet with LSTM conv: new session\n",
    "\n",
    "Results before calibration were:\n",
    "\n",
    "| **Subject** | **EEGNet LSTM conv: best validation accuracy** | **EEGNet LSTM conv: best validation loss** | **EEGNet LSTM conv: test split accuracy (best acc model)** | **EEGNet LSTM conv: test split accuracy (best loss model)** |\n",
    "|-------------|------------------------------------------------|--------------------------------------------|------------------------------------------------------------|-------------------------------------------------------------|\n",
    "| B           | 0.6545 @ epoch 300                             | 0.8255 @ epoch 169                         | 0.6385                                                     | 0.6594                                                      |\n",
    "| C           | 0.8663 @ epoch 300                             | 0.4087 @ epoch 337                         | 0.6872                                                     | 0.6632                                                      |\n",
    "| E           | 0.7431 @ epoch 191                             | 0.6214 @ epoch 191                         | 0.6492                                                     | 0.6492                                                      |\n",
    "\n",
    "Result after calibration are:\n",
    "\n",
    "| **Subject** | **EEGNet LSTM conv: best validation accuracy** | **EEGNet LSTM conv: best validation loss** | **EEGNet LSTM conv: test split accuracy (best acc model)** | **EEGNet LSTM conv: test split accuracy (best loss model)** |\n",
    "|-------------|------------------------------------------------|--------------------------------------------|------------------------------------------------------------|-------------------------------------------------------------|\n",
    "| B           | 0.7333 @ epoch 213                             | 0.8291 @ epoch 82                          | 0.6158                                                     | 0.6395                                                      |\n",
    "| C           | 0.8 @ epoch 1                                  | 0.6055 @ epoch 185                         | 0.6595                                                     | 0.6652                                                      |\n",
    "| E           | 0.8 @ epoch 11                                 | 0.6687 @ epoch 457                         | 0.6727                                                     | 0.7807                                                      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0135994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# MODEL OVERVIEW\n",
    "####################################################\n",
    "\n",
    "EEGNet_lstm_1Dconv(\n",
    "    nb_classes = 3, # int, number of classes to classify. \n",
    "    Chans = 21, # number of channels in the EEG data. \n",
    "    Samples = 100, # number of time points in the EEG data. (default: 128)\n",
    "    dropoutRate = 0.5, # dropout fraction. (default: 0.5)\n",
    "    kernLength = 50, # length of temporal convolution in first layer. Suggested: half the sampling rate. (default: 64)\n",
    "    F1 = 8, # number of temporal filters. (default: 8)\n",
    "    D = 2, # number of spatial filters to learn within each temporal convolution. (default: 2)\n",
    "    norm_rate = 0.25, # Normalisation rate. (default: 0.25)\n",
    "    dropoutType = 'SpatialDropout2D', # Either SpatialDropout2D or Dropout, passed as a string. (default: Dropout)\n",
    "    lstm_filters = 40, # Amount of filters for LSTM layer Conv1D. Default: 32\n",
    "    lstm_kernel_size = 9, # Kernels size for LSTM layer Conv1D.\n",
    "    ltsm_dropout= 0.7,\n",
    "    ltsm_l1 = 0.00005, \n",
    "    ltsm_l2 = 0.00005\n",
    ").layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842b7dd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# CALIBRATE EEGNET ON NEW SESSION\n",
    "####################################################\n",
    "\n",
    "# Configure global parameters for all experiments\n",
    "subject_ids_to_test = [\"B\", \"C\", \"E\"] # Subjects with three recordings\n",
    "start_offset = -1 # One second before visual queue\n",
    "end_offset = 1 # One second after visual queue\n",
    "baseline = None # Baseline correction using data before the visual queue\n",
    "do_experiment = False\n",
    "\n",
    "keras_eegnet_lstm_1Dconv_model = EEGNet_lstm_1Dconv(\n",
    "    nb_classes = 3, # int, number of classes to classify. \n",
    "    Chans = 21, # number of channels in the EEG data. \n",
    "    Samples = 100, # number of time points in the EEG data. (default: 128)\n",
    "    dropoutRate = 0.5, # dropout fraction. (default: 0.5)\n",
    "    kernLength = 50, # length of temporal convolution in first layer. Suggested: half the sampling rate. (default: 64)\n",
    "    F1 = 8, # number of temporal filters. (default: 8)\n",
    "    D = 2, # number of spatial filters to learn within each temporal convolution. (default: 2)\n",
    "    norm_rate = 0.25, # Normalisation rate. (default: 0.25)\n",
    "    dropoutType = 'SpatialDropout2D', # Either SpatialDropout2D or Dropout, passed as a string. (default: Dropout)\n",
    "    lstm_filters = 40, # Amount of filters for LSTM layer Conv1D. Default: 32\n",
    "    lstm_kernel_size = 9, # Kernels size for LSTM layer Conv1D.\n",
    "    ltsm_dropout= 0.7,\n",
    "    ltsm_l1 = 0.00005, \n",
    "    ltsm_l2 = 0.00005\n",
    ")\n",
    "\n",
    "if do_experiment:\n",
    "        # Loop over all found results\n",
    "        for subject_id in subject_ids_to_test:\n",
    "                print()\n",
    "                print(\"####################################################\")\n",
    "                print(f\"# RESULTS FOR SUBJECT {subject_id}\")\n",
    "                print(\"####################################################\")\n",
    "                print()\n",
    "                \n",
    "                ################### LOAD DATA ###################\n",
    "                # Names for model\n",
    "                pretrained_model_name = f\"saved_variables/7/EEGNet_lstmconv1D/samesubject_differentsession/subject{subject_id}/trained_model\"\n",
    "                \n",
    "                tensorboard_name = f\"paper-notebook8_eegnet_convlstm_calibration_newsession_subject{subject_id}\"\n",
    "                best_base_model_filename =  f\"saved_variables/8/calibration/EEGNet_lstmconv1D/samesubject_differentsession/subject{subject_id}/trained_model\"\n",
    "                \n",
    "                # Open lowest loss model from file, lowest loss is chosen as it likely needs \"least calibration\"\n",
    "                pretrained_model = TF_tools.load_lowest_loss_model(filepath= pretrained_model_name)\n",
    "                \n",
    "                # Get train and test split\n",
    "                with io.capture_output():\n",
    "                        # Get new session data\n",
    "                        mne_raw = CLA_dataset.get_last_raw_mne_data_for_subject(subject_id)\n",
    "                        \n",
    "                        # Get epochs for new session\n",
    "                        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                                             start_offset= start_offset,\n",
    "                                                                             end_offset= end_offset,\n",
    "                                                                             baseline= baseline)\n",
    "                        \n",
    "                        # Only keep epochs from the MI tasks\n",
    "                        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "                        \n",
    "                        # Fix the indexing\n",
    "                        # NOTE: this is some weird MNE behaviour, the index retreived is not the actual index if not reset due to filtering done\n",
    "                        mne_epochs.reset_drop_log_selection()\n",
    "                        \n",
    "                        # Load epochs into memory\n",
    "                        mne_epochs.load_data()\n",
    "                        \n",
    "                        # Get calibration test split\n",
    "                        calibration_items, test_items = CLA_dataset.get_calibration_test_split_from_epochs(epochs= mne_epochs,\n",
    "                                                                                                           amount_of_samples_in_calibration_per_class = 25)\n",
    "                        \n",
    "                        \n",
    "                # Get OHE from file\n",
    "                with open(f\"saved_variables/7/EEGNet_lstmconv1D/samesubject_differentsession/subject{subject_id}/ohe-encoder.pickle\", 'rb') as f:\n",
    "                        ohe = pickle.load(f)\n",
    "                        \n",
    "                        \n",
    "                calibration_epochs = mne_epochs[calibration_items]\n",
    "                test_epochs = mne_epochs[test_items]\n",
    "\n",
    "                # Get labels\n",
    "                y_train = calibration_epochs.events[:, -1]\n",
    "                y_test = test_epochs.events[:, -1]\n",
    "\n",
    "                # Get train and test data\n",
    "                X_train = calibration_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "                X_test = test_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "\n",
    "                # Fix scaling sensitivity as MNE stores as data * 10e-6\n",
    "                X_train = X_train * 1000000\n",
    "                X_test = X_test * 1000000\n",
    "                \n",
    "                # Further devide the calibration split in train and eval samples\n",
    "                X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                                  y_train,\n",
    "                                                                  test_size = 0.4, # Use 5 samples per class for validation\n",
    "                                                                  shuffle= True,\n",
    "                                                                  stratify= y_train,                                                    \n",
    "                                                                  random_state= 1998)\n",
    "                \n",
    "                # Convert labels with OHE for Keras\n",
    "                y_train = ohe.transform(y_train.reshape(-1, 1)).toarray()\n",
    "                y_test = ohe.transform(y_test.reshape(-1, 1)).toarray()\n",
    "                y_val = ohe.transform(y_val.reshape(-1, 1)).toarray()\n",
    "                \n",
    "                # Print stats\n",
    "                print(f\"Calibrating with {np.shape(X_train)} windows\")\n",
    "                print(f\"Testing with {np.shape(X_test)} windows\")\n",
    "                \n",
    "                print(\"Calibrating epochs\")\n",
    "                display(calibration_epochs)\n",
    "                \n",
    "                print(\"test epochs\")\n",
    "                display(test_epochs)\n",
    "                        \n",
    "                ################### CALIBRATE MODEL ###################\n",
    "                # Make a calibration model\n",
    "                calibration_model = keras.models.clone_model(keras_eegnet_lstm_1Dconv_model)\n",
    "\n",
    "                \n",
    "                # Copy weights from pretrained model\n",
    "                calibration_model.set_weights(pretrained_model.get_weights())\n",
    "                \n",
    "                for layer in calibration_model.layers:\n",
    "                        layer.trainable = False\n",
    "                \n",
    "                \n",
    "                # Allow last layers to train (softmax)\n",
    "                calibration_model.layers[11].trainable = True\n",
    "                calibration_model.layers[12].trainable = True\n",
    "                \n",
    "                # Allow batch norm to train due to weird behaviour\n",
    "                calibration_model.layers[2].trainable = True\n",
    "                calibration_model.layers[4].trainable = True\n",
    "                \n",
    "                \n",
    "                # Change dropout\n",
    "                calibration_model.layers[6].rate = 0\n",
    "                calibration_model.layers[9].rate = 0.2\n",
    "                \n",
    "                # Compile the model so it can be fitted, note a lower learning rate is set\n",
    "                calibration_model.compile(loss = 'categorical_crossentropy', optimizer = tf.optimizers.Adam(learning_rate= 0.0001), metrics=[\"accuracy\"])\n",
    "                \n",
    "                # Train model with GPU as means of recalibrating\n",
    "                # NOTE: change GPU to CPU if no GPU present\n",
    "                with tf.device('/gpu:0'):\n",
    "                        history = calibration_model.fit(\n",
    "                                x= X_train,\n",
    "                                y= y_train,\n",
    "                                batch_size= 128, # All calibration data at once\n",
    "                                epochs= 500, # Very small due to direct overfit expected\n",
    "                                verbose= 1, # 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                                callbacks= [TF_tools.tensorboard_callback(log_name= tensorboard_name),\n",
    "                                        TF_tools.lowest_loss_model_save_callback(filepath= best_base_model_filename),\n",
    "                                        TF_tools.highest_accuracy_model_save_callback(filepath= best_base_model_filename)],\n",
    "                                validation_data= (X_val, y_val),\n",
    "                                shuffle= True,\n",
    "                                use_multiprocessing= True, # Done for faster speed\n",
    "                                workers= 4 # Done for faster speed\n",
    "                                )\n",
    "                        \n",
    "                # Store the fitting history\n",
    "                with open(f\"saved_variables/8/calibration/EEGNet_lstmconv1D/samesubject_differentsession/subject{subject_id}/fitting_history.pickle\", 'wb') as file:\n",
    "                        pickle.dump(history.history, file)\n",
    "                        \n",
    "                # Store the test data\n",
    "                with open(f\"saved_variables/8/calibration/EEGNet_lstmconv1D/samesubject_differentsession/subject{subject_id}/X_test.pickle\", 'wb') as file:\n",
    "                        pickle.dump(X_test, file)\n",
    "                        \n",
    "                with open(f\"saved_variables/8/calibration/EEGNet_lstmconv1D/samesubject_differentsession/subject{subject_id}/y_test.pickle\", 'wb') as file:\n",
    "                        pickle.dump(y_test, file)\n",
    "        \n",
    "                # remove unused vars\n",
    "                del mne_raw\n",
    "                del mne_epochs\n",
    "                del pretrained_model_name\n",
    "                del pretrained_model\n",
    "                del f\n",
    "                del X_test\n",
    "                del y_test\n",
    "                del ohe\n",
    "                del calibration_epochs\n",
    "                del calibration_items\n",
    "                del test_epochs\n",
    "                del test_items\n",
    "                del X_train\n",
    "                del y_train\n",
    "                del X_val\n",
    "                del y_val\n",
    "                del tensorboard_name\n",
    "                del history\n",
    "                del best_base_model_filename\n",
    "                del calibration_model\n",
    "                del file\n",
    "                del layer\n",
    "        \n",
    "        del subject_id\n",
    "        \n",
    "# Remove unsused variables\n",
    "del subject_ids_to_test\n",
    "del baseline\n",
    "del end_offset\n",
    "del start_offset\n",
    "del keras_eegnet_lstm_1Dconv_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0845bec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# RESULTS\n",
    "####################################################\n",
    "\n",
    "# Configure global parameters for all experiments\n",
    "subject_ids_to_test = [\"B\", \"C\", \"E\"] # Subjects with three recordings\n",
    "start_offset = -1 # One second before visual queue\n",
    "end_offset = 1 # One second after visual queue\n",
    "baseline = None # Baseline correction using data before the visual queue\n",
    "\n",
    "# Loop over all found results\n",
    "for subject_id in subject_ids_to_test:\n",
    "    print()\n",
    "    print(\"####################################################\")\n",
    "    print(f\"# RESULTS FOR SUBJECT {subject_id}\")\n",
    "    print(\"####################################################\")\n",
    "    print()\n",
    "    \n",
    "    ################### load data ###################\n",
    "    # Names for model\n",
    "    best_base_model_filename = f\"saved_variables/8/calibration/EEGNet_lstmconv1D/samesubject_differentsession/subject{subject_id}/trained_model\"\n",
    "    \n",
    "    # Open models from file\n",
    "    lowest_loss_model = TF_tools.load_lowest_loss_model(filepath= best_base_model_filename)\n",
    "    highest_accuracy_model = TF_tools.load_highest_accuracy_model(filepath= best_base_model_filename)\n",
    "    \n",
    "    # Get test data session\n",
    "    with io.capture_output():\n",
    "        # Get test data\n",
    "        mne_raw = CLA_dataset.get_last_raw_mne_data_for_subject(subject_id)\n",
    "        \n",
    "        # Get epochs for test MNE raw\n",
    "        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                             start_offset= start_offset,\n",
    "                                                             end_offset= end_offset,\n",
    "                                                             baseline= baseline)\n",
    "        \n",
    "        # Only keep epochs from the MI tasks\n",
    "        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "\n",
    "        # Load epochs into memory\n",
    "        mne_epochs.load_data()\n",
    "        \n",
    "        # Get the test labels\n",
    "        with open(f\"saved_variables/8/calibration/EEGNet_lstmconv1D/samesubject_differentsession/subject{subject_id}/y_test.pickle\", 'rb') as f:\n",
    "            y_test = pickle.load(f)\n",
    "            \n",
    "        # Get the test data\n",
    "        with open(f\"saved_variables/8/calibration/EEGNet_lstmconv1D/samesubject_differentsession/subject{subject_id}/X_test.pickle\", 'rb') as f:\n",
    "            X_test = pickle.load(f)\n",
    "        \n",
    "        # Delete resedual vars for training data\n",
    "        del mne_raw\n",
    "        del mne_epochs\n",
    "        \n",
    "    # Get OHE from file\n",
    "    with open(f\"saved_variables/7/EEGNet_lstmconv1D/samesubject_differentsession/subject{subject_id}/ohe-encoder.pickle\", 'rb') as f:\n",
    "        ohe = pickle.load(f)\n",
    "        \n",
    "    # Get history from file\n",
    "    with open(f\"saved_variables/8/calibration/EEGNet_lstmconv1D/samesubject_differentsession/subject{subject_id}/fitting_history.pickle\", 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "        \n",
    "    # Inverse y_test to label\n",
    "    y_test = ohe.inverse_transform(y_test)\n",
    "    \n",
    "    ################### history stats ###################\n",
    "    print(\"#### results of training ####\")\n",
    "    print(f\"Best training accuracy (max) {np.round(np.max(history['accuracy']), 4)} @ epoch {np.argmax(history['accuracy']) + 1}\")\n",
    "    print(f\"Best training loss (min) {np.round(np.min(history['loss']), 4)} @ epoch {np.argmin(history['loss']) + 1}\")\n",
    "    print()\n",
    "    print(f\"Best validation accuracy (max) {np.round(np.max(history['val_accuracy']), 4)} @ epoch {np.argmax(history['val_accuracy']) + 1}\")\n",
    "    print(f\"Best validation loss (min) {np.round(np.min(history['val_loss']), 4)} @ epoch {np.argmin(history['val_loss']) + 1}\")\n",
    "    \n",
    "    ################### highest accuracy model ###################\n",
    "    print(\"\\n#### results for highest accuracy model ####\")\n",
    "    # Get predictions from lowest loss model and convert back to labels\n",
    "    y_pred = highest_accuracy_model.predict(X_test)\n",
    "    y_pred = ohe.inverse_transform(y_pred)\n",
    "    \n",
    "    # Get accuracy score and print it\n",
    "    accuracy =  accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy of: {np.round(accuracy, 4)}\")\n",
    "    \n",
    "    # Show CM\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    ################### lowest loss model ###################\n",
    "    print(\"\\n#### results for lowest loss model ####\")\n",
    "    # Get predictions from lowest loss model and convert back to labels\n",
    "    y_pred = lowest_loss_model.predict(X_test)\n",
    "    y_pred = ohe.inverse_transform(y_pred)\n",
    "    \n",
    "    # Get accuracy score and print it\n",
    "    accuracy =  accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy of: {np.round(accuracy, 4)}\")\n",
    "    \n",
    "    # Show CM\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    ################### cleanup ###################\n",
    "    # remove unused vars\n",
    "    del best_base_model_filename\n",
    "    del lowest_loss_model\n",
    "    del highest_accuracy_model\n",
    "    del f\n",
    "    del X_test\n",
    "    del y_test\n",
    "    del history\n",
    "    del ohe\n",
    "    del y_pred\n",
    "    del accuracy\n",
    "\n",
    "# Remove unsused variables\n",
    "del subject_ids_to_test\n",
    "del subject_id\n",
    "del baseline\n",
    "del end_offset\n",
    "del start_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2fd231",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### EEGNet with LSTM conv: new subject\n",
    "\n",
    "Results before calibration were:\n",
    "\n",
    "| **Subject** | **EEGNet LSTM conv: best validation accuracy** | **EEGNet LSTM conv: best validation loss** | **EEGNet LSTM conv: test split accuracy (best acc model)** | **EEGNet LSTM conv: test split accuracy (best loss model)** |\n",
    "|-------------|------------------------------------------------|--------------------------------------------|------------------------------------------------------------|-------------------------------------------------------------|\n",
    "| B           | 0.7497 @ epoch 82                              | 0.6353 @ epoch 47                          | 0.626                                                      | 0.6125                                                      |\n",
    "| C           | 0.7329 @ epoch 50                              | 0.6575 @ epoch 109                         | 0.6204                                                     | 0.5746                                                      |\n",
    "| E           | 0.724 @ epoch 240                              | 0.6687 @ epoch 75                          | 0.6136                                                     | 0.6618                                                      |\n",
    "\n",
    "Result after calibration are:\n",
    "\n",
    "| **Subject**   | **EEGNet LSTM conv: best validation accuracy** | **EEGNet LSTM conv: best validation loss** | **EEGNet LSTM conv: test split accuracy (best acc model)** | **EEGNet LSTM conv: test split accuracy (best loss model)** |\n",
    "|---------------|------------------------------------------------|--------------------------------------------|------------------------------------------------------------|-------------------------------------------------------------|\n",
    "| B (Train C&E) | 0.6667 @ epoch 182                             | 0.8062 @ epoch 366                         | 0.6249                                                     | 0.626                                                       |\n",
    "| C (Train B&E) | 0.7333 @ epoch 206                             | 0.7253 @ epoch 240                         | 0.621                                                      | 0.6199                                                      |\n",
    "| E (Train B&C) | 0.8667 @ epoch 9                               | 0.3985 @ epoch 378                         | 0.6625                                                     | 0.7216                                                      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1094d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# CALIBRATE EEGNET ON NEW SESSION\n",
    "####################################################\n",
    "\n",
    "# Configure global parameters for all experiments\n",
    "subject_ids_to_test = [\"B\", \"C\", \"E\"] # Subjects with three recordings\n",
    "start_offset = -1 # One second before visual queue\n",
    "end_offset = 1 # One second after visual queue\n",
    "baseline = None # Baseline correction using data before the visual queue\n",
    "do_experiment = False\n",
    "\n",
    "keras_eegnet_lstm_1Dconv_model = EEGNet_lstm_1Dconv(\n",
    "    nb_classes = 3, # int, number of classes to classify. \n",
    "    Chans = 21, # number of channels in the EEG data. \n",
    "    Samples = 100, # number of time points in the EEG data. (default: 128)\n",
    "    dropoutRate = 0.5, # dropout fraction. (default: 0.5)\n",
    "    kernLength = 50, # length of temporal convolution in first layer. Suggested: half the sampling rate. (default: 64)\n",
    "    F1 = 8, # number of temporal filters. (default: 8)\n",
    "    D = 2, # number of spatial filters to learn within each temporal convolution. (default: 2)\n",
    "    norm_rate = 0.25, # Normalisation rate. (default: 0.25)\n",
    "    dropoutType = 'SpatialDropout2D', # Either SpatialDropout2D or Dropout, passed as a string. (default: Dropout)\n",
    "    lstm_filters = 40, # Amount of filters for LSTM layer Conv1D. Default: 32\n",
    "    lstm_kernel_size = 9, # Kernels size for LSTM layer Conv1D.\n",
    "    ltsm_dropout= 0.7,\n",
    "    ltsm_l1 = 0.00005, \n",
    "    ltsm_l2 = 0.00005\n",
    ")\n",
    "\n",
    "if do_experiment:\n",
    "        # Loop over all found results\n",
    "        for subject_id in subject_ids_to_test:\n",
    "                print()\n",
    "                print(\"####################################################\")\n",
    "                print(f\"# RESULTS FOR SUBJECT {subject_id}\")\n",
    "                print(\"####################################################\")\n",
    "                print()\n",
    "                \n",
    "                ################### LOAD DATA ###################\n",
    "                # Names for model\n",
    "                pretrained_model_name = f\"saved_variables/7/EEGNet_lstmconv1D/newsubject/subject{subject_id}/trained_model\"\n",
    "                \n",
    "                tensorboard_name = f\"paper-notebook8_eegnet_convlstm_calibration_newsubject_subject{subject_id}\"\n",
    "                best_base_model_filename =  f\"saved_variables/8/calibration/EEGNet_lstmconv1D/newsubject/subject{subject_id}/trained_model\"\n",
    "                \n",
    "                # Open lowest loss model from file, lowest loss is chosen as it likely needs \"least calibration\"\n",
    "                pretrained_model = TF_tools.load_lowest_loss_model(filepath= pretrained_model_name)\n",
    "                \n",
    "                # Get train and test split\n",
    "                with io.capture_output():\n",
    "                        # Get new session data\n",
    "                        mne_raw = CLA_dataset.get_last_raw_mne_data_for_subject(subject_id)\n",
    "                        \n",
    "                        # Get epochs for new session\n",
    "                        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                                             start_offset= start_offset,\n",
    "                                                                             end_offset= end_offset,\n",
    "                                                                             baseline= baseline)\n",
    "                        \n",
    "                        # Only keep epochs from the MI tasks\n",
    "                        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "                        \n",
    "                        # Fix the indexing\n",
    "                        # NOTE: this is some weird MNE behaviour, the index retreived is not the actual index if not reset due to filtering done\n",
    "                        mne_epochs.reset_drop_log_selection()\n",
    "                        \n",
    "                        # Load epochs into memory\n",
    "                        mne_epochs.load_data()\n",
    "                        \n",
    "                        # Get calibration test split\n",
    "                        calibration_items, test_items = CLA_dataset.get_calibration_test_split_from_epochs(epochs= mne_epochs,\n",
    "                                                                                                           amount_of_samples_in_calibration_per_class = 25)\n",
    "                        \n",
    "                        \n",
    "                # Get OHE from file\n",
    "                with open(f\"saved_variables/7/EEGNet_lstmconv1D/newsubject/subject{subject_id}/ohe-encoder.pickle\", 'rb') as f:\n",
    "                        ohe = pickle.load(f)\n",
    "                        \n",
    "                        \n",
    "                calibration_epochs = mne_epochs[calibration_items]\n",
    "                test_epochs = mne_epochs[test_items]\n",
    "\n",
    "                # Get labels\n",
    "                y_train = calibration_epochs.events[:, -1]\n",
    "                y_test = test_epochs.events[:, -1]\n",
    "\n",
    "                # Get train and test data\n",
    "                X_train = calibration_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "                X_test = test_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "\n",
    "                # Fix scaling sensitivity as MNE stores as data * 10e-6\n",
    "                X_train = X_train * 1000000\n",
    "                X_test = X_test * 1000000\n",
    "                \n",
    "                # Further devide the calibration split in train and eval samples\n",
    "                X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                                  y_train,\n",
    "                                                                  test_size = 0.4, # Use 5 samples per class for validation\n",
    "                                                                  shuffle= True,\n",
    "                                                                  stratify= y_train,                                                    \n",
    "                                                                  random_state= 1998)\n",
    "                \n",
    "                # Convert labels with OHE for Keras\n",
    "                y_train = ohe.transform(y_train.reshape(-1, 1)).toarray()\n",
    "                y_test = ohe.transform(y_test.reshape(-1, 1)).toarray()\n",
    "                y_val = ohe.transform(y_val.reshape(-1, 1)).toarray()\n",
    "                \n",
    "                # Print stats\n",
    "                print(f\"Calibrating with {np.shape(X_train)} windows\")\n",
    "                print(f\"Testing with {np.shape(X_test)} windows\")\n",
    "                \n",
    "                print(\"Calibrating epochs\")\n",
    "                display(calibration_epochs)\n",
    "                \n",
    "                print(\"test epochs\")\n",
    "                display(test_epochs)\n",
    "                        \n",
    "                ################### CALIBRATE MODEL ###################\n",
    "                # Make a calibration model\n",
    "                calibration_model = keras.models.clone_model(keras_eegnet_lstm_1Dconv_model)\n",
    "\n",
    "                \n",
    "                # Copy weights from pretrained model\n",
    "                calibration_model.set_weights(pretrained_model.get_weights())\n",
    "                \n",
    "                for layer in calibration_model.layers:\n",
    "                        layer.trainable = False\n",
    "                \n",
    "                \n",
    "                # Allow last layers to train (softmax)\n",
    "                calibration_model.layers[11].trainable = True\n",
    "                calibration_model.layers[12].trainable = True\n",
    "                \n",
    "                # Allow batch norm to train due to weird behaviour\n",
    "                calibration_model.layers[2].trainable = True\n",
    "                calibration_model.layers[4].trainable = True\n",
    "                \n",
    "                \n",
    "                # Change dropout\n",
    "                calibration_model.layers[6].rate = 0\n",
    "                calibration_model.layers[9].rate = 0.3\n",
    "                \n",
    "                # Compile the model so it can be fitted, note a lower learning rate is set\n",
    "                calibration_model.compile(loss = 'categorical_crossentropy', optimizer = tf.optimizers.Adam(learning_rate= 0.00005), metrics=[\"accuracy\"])\n",
    "                \n",
    "                # Train model with GPU as means of recalibrating\n",
    "                # NOTE: change GPU to CPU if no GPU present\n",
    "                with tf.device('/gpu:0'):\n",
    "                        history = calibration_model.fit(\n",
    "                                x= X_train,\n",
    "                                y= y_train,\n",
    "                                batch_size= 128, # All calibration data at once\n",
    "                                epochs= 500, # Very small due to direct overfit expected\n",
    "                                verbose= 1, # 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                                callbacks= [TF_tools.tensorboard_callback(log_name= tensorboard_name),\n",
    "                                        TF_tools.lowest_loss_model_save_callback(filepath= best_base_model_filename),\n",
    "                                        TF_tools.highest_accuracy_model_save_callback(filepath= best_base_model_filename)],\n",
    "                                validation_data= (X_val, y_val),\n",
    "                                shuffle= True,\n",
    "                                use_multiprocessing= True, # Done for faster speed\n",
    "                                workers= 4 # Done for faster speed\n",
    "                                )\n",
    "                        \n",
    "                # Store the fitting history\n",
    "                with open(f\"saved_variables/8/calibration/EEGNet_lstmconv1D/newsubject/subject{subject_id}/fitting_history.pickle\", 'wb') as file:\n",
    "                        pickle.dump(history.history, file)\n",
    "                        \n",
    "                # Store the test data\n",
    "                with open(f\"saved_variables/8/calibration/EEGNet_lstmconv1D/newsubject/subject{subject_id}/X_test.pickle\", 'wb') as file:\n",
    "                        pickle.dump(X_test, file)\n",
    "                        \n",
    "                with open(f\"saved_variables/8/calibration/EEGNet_lstmconv1D/newsubject/subject{subject_id}/y_test.pickle\", 'wb') as file:\n",
    "                        pickle.dump(y_test, file)\n",
    "        \n",
    "                # remove unused vars\n",
    "                del mne_raw\n",
    "                del mne_epochs\n",
    "                del pretrained_model_name\n",
    "                del pretrained_model\n",
    "                del f\n",
    "                del X_test\n",
    "                del y_test\n",
    "                del ohe\n",
    "                del calibration_epochs\n",
    "                del calibration_items\n",
    "                del test_epochs\n",
    "                del test_items\n",
    "                del X_train\n",
    "                del y_train\n",
    "                del X_val\n",
    "                del y_val\n",
    "                del tensorboard_name\n",
    "                del history\n",
    "                del best_base_model_filename\n",
    "                del calibration_model\n",
    "                del file\n",
    "                del layer\n",
    "        \n",
    "        del subject_id\n",
    "        \n",
    "# Remove unsused variables\n",
    "del subject_ids_to_test\n",
    "del baseline\n",
    "del end_offset\n",
    "del start_offset\n",
    "del keras_eegnet_lstm_1Dconv_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67b7c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# RESULTS\n",
    "####################################################\n",
    "\n",
    "# Configure global parameters for all experiments\n",
    "subject_ids_to_test = [\"B\", \"C\", \"E\"] # Subjects with three recordings\n",
    "start_offset = -1 # One second before visual queue\n",
    "end_offset = 1 # One second after visual queue\n",
    "baseline = None # Baseline correction using data before the visual queue\n",
    "\n",
    "# Loop over all found results\n",
    "for subject_id in subject_ids_to_test:\n",
    "    print()\n",
    "    print(\"####################################################\")\n",
    "    print(f\"# RESULTS FOR SUBJECT {subject_id}\")\n",
    "    print(\"####################################################\")\n",
    "    print()\n",
    "    \n",
    "    ################### load data ###################\n",
    "    # Names for model\n",
    "    best_base_model_filename = f\"saved_variables/8/calibration/EEGNet_lstmconv1D/newsubject/subject{subject_id}/trained_model\"\n",
    "    \n",
    "    # Open models from file\n",
    "    lowest_loss_model = TF_tools.load_lowest_loss_model(filepath= best_base_model_filename)\n",
    "    highest_accuracy_model = TF_tools.load_highest_accuracy_model(filepath= best_base_model_filename)\n",
    "    \n",
    "    # Get test data session\n",
    "    with io.capture_output():\n",
    "        # Get test data\n",
    "        mne_raw = CLA_dataset.get_last_raw_mne_data_for_subject(subject_id)\n",
    "        \n",
    "        # Get epochs for test MNE raw\n",
    "        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                             start_offset= start_offset,\n",
    "                                                             end_offset= end_offset,\n",
    "                                                             baseline= baseline)\n",
    "        \n",
    "        # Only keep epochs from the MI tasks\n",
    "        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "\n",
    "        # Load epochs into memory\n",
    "        mne_epochs.load_data()\n",
    "        \n",
    "        # Get the test labels\n",
    "        with open(f\"saved_variables/8/calibration/EEGNet_lstmconv1D/newsubject/subject{subject_id}/y_test.pickle\", 'rb') as f:\n",
    "            y_test = pickle.load(f)\n",
    "            \n",
    "        # Get the test data\n",
    "        with open(f\"saved_variables/8/calibration/EEGNet_lstmconv1D/newsubject/subject{subject_id}/X_test.pickle\", 'rb') as f:\n",
    "            X_test = pickle.load(f)\n",
    "        \n",
    "        # Delete resedual vars for training data\n",
    "        del mne_raw\n",
    "        del mne_epochs\n",
    "        \n",
    "    # Get OHE from file\n",
    "    with open(f\"saved_variables/7/EEGNet_lstmconv1D/newsubject/subject{subject_id}/ohe-encoder.pickle\", 'rb') as f:\n",
    "        ohe = pickle.load(f)\n",
    "        \n",
    "    # Get history from file\n",
    "    with open(f\"saved_variables/8/calibration/EEGNet_lstmconv1D/newsubject/subject{subject_id}/fitting_history.pickle\", 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "        \n",
    "    # Inverse y_test to label\n",
    "    y_test = ohe.inverse_transform(y_test)\n",
    "    \n",
    "    ################### history stats ###################\n",
    "    print(\"#### results of training ####\")\n",
    "    print(f\"Best training accuracy (max) {np.round(np.max(history['accuracy']), 4)} @ epoch {np.argmax(history['accuracy']) + 1}\")\n",
    "    print(f\"Best training loss (min) {np.round(np.min(history['loss']), 4)} @ epoch {np.argmin(history['loss']) + 1}\")\n",
    "    print()\n",
    "    print(f\"Best validation accuracy (max) {np.round(np.max(history['val_accuracy']), 4)} @ epoch {np.argmax(history['val_accuracy']) + 1}\")\n",
    "    print(f\"Best validation loss (min) {np.round(np.min(history['val_loss']), 4)} @ epoch {np.argmin(history['val_loss']) + 1}\")\n",
    "    \n",
    "    ################### highest accuracy model ###################\n",
    "    print(\"\\n#### results for highest accuracy model ####\")\n",
    "    # Get predictions from lowest loss model and convert back to labels\n",
    "    y_pred = highest_accuracy_model.predict(X_test)\n",
    "    y_pred = ohe.inverse_transform(y_pred)\n",
    "    \n",
    "    # Get accuracy score and print it\n",
    "    accuracy =  accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy of: {np.round(accuracy, 4)}\")\n",
    "    \n",
    "    # Show CM\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    ################### lowest loss model ###################\n",
    "    print(\"\\n#### results for lowest loss model ####\")\n",
    "    # Get predictions from lowest loss model and convert back to labels\n",
    "    y_pred = lowest_loss_model.predict(X_test)\n",
    "    y_pred = ohe.inverse_transform(y_pred)\n",
    "    \n",
    "    # Get accuracy score and print it\n",
    "    accuracy =  accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy of: {np.round(accuracy, 4)}\")\n",
    "    \n",
    "    # Show CM\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    ################### cleanup ###################\n",
    "    # remove unused vars\n",
    "    del best_base_model_filename\n",
    "    del lowest_loss_model\n",
    "    del highest_accuracy_model\n",
    "    del f\n",
    "    del X_test\n",
    "    del y_test\n",
    "    del history\n",
    "    del ohe\n",
    "    del y_pred\n",
    "    del accuracy\n",
    "\n",
    "# Remove unsused variables\n",
    "del subject_ids_to_test\n",
    "del subject_id\n",
    "del baseline\n",
    "del end_offset\n",
    "del start_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97904430",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Subsampling electrodes\n",
    "\n",
    "According to Kaya et al., the authors of the used dataset, the channels of most interest are C3, Cz, C4, T3 and T4.\n",
    "According to our research these are: T3, C3, Cz, C4 and T4 for primary motor cortex but also P3 and P4 for poor spatial resolution inclusion and F3, Fz and F4 for the premotor cortex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_channel_list = [\"T3\", \"C3\", \"Cz\", \"C4\", \"T4\", \"P3\", \"P4\", \"F3\", \"Fz\", \"F4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0000c54",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### CSP + LDA\n",
    "\n",
    "#### Same session\n",
    "\n",
    "Results using all channels:\n",
    "\n",
    "| **Subject** | **CSP + LDA: cross validation accuracy** | **CSP + LDA: test split accuracy** | **Config**                                          |\n",
    "|-------------|------------------------------------------|------------------------------------|-----------------------------------------------------|\n",
    "| B           | 0.6615 +- 0.0504                         | 0.6094                             | 6 CSP components \\| LDA SVD solver with 0.0001 tol  |\n",
    "| C           | 0.7144 +- 0.0341                         | 0.7240                             | 10 CSP components \\| LDA SVD solver with 0.0001 tol |\n",
    "| E           | 0.7342 +- 0.0171                         | 0.7277                             | 10 CSP components \\| LDA SVD solver with 0.0001 tol |\n",
    "\n",
    "Results using subsampled channels:\n",
    "\n",
    "| **Subject** | **CSP + LDA: cross validation accuracy** | **CSP + LDA: test split accuracy** | **Config**                                          |\n",
    "|-------------|------------------------------------------|------------------------------------|-----------------------------------------------------|\n",
    "| B           | 0.5781 +- 0.0212                         | 0.6302                             | 6 CSP components \\| LDA SVD solver with 0.0001 tol  |\n",
    "| C           | 0.6232 +- 0.0118                         | 0.5833                             | 10 CSP components \\| LDA SVD solver with 0.0001 tol |\n",
    "| E           | 0.5864 +- 0.0153                         | 0.5759                             | 10 CSP components \\| LDA SVD solver with 0.0001 tol |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38b807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# SAME SESSION TEST\n",
    "####################################################\n",
    "\n",
    "# Configure global parameters for all experiments\n",
    "start_offset = -1 # One second before visual queue\n",
    "end_offset = 1 # One second after visual queue\n",
    "baseline = (None, 0) # Baseline correction using data before the visual queue\n",
    "filter_lower_bound = 2 # Filter out any frequency below this \n",
    "filter_upper_bound = 32 # Filter out any frequency above this\n",
    "\n",
    "subject_ids_to_test = [\"B\", \"C\", \"E\"] # Subjects with three recordings\n",
    "best_found_csp_components = [6, 10 , 10]\n",
    "best_found_solver = [\"svd\", \"svd\", \"svd\"]\n",
    "best_found_tol = [0.0001, 0.0001, 0.0001]\n",
    "\n",
    "# Loop over all found results\n",
    "for i in range(len(subject_ids_to_test)):\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"####################################################\")\n",
    "    print(f\"# TEST RESULTS FOR SUBJECT {subject_ids_to_test[i]}\")\n",
    "    print(\"####################################################\")\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    ###########################################\n",
    "    # DATA\n",
    "    with io.capture_output():\n",
    "        # Get MNE raw object for latest recording of that subject\n",
    "        mne_raw = CLA_dataset.get_last_raw_mne_data_for_subject(subject_id= subject_ids_to_test[i])\n",
    "        \n",
    "        # Use only the channels of interst\n",
    "        mne_raw = mne_raw.pick_channels(mi_channel_list)\n",
    "        \n",
    "        # Get epochs for that MNE raw\n",
    "        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                             start_offset= start_offset,\n",
    "                                                             end_offset= end_offset,\n",
    "                                                             baseline= baseline)\n",
    "        \n",
    "        # Only keep epochs from the MI tasks\n",
    "        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "        \n",
    "        # Load epochs into memory\n",
    "        mne_epochs.load_data()\n",
    "        \n",
    "        # Get the labels\n",
    "        labels = mne_epochs.events[:, -1]\n",
    "        \n",
    "        # Use a fixed filter\n",
    "        mne_epochs.filter(l_freq= filter_lower_bound,\n",
    "                          h_freq= filter_upper_bound,\n",
    "                          picks= \"all\",\n",
    "                          phase= \"minimum\",\n",
    "                          fir_window= \"blackman\",\n",
    "                          fir_design= \"firwin\",\n",
    "                          pad= 'median', \n",
    "                          n_jobs= -1,\n",
    "                          verbose= False)\n",
    "        \n",
    "        # Get a half second window\n",
    "        mne_epochs_data = mne_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Create a test and train split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(mne_epochs_data,\n",
    "                                                        labels,\n",
    "                                                        test_size = 0.2,\n",
    "                                                        shuffle= True,\n",
    "                                                        stratify= labels,                                                    \n",
    "                                                        random_state= 1998)\n",
    "    \n",
    "    ###########################################\n",
    "    # CLASSIFIER\n",
    "    \n",
    "    # Make the classifier\n",
    "    csp = CSP(norm_trace=False,\n",
    "              component_order=\"mutual_info\",\n",
    "              cov_est= \"epoch\",\n",
    "              n_components= best_found_csp_components[i])\n",
    "    \n",
    "    lda = LinearDiscriminantAnalysis(shrinkage= None,\n",
    "                                     priors=[1/3, 1/3, 1/3],\n",
    "                                     solver= best_found_solver[i],\n",
    "                                     tol= best_found_tol[i])\n",
    "    \n",
    "    # Configure the pipeline\n",
    "    pipeline = Pipeline([('CSP', csp), ('LDA', lda)])\n",
    "    \n",
    "    # Get the cross val scores\n",
    "    cv = StratifiedKFold(n_splits=4,\n",
    "                         shuffle= True,\n",
    "                         random_state= 2022)\n",
    "    \n",
    "    with io.capture_output():\n",
    "        cv_results = cross_val_score(pipeline, X_train, y_train,\n",
    "                                     cv=cv, n_jobs=-1)\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    with io.capture_output():\n",
    "        pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Get accuracy for single fit\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    accuracy =  accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print cross val results\n",
    "    print(f\"Validation accuracy (CV) of {np.round(np.mean(cv_results), 4)} +- {np.round(np.std(cv_results), 4)}\")\n",
    "    \n",
    "    # Print accuracy results and CM\n",
    "    print(f\"Test accuracy for subject {subject_ids_to_test[i]}: {np.round(accuracy, 4)}\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "    plt.show()\n",
    "        \n",
    "    # plot CSP patterns estimated on train data for visualization\n",
    "    pipeline['CSP'].plot_patterns(mne_raw.info, ch_type='eeg', units='Patterns (AU)', size=1.5)    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Remove unsused variables\n",
    "del accuracy\n",
    "del baseline\n",
    "del best_found_csp_components\n",
    "del best_found_solver\n",
    "del best_found_tol\n",
    "del csp\n",
    "del cv\n",
    "del cv_results\n",
    "del end_offset\n",
    "del filter_lower_bound\n",
    "del filter_upper_bound\n",
    "del i\n",
    "del labels\n",
    "del lda\n",
    "del mne_epochs\n",
    "del mne_raw\n",
    "del pipeline\n",
    "del start_offset\n",
    "del subject_ids_to_test\n",
    "del X_test\n",
    "del X_train\n",
    "del y_pred\n",
    "del y_test\n",
    "del y_train\n",
    "del mne_epochs_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eedc181",
   "metadata": {},
   "source": [
    "#### New session\n",
    "\n",
    "Results using all channels:\n",
    "\n",
    "| **Subject** | **CSP + LDA: cross validation accuracy** | **CSP + LDA: test split accuracy** | **Config**                                          |\n",
    "|-------------|------------------------------------------|------------------------------------|-----------------------------------------------------|\n",
    "| B           | 0.6615 +- 0.0504                         | 0.6094                             | 6 CSP components \\| LDA SVD solver with 0.0001 tol  |\n",
    "| C           | 0.7144 +- 0.0341                         | 0.7240                             | 10 CSP components \\| LDA SVD solver with 0.0001 tol |\n",
    "| E           | 0.7342 +- 0.0171                         | 0.7277                             | 10 CSP components \\| LDA SVD solver with 0.0001 tol |\n",
    "\n",
    "Results using subsampled channels:\n",
    "\n",
    "| **Subject** | **CSP + LDA: cross validation accuracy** | **CSP + LDA: test split accuracy** | **Config**                                          |\n",
    "|-------------|------------------------------------------|------------------------------------|-----------------------------------------------------|\n",
    "| B           | 0.5781 +- 0.0212                         | 0.6302                             | 6 CSP components \\| LDA SVD solver with 0.0001 tol  |\n",
    "| C           | 0.6232 +- 0.0118                         | 0.5833                             | 10 CSP components \\| LDA SVD solver with 0.0001 tol |\n",
    "| E           | 0.5864 +- 0.0153                         | 0.5759                             | 10 CSP components \\| LDA SVD solver with 0.0001 tol |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f6e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# NEW SESSION TEST\n",
    "####################################################\n",
    "\n",
    "# Configure global parameters for all experiments\n",
    "start_offset = -1 # One second before visual queue\n",
    "end_offset = 1 # One second after visual queue\n",
    "baseline = (None, 0) # Baseline correction using data before the visual queue\n",
    "filter_lower_bound = 2 # Filter out any frequency below this \n",
    "filter_upper_bound = 32 # Filter out any frequency above this\n",
    "\n",
    "subject_ids_to_test = [\"B\", \"C\", \"E\"] # Subjects with three recordings\n",
    "best_found_csp_components = [10, 10 , 10]\n",
    "best_found_solver = [\"svd\", \"svd\", \"svd\"]\n",
    "best_found_tol = [0.0001, 0.0001, 0.0001]\n",
    "\n",
    "# Loop over all found results\n",
    "for i in range(len(subject_ids_to_test)):\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"####################################################\")\n",
    "    print(f\"# TEST RESULTS FOR SUBJECT {subject_ids_to_test[i]}\")\n",
    "    print(\"####################################################\")\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    ###########################################\n",
    "    # TRAINING DATA\n",
    "    with io.capture_output():\n",
    "        # Get MNE raw object for latest recording of that subject\n",
    "        mne_raws = CLA_dataset.get_all_but_last_raw_mne_data_for_subject(subject_id= subject_ids_to_test[i])\n",
    "        \n",
    "        # Combine training data into singular mne raw\n",
    "        mne_raw = mne.concatenate_raws(mne_raws)\n",
    "        \n",
    "        # Delete raws as they are altered\n",
    "        del mne_raws\n",
    "        \n",
    "        # Use only the channels of interst\n",
    "        mne_raw = mne_raw.pick_channels(mi_channel_list)\n",
    "        \n",
    "        # Get epochs for that MNE raw\n",
    "        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                             start_offset= start_offset,\n",
    "                                                             end_offset= end_offset,\n",
    "                                                             baseline= baseline)\n",
    "        \n",
    "        # Only keep epochs from the MI tasks\n",
    "        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "        \n",
    "        # Load epochs into memory\n",
    "        mne_epochs.load_data()\n",
    "        \n",
    "        # Get the labels\n",
    "        y_train = mne_epochs.events[:, -1]\n",
    "        \n",
    "        # Use a fixed filter\n",
    "        mne_epochs.filter(l_freq= filter_lower_bound,\n",
    "                          h_freq= filter_upper_bound,\n",
    "                          picks= \"all\",\n",
    "                          phase= \"minimum\",\n",
    "                          fir_window= \"blackman\",\n",
    "                          fir_design= \"firwin\",\n",
    "                          pad= 'median', \n",
    "                          n_jobs= -1,\n",
    "                          verbose= False)\n",
    "        \n",
    "        # Get a half second window\n",
    "        X_train = mne_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "        \n",
    "        \n",
    "    \n",
    "    ################# TESTING DATA #################\n",
    "    with io.capture_output():\n",
    "        # Get MNE raw object for latest recording of that subject\n",
    "        mne_raw = CLA_dataset.get_last_raw_mne_data_for_subject(subject_id= subject_ids_to_test[i])\n",
    "        \n",
    "        # Use only the channels of interst\n",
    "        mne_raw = mne_raw.pick_channels(mi_channel_list)\n",
    "        \n",
    "        # Get epochs for that MNE raw\n",
    "        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                             start_offset= start_offset,\n",
    "                                                             end_offset= end_offset,\n",
    "                                                             baseline= baseline)\n",
    "        \n",
    "        # Only keep epochs from the MI tasks\n",
    "        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "        \n",
    "        # Load epochs into memory\n",
    "        mne_epochs.load_data()\n",
    "        \n",
    "        # Get the labels\n",
    "        y_test = mne_epochs.events[:, -1]\n",
    "        \n",
    "        # Use a fixed filter\n",
    "        mne_epochs.filter(l_freq= filter_lower_bound,\n",
    "                          h_freq= filter_upper_bound,\n",
    "                          picks= \"all\",\n",
    "                          phase= \"minimum\",\n",
    "                          fir_window= \"blackman\",\n",
    "                          fir_design= \"firwin\",\n",
    "                          pad= 'median', \n",
    "                          n_jobs= -1,\n",
    "                          verbose= False)\n",
    "        \n",
    "        # Get a half second window\n",
    "        X_test = mne_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    # CLASSIFIER\n",
    "    \n",
    "    # Make the classifier\n",
    "    csp = CSP(norm_trace=False,\n",
    "              component_order=\"mutual_info\",\n",
    "              cov_est= \"epoch\",\n",
    "              n_components= best_found_csp_components[i])\n",
    "    \n",
    "    lda = LinearDiscriminantAnalysis(shrinkage= None,\n",
    "                                     priors=[1/3, 1/3, 1/3],\n",
    "                                     solver= best_found_solver[i],\n",
    "                                     tol= best_found_tol[i])\n",
    "    \n",
    "    # Configure the pipeline\n",
    "    pipeline = Pipeline([('CSP', csp), ('LDA', lda)])\n",
    "    \n",
    "    # Get the cross val scores\n",
    "    cv = StratifiedKFold(n_splits=4,\n",
    "                         shuffle= True,\n",
    "                         random_state= 2022)\n",
    "    \n",
    "    with io.capture_output():\n",
    "        cv_results = cross_val_score(pipeline, X_train, y_train,\n",
    "                                     cv=cv, n_jobs=-1)\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    with io.capture_output():\n",
    "        pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Get accuracy for single fit\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    accuracy =  accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print cross val results\n",
    "    print(f\"Validation accuracy (CV) of {np.round(np.mean(cv_results), 4)} +- {np.round(np.std(cv_results), 4)}\")\n",
    "    \n",
    "    # Print accuracy results and CM\n",
    "    print(f\"Test accuracy for subject {subject_ids_to_test[i]}: {np.round(accuracy, 4)}\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "    plt.show()\n",
    "        \n",
    "    # plot CSP patterns estimated on train data for visualization\n",
    "    pipeline['CSP'].plot_patterns(mne_raw.info, ch_type='eeg', units='Patterns (AU)', size=1.5)    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Remove unsused variables\n",
    "del accuracy\n",
    "del baseline\n",
    "del best_found_csp_components\n",
    "del best_found_solver\n",
    "del best_found_tol\n",
    "del csp\n",
    "del cv\n",
    "del cv_results\n",
    "del end_offset\n",
    "del filter_lower_bound\n",
    "del filter_upper_bound\n",
    "del i\n",
    "del lda\n",
    "del mne_epochs\n",
    "del mne_raw\n",
    "del pipeline\n",
    "del start_offset\n",
    "del subject_ids_to_test\n",
    "del X_test\n",
    "del X_train\n",
    "del y_pred\n",
    "del y_test\n",
    "del y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747a0316",
   "metadata": {},
   "source": [
    "#### New session\n",
    "\n",
    "Results using all channels:\n",
    "\n",
    "| **Subject**      | **CSP + LDA: cross validation accuracy** | **CSP + LDA: test split accuracy** | **Config**                                   |\n",
    "|------------------|------------------------------------------|------------------------------------|----------------------------------------------|\n",
    "| B (Train on C&E) | 0.5662 +- 0.0129                         | 0.3961                             | 10 CSP components \\| SVD LDA with 0.0001 tol |\n",
    "| C (Train on B&E) | 0.4781 +- 0.0185                         | 0.4731                             | 10 CSP components \\| lsqr LDA                |\n",
    "| E (Train on B&C) | 0.5567 +- 0.0287                         | 0.4098                             | 10 CSP components \\| SVD LDA with 0.0001 tol |\n",
    "\n",
    "Results using subsampled channels:\n",
    "\n",
    "| **Subject**      | **CSP + LDA: cross validation accuracy** | **CSP + LDA: test split accuracy** | **Config**                                   |\n",
    "|------------------|------------------------------------------|------------------------------------|----------------------------------------------|\n",
    "| B (Train on C&E) | 0.5406 +- 0.0128                         | 0.375                              | 10 CSP components \\| SVD LDA with 0.0001 tol |\n",
    "| C (Train on B&E) | 0.4548 +- 0.0071                         | 0.3556                             | 10 CSP components \\| lsqr LDA                |\n",
    "| E (Train on B&C) | 0.4813 +- 0.0219                         | 0.4188                             | 10 CSP components \\| SVD LDA with 0.0001 tol |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c613a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# NEW SESSION TEST\n",
    "####################################################\n",
    "\n",
    "# Configure global parameters for all experiments\n",
    "start_offset = -1 # One second before visual queue\n",
    "end_offset = 1 # One second after visual queue\n",
    "baseline = (None, 0) # Baseline correction using data before the visual queue\n",
    "filter_lower_bound = 2 # Filter out any frequency below this \n",
    "filter_upper_bound = 32 # Filter out any frequency above this\n",
    "\n",
    "subject_ids_to_test = [\"B\", \"C\", \"E\"] # Subjects with three recordings\n",
    "best_found_csp_components = [10, 10 , 10]\n",
    "best_found_solver = [\"svd\", \"svd\", \"svd\"]\n",
    "best_found_tol = [0.0001, 0.0001, 0.0001]\n",
    "\n",
    "# Loop over all found results\n",
    "for i in range(len(subject_ids_to_test)):\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"####################################################\")\n",
    "    print(f\"# TEST RESULTS FOR SUBJECT {subject_ids_to_test[i]}\")\n",
    "    print(\"####################################################\")\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    ###########################################\n",
    "    # TRAINING DATA\n",
    "    with io.capture_output():\n",
    "        # Determine the train subjects\n",
    "        train_subjects = copy.deepcopy(subject_ids_to_test)\n",
    "        train_subjects.remove(subject_ids_to_test[i])\n",
    "        \n",
    "        mne_raws = []\n",
    "        \n",
    "        # Get all training data\n",
    "        for train_subject in train_subjects:\n",
    "            mne_raws.extend(CLA_dataset.get_all_raw_mne_data_for_subject(subject_id= train_subject))\n",
    "        \n",
    "        # Combine training data into singular mne raw\n",
    "        mne_raw = mne.concatenate_raws(mne_raws)\n",
    "        \n",
    "        # Delete raws as they are altered\n",
    "        del mne_raws\n",
    "        del train_subject\n",
    "        del train_subjects\n",
    "        \n",
    "        # Use only the channels of interst\n",
    "        mne_raw = mne_raw.pick_channels(mi_channel_list)\n",
    "        \n",
    "        # Get epochs for that MNE raw\n",
    "        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                             start_offset= start_offset,\n",
    "                                                             end_offset= end_offset,\n",
    "                                                             baseline= baseline)\n",
    "        \n",
    "        # Only keep epochs from the MI tasks\n",
    "        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "        \n",
    "        # Load epochs into memory\n",
    "        mne_epochs.load_data()\n",
    "        \n",
    "        # Get the labels\n",
    "        y_train = mne_epochs.events[:, -1]\n",
    "        \n",
    "        # Use a fixed filter\n",
    "        mne_epochs.filter(l_freq= filter_lower_bound,\n",
    "                          h_freq= filter_upper_bound,\n",
    "                          picks= \"all\",\n",
    "                          phase= \"minimum\",\n",
    "                          fir_window= \"blackman\",\n",
    "                          fir_design= \"firwin\",\n",
    "                          pad= 'median', \n",
    "                          n_jobs= -1,\n",
    "                          verbose= False)\n",
    "        \n",
    "        # Get a half second window\n",
    "        X_train = mne_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "        \n",
    "        \n",
    "    \n",
    "    ################# TESTING DATA #################\n",
    "    with io.capture_output():\n",
    "        # Get MNE raw object for latest recording of that subject\n",
    "        mne_raw = CLA_dataset.get_last_raw_mne_data_for_subject(subject_id= subject_ids_to_test[i])\n",
    "        \n",
    "        # Use only the channels of interst\n",
    "        mne_raw = mne_raw.pick_channels(mi_channel_list)\n",
    "        \n",
    "        # Get epochs for that MNE raw\n",
    "        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                             start_offset= start_offset,\n",
    "                                                             end_offset= end_offset,\n",
    "                                                             baseline= baseline)\n",
    "        \n",
    "        # Only keep epochs from the MI tasks\n",
    "        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "        \n",
    "        # Load epochs into memory\n",
    "        mne_epochs.load_data()\n",
    "        \n",
    "        # Get the labels\n",
    "        y_test = mne_epochs.events[:, -1]\n",
    "        \n",
    "        # Use a fixed filter\n",
    "        mne_epochs.filter(l_freq= filter_lower_bound,\n",
    "                          h_freq= filter_upper_bound,\n",
    "                          picks= \"all\",\n",
    "                          phase= \"minimum\",\n",
    "                          fir_window= \"blackman\",\n",
    "                          fir_design= \"firwin\",\n",
    "                          pad= 'median', \n",
    "                          n_jobs= -1,\n",
    "                          verbose= False)\n",
    "        \n",
    "        # Get a half second window\n",
    "        X_test = mne_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "    \n",
    "    \n",
    "    ###########################################\n",
    "    # CLASSIFIER\n",
    "    \n",
    "    # Make the classifier\n",
    "    csp = CSP(norm_trace=False,\n",
    "              component_order=\"mutual_info\",\n",
    "              cov_est= \"epoch\",\n",
    "              n_components= best_found_csp_components[i])\n",
    "    \n",
    "    lda = LinearDiscriminantAnalysis(shrinkage= None,\n",
    "                                     priors=[1/3, 1/3, 1/3],\n",
    "                                     solver= best_found_solver[i],\n",
    "                                     tol= best_found_tol[i])\n",
    "    \n",
    "    # Configure the pipeline\n",
    "    pipeline = Pipeline([('CSP', csp), ('LDA', lda)])\n",
    "    \n",
    "    # Get the cross val scores\n",
    "    cv = StratifiedKFold(n_splits=4,\n",
    "                         shuffle= True,\n",
    "                         random_state= 2022)\n",
    "    \n",
    "    with io.capture_output():\n",
    "        cv_results = cross_val_score(pipeline, X_train, y_train,\n",
    "                                     cv=cv, n_jobs=-1)\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    with io.capture_output():\n",
    "        pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Get accuracy for single fit\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    accuracy =  accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print cross val results\n",
    "    print(f\"Validation accuracy (CV) of {np.round(np.mean(cv_results), 4)} +- {np.round(np.std(cv_results), 4)}\")\n",
    "    \n",
    "    # Print accuracy results and CM\n",
    "    print(f\"Test accuracy for subject {subject_ids_to_test[i]}: {np.round(accuracy, 4)}\")\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "    plt.show()\n",
    "        \n",
    "    # plot CSP patterns estimated on train data for visualization\n",
    "    pipeline['CSP'].plot_patterns(mne_raw.info, ch_type='eeg', units='Patterns (AU)', size=1.5)    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Remove unsused variables\n",
    "del accuracy\n",
    "del baseline\n",
    "del best_found_csp_components\n",
    "del best_found_solver\n",
    "del best_found_tol\n",
    "del csp\n",
    "del cv\n",
    "del cv_results\n",
    "del end_offset\n",
    "del filter_lower_bound\n",
    "del filter_upper_bound\n",
    "del i\n",
    "del lda\n",
    "del mne_epochs\n",
    "del mne_raw\n",
    "del pipeline\n",
    "del start_offset\n",
    "del subject_ids_to_test\n",
    "del X_test\n",
    "del X_train\n",
    "del y_pred\n",
    "del y_test\n",
    "del y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdad109",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Using more training data\n",
    "\n",
    "During the experiments only the data of three participants were used as these were the only participants with 3 recorded session for hte CLA paradigm of the open-source data.\n",
    "To determine if having more data will yield an improvement in the intersubject perfomance of the DL algorithms, we perform this experiment were all possible CLA data is used.\n",
    "We also can use one subject as validation subject so that we can actually test for the performance on a new subject.\n",
    "\n",
    "<hr>\n",
    "\n",
    "### EEGNet: new subject\n",
    "\n",
    "Results for EEGNet were:\n",
    "\n",
    "| **Subject**   | **EEGNet: best validation accuracy** | **EEGNet: best validation loss** | **EEGNet: test split accuracy (best acc model)** | **EEGNet: test split accuracy (best loss model)** |\n",
    "|---------------|--------------------------------------|----------------------------------|--------------------------------------------------|---------------------------------------------------|\n",
    "| B (Train C&E) | 0.7654 @ epoch 92                    | 0.5768 @ epoch 135               | 0.6469                                           | 0.6479                                            |\n",
    "| C (Train B&E) | 0.6993 @ epoch 458                   | 0.6921 @ epoch 344               | 0.5892                                           | 0.5996                                            |\n",
    "| E (Train B&C) | 0.7454 @ epoch 889                   | 0.6425 @ epoch 1196              | 0.6419                                           | 0.6262                                            |\n",
    "\n",
    "Result using more training data:\n",
    "\n",
    "> TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ee4ed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################\n",
      "# TRAINING FOR SUBJECT B\n",
      "####################################################\n",
      "\n",
      "Using data from all participants except testing subject B\n",
      "Shape of all training data (epochs, channels, samples): (8629, 21, 100)\n",
      "Shape of all val data (epochs, channels, samples): (958, 21, 100)\n",
      "Epoch 1/5\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0888 - accuracy: 0.3987\n",
      "Epoch 1: val_loss improved from inf to 1.08729, saving model to saved_variables/8/moredata/EEGNet/newsubject/subjectB\\trained_model_lowest_loss_model.hdf5\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50522, saving model to saved_variables/8/moredata/EEGNet/newsubject/subjectB\\trained_model_highest_acc_model.hdf5\n",
      "34/34 [==============================] - 6s 121ms/step - loss: 1.0888 - accuracy: 0.3987 - val_loss: 1.0873 - val_accuracy: 0.5052\n",
      "Epoch 2/5\n",
      "34/34 [==============================] - ETA: 0s - loss: 1.0428 - accuracy: 0.4647\n",
      "Epoch 2: val_loss improved from 1.08729 to 1.07566, saving model to saved_variables/8/moredata/EEGNet/newsubject/subjectB\\trained_model_lowest_loss_model.hdf5\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.50522 to 0.54384, saving model to saved_variables/8/moredata/EEGNet/newsubject/subjectB\\trained_model_highest_acc_model.hdf5\n",
      "34/34 [==============================] - 3s 100ms/step - loss: 1.0428 - accuracy: 0.4647 - val_loss: 1.0757 - val_accuracy: 0.5438\n",
      "Epoch 3/5\n",
      "33/34 [============================>.] - ETA: 0s - loss: 1.0144 - accuracy: 0.4911\n",
      "Epoch 3: val_loss improved from 1.07566 to 1.05954, saving model to saved_variables/8/moredata/EEGNet/newsubject/subjectB\\trained_model_lowest_loss_model.hdf5\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.54384 to 0.57829, saving model to saved_variables/8/moredata/EEGNet/newsubject/subjectB\\trained_model_highest_acc_model.hdf5\n",
      "34/34 [==============================] - 1s 42ms/step - loss: 1.0131 - accuracy: 0.4923 - val_loss: 1.0595 - val_accuracy: 0.5783\n",
      "Epoch 4/5\n",
      "33/34 [============================>.] - ETA: 0s - loss: 0.9896 - accuracy: 0.5182\n",
      "Epoch 4: val_loss improved from 1.05954 to 1.04430, saving model to saved_variables/8/moredata/EEGNet/newsubject/subjectB\\trained_model_lowest_loss_model.hdf5\n",
      "\n",
      "Epoch 4: val_accuracy did not improve from 0.57829\n",
      "34/34 [==============================] - 1s 28ms/step - loss: 0.9900 - accuracy: 0.5171 - val_loss: 1.0443 - val_accuracy: 0.5480\n",
      "Epoch 5/5\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.9683 - accuracy: 0.5392\n",
      "Epoch 5: val_loss improved from 1.04430 to 1.02821, saving model to saved_variables/8/moredata/EEGNet/newsubject/subjectB\\trained_model_lowest_loss_model.hdf5\n",
      "\n",
      "Epoch 5: val_accuracy did not improve from 0.57829\n",
      "34/34 [==============================] - 1s 24ms/step - loss: 0.9683 - accuracy: 0.5392 - val_loss: 1.0282 - val_accuracy: 0.5564\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# TRAINING EEGNET ON EACH SUBJECT AND TWO SESSIONS\n",
    "####################################################\n",
    "\n",
    "# Configure global parameters for all experiments\n",
    "subject_ids_to_test = [\"B\", \"C\", \"E\"] # Subjects with three recordings\n",
    "start_offset = -1 # One second before visual queue\n",
    "end_offset = 1 # One second after visual queue\n",
    "baseline = None # Baseline correction using data before the visual queue\n",
    "\n",
    "do_experiment = True # Long experiment disabled per default\n",
    "\n",
    "# Create the TensorFlow Keras model\n",
    "keras_eegnet_model = EEGNet(\n",
    "        nb_classes = 3, # int, number of classes to classify. \n",
    "        Chans = 21, # number of channels in the EEG data. \n",
    "        Samples = 100, # number of time points in the EEG data. (default: 128)\n",
    "        dropoutRate = 0.5, # dropout fraction. (default: 0.5)\n",
    "        kernLength = 50, # length of temporal convolution in first layer. Suggested: half the sampling rate. (default: 64)\n",
    "        F1 = 8, # number of temporal filters. (default: 8)\n",
    "        F2 = 16, # number of pointwise filters. (default: 16)\n",
    "        D = 2, # number of spatial filters to learn within each temporal convolution. (default: 2)\n",
    "        norm_rate = 0.25, # Normalisation rate. (default: 0.25)\n",
    "        dropoutType = 'SpatialDropout2D' # Either SpatialDropout2D or Dropout, passed as a string. (default: Dropout)\n",
    "        )\n",
    "\n",
    "if do_experiment:\n",
    "        # Loop over all subjects and perform the grid search for finding the best parameters\n",
    "        for subject_id in subject_ids_to_test[:1]:\n",
    "                print(\"\")\n",
    "                print(\"####################################################\")\n",
    "                print(f\"# TRAINING FOR SUBJECT {subject_id}\")\n",
    "                print(\"####################################################\")\n",
    "                print(\"\")\n",
    "                ###################### PREPARE DATA ######################\n",
    "                \n",
    "                with io.capture_output():\n",
    "                    # Get all training data\n",
    "                    training_data, val_data = CLA_dataset.get_data_from_all_but_one_subject(test_subject = \"C\",\n",
    "                                                                                            val_subject = \"D\")\n",
    "                    \n",
    "                    # Get epochs for that training MNE raw\n",
    "                    mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(training_data,\n",
    "                                                                         start_offset= start_offset,\n",
    "                                                                         end_offset= end_offset,\n",
    "                                                                         baseline= baseline)\n",
    "                    \n",
    "                    # Only keep epochs from the MI tasks\n",
    "                    mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "                    \n",
    "                    # Load epochs into memory\n",
    "                    mne_epochs.load_data()\n",
    "                    \n",
    "                    # Get epochs for that validation MNE raw\n",
    "                    mne_epochs_val = CLA_dataset.get_usefull_epochs_from_raw(val_data,\n",
    "                                                                             start_offset= start_offset,\n",
    "                                                                             end_offset= end_offset,\n",
    "                                                                             baseline= baseline)\n",
    "                    \n",
    "                    # Only keep epochs from the MI tasks\n",
    "                    mne_epochs_val = mne_epochs_val['task/neutral', 'task/left', 'task/right']\n",
    "                    \n",
    "                    # Load epochs into memory\n",
    "                    mne_epochs_val.load_data()\n",
    "                    \n",
    "                # Show training data\n",
    "                print(f\"Using data from all participants except testing subject {subject_id}\")\n",
    "                \n",
    "                # Get the labels\n",
    "                labels = mne_epochs.events[:, -1]\n",
    "                labels_val = mne_epochs_val.events[:, -1]\n",
    "                \n",
    "                # Convert the labels to OHE labels as needed for Keras\n",
    "                labels = labels.reshape(-1, 1)\n",
    "                ohe = OneHotEncoder()\n",
    "                labels = ohe.fit_transform(labels).toarray()\n",
    "                \n",
    "                \n",
    "                labels_val = labels_val.reshape(-1, 1)\n",
    "                labels_val = ohe.transform(labels_val).toarray()\n",
    "                \n",
    "                # Get a half second window\n",
    "                mne_epochs_data = mne_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "                mne_epochs_data_val = mne_epochs_val.get_data(tmin= 0.1, tmax= 0.6)\n",
    "                \n",
    "                # Fix scaling sensitivity as MNE stores as data * 10e-6\n",
    "                mne_epochs_data = mne_epochs_data * 1000000\n",
    "                mne_epochs_data_val = mne_epochs_data_val * 1000000\n",
    "                        \n",
    "                # Store the OHE encoder to enable same conversion later\n",
    "                with open(f\"saved_variables/8/moredata/EEGNet/newsubject/subject{subject_id}/ohe-encoder.pickle\", 'wb') as file:\n",
    "                        pickle.dump(ohe, file)\n",
    "                        \n",
    "                print(f\"Shape of all training data (epochs, channels, samples): {np.shape(mne_epochs_data)}\")\n",
    "                print(f\"Shape of all val data (epochs, channels, samples): {np.shape(mne_epochs_data_val)}\")\n",
    "                \n",
    "                \n",
    "                ###################### PREPARE MODEL ######################\n",
    "                \n",
    "                # Names for model\n",
    "                best_base_model_filename = f\"saved_variables/8/moredata/EEGNet/newsubject/subject{subject_id}/trained_model\" \n",
    "                tensorboard_name = f\"paper-notebook8_eegnet_newsubject_moredata_subject{subject_id}\" # log name for tensorboard\n",
    "                \n",
    "                # Create copy of the model that needs training\n",
    "                trained_model = keras.models.clone_model(keras_eegnet_model)\n",
    "                \n",
    "                # Compile the model so it can be fitted (loss and optimizer from EEGNet paper)\n",
    "                trained_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
    "                \n",
    "                # Train model with GPU\n",
    "                # NOTE: change GPU to CPU if nog GPU present\n",
    "                with tf.device('/gpu:0'):\n",
    "                        history = trained_model.fit(\n",
    "                                x= mne_epochs_data,\n",
    "                                y= labels,\n",
    "                                batch_size= 256, # Default: 32 - further improved since more data available anyway\n",
    "                                epochs= 5, # Default: 500 (EEGNet paper)\n",
    "                                verbose= 1, # 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "                                callbacks= [TF_tools.tensorboard_callback(log_name= tensorboard_name),\n",
    "                                            TF_tools.lowest_loss_model_save_callback(filepath= best_base_model_filename),\n",
    "                                            TF_tools.highest_accuracy_model_save_callback(filepath= best_base_model_filename)],\n",
    "                                validation_data= (mne_epochs_data_val, labels_val),\n",
    "                                shuffle= True,\n",
    "                                sample_weight= None, # Can be interesting due to time series\n",
    "                                use_multiprocessing=True, # Done for faster speed\n",
    "                                workers= 4 # Done for faster speed\n",
    "                                )\n",
    "                        \n",
    "                # Store the fitting history\n",
    "                with open(f\"saved_variables/8/moredata/EEGNet/newsubject/subject{subject_id}/fitting_history.pickle\", 'wb') as file:\n",
    "                        pickle.dump(history.history, file)\n",
    "                \n",
    "                # Delete vars after singular experiment\n",
    "                del training_data\n",
    "                del mne_epochs\n",
    "                del mne_epochs_data\n",
    "                del trained_model\n",
    "                del best_base_model_filename\n",
    "                del tensorboard_name\n",
    "                del labels\n",
    "                del file\n",
    "                del history\n",
    "                del ohe\n",
    "                del labels_val\n",
    "                del mne_epochs_data_val\n",
    "                del mne_epochs_val\n",
    "                del val_data\n",
    "                \n",
    "    \n",
    "        # Delete vars after all experiments\n",
    "        del subject_id\n",
    "        \n",
    "# Del global vars\n",
    "del subject_ids_to_test\n",
    "del baseline\n",
    "del do_experiment\n",
    "del end_offset\n",
    "del start_offset\n",
    "del keras_eegnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "163db913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################\n",
      "# RESULTS FOR SUBJECT B\n",
      "####################################################\n",
      "\n",
      "#### results of training ####\n",
      "Best training accuracy (max) 0.5392 @ epoch 5\n",
      "Best training loss (min) 0.9683 @ epoch 5\n",
      "\n",
      "Best validation accuracy (max) 0.5783 @ epoch 3\n",
      "Best validation loss (min) 1.0282 @ epoch 5\n",
      "\n",
      "#### results for highest accuracy model ####\n",
      "Accuracy of: 0.5438\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEKCAYAAACGzUnMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAi7UlEQVR4nO3deXxU9bnH8c+TEEIIS9hFQEFBELmKSC0WxX2j3oK9rm1vqdWi1qq1tlZrb7m1V+u1Vdtq1XKrV6xWxaWtVSsiVRGvoEitbC4oyr4kEJawmEye+8c5gYhJZibM5MycfN+v13ll5jdnznlmXsmT33J+v2PujohIHBVEHYCISLYowYlIbCnBiUhsKcGJSGwpwYlIbCnBiUhsKcGJSCTMrJ+ZvWhmi8xsoZldGZZ3NbPpZvZ++LNLWG5m9hszW2Jmb5vZiGTnUIITkajUAFe7+1BgFHCZmQ0FrgVmuPsgYEb4HOB0YFC4TQTuTnYCJTgRiYS7r3b3eeHjLcBioA8wDpgS7jYFGB8+Hgc84IHZQJmZ9W7qHG2yEXhzde9a6P37FUUdRs56f2HHqEPIeZ5IRB1CTttBFZ/4TtubY5x6fKlXbEjte37z7Z0LgR31iia7++Q99zOz/sDhwBygl7uvDl9aA/QKH/cBltd724qwbDWNyKkE179fEa9P6xd1GDlr7CHHRx1CzktUVkYdQk6bU/vCXh+jfEOCOdP6prRvUe8Pdrj7yKb2MbMOwBPAd919s9nu/OvubmbNnk+aUwlORPKBk/DajBzJzIoIkttD7v5kWLzWzHq7++qwCbouLF8J1K8B9Q3LGqU+OBFJiwO1eEpbUyyoqt0LLHb32+q99BQwIXw8AfhLvfKvh6Opo4BN9ZqyDVINTkTSVktGanCjgX8H5pvZW2HZj4CbgalmdiHwMXBO+NqzwFhgCbANuCDZCZTgRCQtjlOdgSaqu88CGhvwOLGB/R24LJ1zKMGJSFocSCRpfuYKJTgRSVuy/rVcoQQnImlxIJEnK4ErwYlI2jJzkUj2KcGJSFocVx+ciMSTO1TnR35TghORdBmJRq/uyC1KcCKSFgdqVYMTkbhSDU5EYim40FcJTkRiyIFqz491OpTgRCQtjpHIk4WIlOBEJG21riaqiMSQ+uBEJMaMhPrgRCSOghV9leBEJIbcjU+8MOowUqIEJyJpq1UfnIjEUTDIoCaqiMSSBhlEJKY0yCAisZbIkwt98yMNi0jOcIxqb5PSloyZ3Wdm68xsQb2y4WY228zeMrO5ZnZkWG5m9hszW2Jmb5vZiGTHV4ITkbTUDTKksqXgfuC0PcpuAX7q7sOBn4TPAU4HBoXbRODuZAdXghORtDhGwlPbkh7LfSaw4TOngE7h487AqvDxOOABD8wGysysd1PHVx+ciKQtjUGG7mY2t97zye4+Ocl7vgtMM7NfElTCvhCW9wGW19tvRVi2urEDtdoEt25lEb+4cj8q1xeBOWO/VsGZF5WzeWMhN13Sn7Ur2tKr7ydc/7uP6FiWwB3u/o8+vP73TrQrqeXq25cx6NDtUX+MFlXasZorb3iX/QdW4W786j8G884/OwNw5oTlfOuaDzhv9BfYXNk24kijMWX2QrZvLaS2FhI1xuVjB3PAIdu44uYVtC2uJVFj3Pmjvrz7VmnUoe4Vd9K5TKTc3UemeYpLgavc/QkzOwe4FzgpzWMAWUxwZnYfcAawzt2HZes8zVXYxpn4k1UMOnQ727YW8J3TDmLEmC1Mf7Qrhx+9hXMvX8ejd/Tk0Tt7ctGPV/PG3zuycmkx//vqYt6Z1547ruvLb555P+qP0aIuvm4Jb87qyk1XDaNNUS3F7RIAdN9nByNGb2DdquKII4zeNWcPZPPG3X9WF12/mgdv24e5L3bicyds5sLrV3HN2YMijHDvBYMMWZ2qNQG4Mnz8GPD78PFKoF+9/fqGZY3KZh/c/Xy28zBndOtVs6sG1r5DLf0G7qR8dRGvTevMSecEXQInnbOB154LaiivTevMSWdtwAwOPmIbVZsKqVjbeirA7TvUMOyITUx7IujyqKkuoGpLEQATf7iE+249kDy52XmLcofSjsE/gtKOCTasLYo4oszI4CBDQ1YBx4aPTwDqahJPAV8PR1NHAZvcvdHmKWSxBufuM82sf7aOn0lrlrflgwUlDBmxjY3lRXTrVQNA1541bCwPfiHL1xTRY9/qXe/pvm81FWt27xt3+/TdzqaNRVx14zscMLiKJQs7cM/Ngzh81EYq1haz9N0OUYcYPTduevgDcHjmwW787aHu3DOpDzf98QO+9R+rMIOrxuV37Q2CGlymFrw0s4eB4wj66lYAk4BvAb82szbADoIRU4BngbHAEmAbcEGy47eeKkgjtlcV8LOL+nPJDSsp7Vj7qdfMwEzVEoDCQmfgwVu458ZBvDu/Exdf+z5f/fZH/MvISq7/1mFRh5cTvnfmQCrWtKVzt2pufuQDli9pxzFfrOR3/9mHWc+WMeZfN/K9W5dx7XkDow51r2VqLqq7n9/IS0c0sK8Dl6Vz/MgvEzGzieHFfHPXVyRa9Nw11fCzi/pzwpc3cvTYTQB06V69q+lZsbYNZd2CGlr3fapZv2p386J8VRHd9qn+7EFjqnxtMeVri3l3fjB6P+v5HgwcuoVefXbw2yff4H+ff43uvXbym8ffpEv3nRFHG42KNcHgyqaKIl79W2eGDN/GyWdvYNazQTfHzL+WcdDwbVGGmBHBfVELUtqiFnkE7j7Z3Ue6+8ge3VpujSl3uO3q/eg3aCf/dvH6XeWjTtnMC1O7AvDC1K4cdeqm3eWPd8UdFr/ZnvadEq2meQqwsbyY9Wva0ad/8Ac6fNRGlizqyFfGjOaCU47iglOOonxtMVecdQQby1vfYENxSYKS0sSux0ccu4WP3m1HxdoiDj1qKwDDj97KqqVx+G6CO9unskWt1TZRF75eyozHuzLg4O1cetJgAC64bhXnfmctN17Sn+ce6UbPPsFlIgBHnriZN2Z05IIvHExxeJlIa3PPTQO55r8X0abIWbOiHbf/eEjUIeWMLj1qmHTvUgAKC+HFP5cx96VObP9BAZfesJLCNs4nOwr41TX9khwp9wW3DcyPBS/NszT0Vb/zEFgLTHL3e5t6z8jD2vnr0/L/FyBbxh5yfNQh5LxEZWXUIeS0ObUvsNk37FXVqs8hZf7tqUentO+Phz3zZjOug8uYbI6iNtZ5KCJ5TuvBiUgsBevBRd+/lgolOBFJk1b0FZGYCi4TUQ1ORGKoBeaiZowSnIikTfdkEJFYCpZLUhNVRGJKfXAiEkvBaiJqoopIDAVTtZTgRCSWVIMTkRjTTAYRiSWNoopIrKmJKiKxlMl7MmSbEpyIpMWBGtXgRCSu8qWJmh9Rikju8KCJmsqWjJndZ2brzGzBHuWXm9k7ZrbQzG6pV36dmS0xs3fN7NRkx1cNTkTSkuEFL+8H7gQeqCsws+OBccBh7r7TzHqG5UOB84BDgH2BF8zsIHdv9HZ8qsGJSNoyVYNz95nAhj2KLwVudved4T7rwvJxwCPuvtPdlxLcAPrIpo6vBCciaalb8DLFBNe97r7H4TYxyeEBDgKOMbM5ZvaymX0uLO8DLK+334qwrFFqoopIWhyjpjblulF5M+6q1QboCowCPgdMNbMD0jzGrgOJiKQly1O1VgBPenBP09fNrJbg9qMrgfr3Fe0bljVKTVQRSY9nrg+uEX8Gjgcws4OAtkA58BRwnpkVm9kAYBDwelMHUg1ORNKSyZvO1L9BvJmtACYB9wH3hZeOfAJMCGtzC81sKrAIqAEua2oEFZTgRKQZMpXgmrhB/Nca2f9G4MZUj68EJyJpcYxE6oMMkVKCE5G0aT04EYkld910RkRizJXgRCSetB6ciMSYanDNsGhVD0ZOujTqMHKW/aEi6hByXrfxW6IOIbd5Bg7hkKhVghORmNIoqojEkqMmqojElgYZRCTGPAN9eS1BCU5E0qYmqojEUjCKqrmoIhJTaqKKSGypiSoiseSYEpyIxFeetFCV4EQkTQ6uqVoiEldqoopIbOX9KKqZ3UETTW13vyIrEYlITovLXNS5LRaFiOQPBzJ328D7gDOAde4+bI/XrgZ+CfRw93IzM+DXwFhgG/ANd5/X1PEbTXDuPmWPk7V3923N+xgiEicZbKLeD9wJPFC/0Mz6AacAy+oVn05ws+dBwOeBu8OfjUo638LMjjKzRcA74fPDzOyu1OMXkXgxvDa1LRl3nwlsaOCl24Fr+HQ32TjgAQ/MBsrMrHdTx09lQtmvgFOBijCgfwJjUnifiMSVp7g1g5mNA1aGuaa+PsDyes9XhGWNSmkU1d2XB83fXRKpvE9EYsjTGmTobmb1+/Mnu/vkxnY2s/bAjwiap3stlQS33My+ALiZFQFXAoszcXIRyVOp187K3X1kGkc+EBgA/DOsVPUF5pnZkcBKoF+9ffuGZY1KpYl6CXAZQVVwFTA8fC4irZaluKXH3ee7e0937+/u/QmaoSPcfQ3wFPB1C4wCNrn76qaOl7QG5+7lwFfTjlRE4qs2M4cxs4eB4wiasiuASe5+byO7P0twicgSgstELkh2/KQJzswOILj2ZBRBxfQ14Cp3/zCVDyAiMZPB6+Dc/fwkr/ev99hJs/WYShP1j8BUoDewL/AY8HA6JxGReHFPbYtaKgmuvbv/wd1rwu1BoF22AxORHJbFy0Qyqam5qF3Dh38zs2uBRwhCPpegLSwirVUM5qK+SZDQ6j7JxfVec+C6bAUlIrnNcqB2loqm5qIOaMlARCRPuEGcFrw0s2HAUOr1vbn7A42/Q0RiLd9rcHXMbBLBdSpDCfreTgdmscfsfxFpRfIkwaUyinoWcCKwxt0vAA4DOmc1KhHJbfk+ilrPdnevNbMaM+sErOPT88Hy1k/GvcjRB33MxqoSzr3rXAA6lezg52dPp3fZFlZXduTaqaewZUfxrvcM3Xcd9130J65//CRmLDowqtBbROmv1lD0RhW1nQvZfFd/AEoeKqd42iZqOwe/Otu/3o3qz3XANifo8PNVtHl/BztP7MS2S3tFGHk0prw6n21VBdQmjETCuOKMgxlw8DauuGkZ7UoTrF1RzC1XDGDb1sKoQ907GbzQN9tSSXBzzawM+B+CkdWtBLMZmhQuWPcA0IvgK5ns7r9ufqiZ99e3BvPo68O44cy/7yr7xtH/4PUP+zJl1uFMOPoffOOYf3DH9FEAFFgtl588mzkf9I0q5Ba186RO7DijjNLb1nyqfMf4Luz4ctdPlXlbY/vXulP48U4KP97ZkmHmlB+eO5jNG3f/WV11y8f8z3/1Zf6cjpxyTjlnXbyGB25tcoWfvJAvo6hJm6ju/m13r3T3e4CTgQlhUzWZGuBqdx9KMM3rMjMbunfhZtY/Pt6XzduLP1V27JCPePqtgwB4+q2DOG7I0l2vnfv5Bfx98QFsqCpp0TijUjOsPd4xxdpGuwJqDinB2+bHf/aW0mfADubP6QDAvFc6MXpsZbQBZUqeNFEbTXBmNmLPDegKtAkfN8ndV9etl+7uWwiWWMr5f11dS7dTsbUUgIqt7elauh2AHh23ctzBS3n8jUOiDC8nFD9dSafvfETpr9ZgW7U0YB13uOnB97jjmcWc/pX1AHz8XglHnbIJgDFf3EiP3p9EGWLGmKe2Ra2pJuqtTbzmwAmpnsTM+gOHA3MaeG0iMBGgqEOXVA/ZQmzXP6GrT/8/7pg+Km/uJpQtO8aWsf28bmBQ8mAF7X+/nqrv7hN1WDnh6n8bTMXatnTuVs3PH3qf5UvacdsP+nPpT5fxlStXM3t6Z2qqY/L7kyd/B01d6Ht8Jk5gZh2AJ4DvuvvmBs4zGZgM0L5Hv8hz/oaqErp1qKJiayndOlSxMWyOHrzvem46azoAZe13MHrQMmpqC3j5ndZ1PbR32f0rs/PUznT4aZPrDbYqFWvbArCpooj/m1bG4OFVPDF5H67/WtDl0WfADo48YVOUIWZGjjQ/U5HVGz+HKwA/ATzk7k9m81yZ8vK7/Tlj+HtMmXU4Zwx/j5ff6Q/AuF/tXhJv0vi/M+u9/VtdcgOwDTV41+DXpui1rST2L07yjtahuCRBQQFsryqkuCTBiGM289Cve9O5WzWbKoowc86/YjXPPNgj6lAzo7UnuPAehvcCi939tmydZ2/ceNYLHNF/FWXtd/DM9/7A5JdGMuWVw/n5OdMZN2Ixqys7ct1jJ0cdZmRKb1lN0fxt2OYEZRM+ZNtXu1E0fxuFH+4Eg9qeRVR9Z/flIJ2/+SG2rRarcdrOrmLzz/pQu1/rSIBdetTwk8kfAFDYxnnxz1158+XOjPvmWv7160F/3KvPlfH81G5RhpkxlqEFL7PNPEuLNpnZ0cArwHx2r//5I3dvdCWS9j36+ZAvX5WVeOLAxlVEHULO6zZe67A2ZXbNNDbXbtirDrTifv2875Wp/Z1++IOr30zzngwZlcpULSNYsvwAd7/BzPYD9nH315t6n7vPojmLsotITsuVEdJUpDJV6y7gKKBuaeEtwG+zFpGI5D631LaIpdIH93l3H2Fm/wBw941m1jbLcYlILsuTGlwqCa7azAoJP5KZ9SBj99QRkXyUL03UVBLcb4A/AT3N7EaC1UV+nNWoRCR3ef6MoqYyF/Uh4Brg58BqYLy7P5btwEQkh2VoLqqZ3Wdm68xsQb2yX5jZO2b2tpn9KVzso+6168xsiZm9a2anJjt+0gQXjppuA/5KcGfpqrBMRFqrzE22vx84bY+y6cAwdz8UeI/w/i/hYh3nAYeE77kr7D5rVCpN1GfYffOZdsAA4N3wJCLSCmWqD87dZ4Zz1euXPV/v6WyCbjGAccAj7r4TWGpmS4AjaWL5tqQJzt3/pf7zcCWRb6cUvYi0dt3NbG6955PD+eep+ibwaPi4D0HCq7OCJCsUpT1Vy93nmdnn032fiMRI6jW48ubOZDCz6wnWlXyoOe+H1GYyfK/e0wJgBLCquScUkTzXAqOoZvYN4AzgRN89n3Qln75dQt+wrFGpzGToWG8rJuiTG5dmvCISJ1lc0dfMTiO4cuNL7r6t3ktPAeeZWbGZDQAGAU1OGW2yBheOUHR09+83L1QRiRsjc4MMZvYwwW1Ju5vZCmASwahpMTA9mArPbHe/xN0XmtlUYBFB0/Uyd29ySelGE5yZtXH3GjMbnZmPIiKxkblR1PMbKL63if1vBG5M9fhN1eBeJ+hve8vMngIeA6rqnSgvFrAUkQzLo9VEUhlFbQdUENyDoe56OAeU4ERaqzyZqtVUgusZjqAuYHdiq5Mn+VtEsiEONbhCoAMNL1qZJx9PRLIiTzJAUwlutbvf0GKRiEh+iMldtaJfjlNEclIcmqgntlgUIpJf8j3BufuGlgxERPJHvix4mdUbP4tIDMWkD05E5DOM/OmgV4ITkfSpBicicRWHUVQRkYYpwYlILOXRbQOV4EQkfarBiUhcqQ9OROJLCS59BQko3pQn31wEOpzxXtQh5LyRbzW5gnWrN//8zPx9qQYnIvHkxGLBSxGRz8jkTWeyTQlORNKXJwkulfuiioh8irmntCU9jtl9ZrbOzBbUK+tqZtPN7P3wZ5ew3MzsN2a2xMzeNrMRyY6vBCci6Un1ps+p1fLuB07bo+xaYIa7DwJmhM8BTie42fMgYCJwd7KDK8GJSNrMU9uScfeZwJ5rT44DpoSPpwDj65U/4IHZQJmZ9W7q+OqDE5G0pTFVq7uZza33fLK7T07ynl7uvjp8vAboFT7uAyyvt9+KsGw1jVCCE5H0pT7IUO7uI5t9Gnc3a/6YrZqoIpKeFJune3Epydq6pmf4c11YvhLoV2+/vmFZo5TgRCR9mRtkaMhTwITw8QTgL/XKvx6Opo4CNtVryjZITVQRSUsmL/Q1s4eB4wj66lYAk4CbgalmdiHwMXBOuPuzwFhgCbANuCDZ8ZXgRCRtVpuZDOfu5zfy0mduW+ruDlyWzvGV4EQkPbqrlojEmVb0FZH4Ug1OROJKq4mISDw5kMJE+lygBCciaVMfnIjEkha8FJH4clcTVUTiSzU4EYkvJTgRiSvV4EQknhxI5EeGU4ITkbSpBici8aVRVBGJK9XgRCSetFySiMSVAaZBBhGJq1TuWp8LlOBEJD1qouafs8fM50tHLcaAp2YPYerLhwJw1jEL+PLRC6mtNf5v0X7c9ddR0QYaoSlzFrF9ayG1tZCoMS4//SB+dM9H9D1wJwClnRJUbS7k2ycPjjjSlrF0klE50yjqCsOeCJbXWHKNseMjAyCxBQo7wrCptdRUwpLvF1C1ELp/ydn/ujzJEA3SXFTMrB0wEygOz/O4u0/K1vn2xoB9NvCloxZz0W1nUpMo5NaLn+XVhfvTq2wrRw/7iAm3nEV1opCyDtujDjVy15x9IJs37P61uemS/rseT/zJKqq2tJ47UXb/ktPzPGfpj3d/5oG37K7eLLvVKOwQlFsx9Lmslu1LjO1LIgg2w/JlFDWbv407gRPc/TBgOHBaeC/DnNO/10YWftyTndVFJGoLeOuD3hx76FLGj17EgzOGU50oBKBya0nEkeYyZ8yXKnnxz12iDqTFdDwC2nRq+DV32PC80e20IBMUlkDHw6GgbQsGmE11K4ok2yKWtQTnga3h06Jwi/4TN+DDNV057IA1dGq/g+Kiao4auoxeZVvZr+cmDjtgNZOv+hN3fucphvRbl/xgcebGTQ9/yJ3PvcfpX6341EvDPl/FxvVtWLW0OKLgcsvWeVDUDdrtH3UkWeDBKGoqWzJmdpWZLTSzBWb2sJm1M7MBZjbHzJaY2aNm1ux/C1ntgzOzQuBNYCDwW3efk83zNdfHa7vw0Izh3H7pM+z4pA3vr+xOrRuFBbV0ar+TibeP5+D91vOzb7zA2T87n2CgvPX53viBVKwponO3am5+5EOWLylmwZygDXb8+Epe+nNZtAHmkIrndtfeYikDH83M+gBXAEPdfbuZTQXOI7i58+3u/oiZ3QNcCNzdnHNktcPE3RPuPhzoCxxpZsP23MfMJprZXDObW72zKpvhNOnpOUO48NZ/47I7xrFlW1uWrStjXWUpL789ADAWL+uJu1FWuiOyGKNWsaYIgE0VRbz6XGeGHL4NgIJCZ/TYTbz8VFmE0eUOr4GNM4yup8Y3wZl7SlsK2gAlZtYGaA+sBk4AHg9fnwKMb26cLdIj7O6VwIvAaQ28NtndR7r7yKLi0pYIp0F1Awi9yrZw7KEfMX3eQF6ZP4ARg1YB0K9HJW0KE1RWtYssxigVlyQoKU3senzEsVv46J3guxhxzBaWLymmfHVcOpj2zuY5UDIA2vaKOpIsSr0PrntdBSbcJu4+hK8EfgksI0hsmwhafJXuXhPutgLo09wwszmK2gOodvdKMysBTgb+O1vn21s3XfA8nUp3UJMo4NbHR7N1ezFPzxnMj85/iT/8cCrVNYX81x+Pp7U2T7v0qGHSvR8BUNjGefFPXZj7UtDDfuy41tk8/eBaY8tco6YS3jqlgD6XOj3OdCqeM7o20Dz95+kFJKrAq2Hji8bgu2spObDl495rDqR+05lydx/Z0Atm1gUYBwwAKoHHaKAStDey2QfXG5gS9sMVAFPd/eksnm+vfPuOcZ8pq0kUcsODJ0YQTe5Zs6yYSxu5vu3Wq/Zr4Whyw4E3N3zF6wE/a7hpdtjf8uRWVEkYKTc/kzkJWOru6wHM7ElgNFBmZm3CWlxfYGVzT5C1BOfubwOHZ+v4IhKh2owk62XAKDNrD2wHTgTmEnRnnQU8AkwA/tLcE7SeqzJFJDPqmqipbE0dJriq4nFgHjCfIB9NBn4IfM/MlgDdgHubG6qmaolI2jI12T6c3bTnDKcPgSMzcXwlOBFJXw7MUkiFEpyIpCk3pmGlQglORNKju2qJSJxpwUsRiS8lOBGJJQdqleBEJJY0yCAicaYEJyKx5EAiP+bVKsGJSJocXAlOROJKTVQRiSWNoopIrKkGJyKxpQQnIrHkDolE1FGkRAlORNKnGpyIxJYSnIjEk2sUVURiysF1oa+IxJamaolILLln6raBWafbBopI+txT25IwszIze9zM3jGzxWZ2lJl1NbPpZvZ++LNLc8NUghORtHltbUpbCn4NPOfuQ4DDgMXAtcAMdx8EzAifN4sSnIikKcXaW5IanJl1BsYQ3tjZ3T9x90pgHDAl3G0KML65kSrBiUh66ibbp7JBdzObW2+bWO9IA4D1wP+a2T/M7PdmVgr0cvfV4T5rgF7NDVWDDCKSFgc89ala5e4+spHX2gAjgMvdfY6Z/Zo9mqPu7mbW7IvuVIMTkfR4uOBlKlvTVgAr3H1O+PxxgoS31sx6A4Q/1zU3VCU4EUmb13pKW5PHcF8DLDezwWHRicAi4ClgQlg2AfhLc+NUE1VE0pe5mQyXAw+ZWVvgQ+ACgorXVDO7EPgYOKe5BzfPoUmzZrae4APliu5AedRB5DB9P8nl2ne0v7v32JsDmNlzBJ8rFeXuftrenG9v5FSCyzVmNreJDtJWT99PcvqOoqU+OBGJLSU4EYktJbimTY46gByn7yc5fUcRUh+ciMSWanAiEltKcCISW0pwDTCz+8xsnZktiDqWXGRm/czsRTNbZGYLzezKqGPKJWbWzsxeN7N/ht/PT6OOqbVSH1wDzGwMsBV4wN2HRR1PrgnnB/Z293lm1hF4Exjv7osiDi0nmJkBpe6+1cyKgFnAle4+O+LQWh3V4Brg7jOBDVHHkavcfbW7zwsfbyFYpLBPtFHlDg9sDZ8WhZtqEhFQgpO9Ymb9gcOBOUl2bVXMrNDM3iJYCWN6vRUzpAUpwUmzmVkH4Angu+6+Oep4com7J9x9ONAXONLM1NURASU4aZawb+kJ4CF3fzLqeHJVuAT3i0BkE85bMyU4SVvYiX4vsNjdb4s6nlxjZj3MrCx8XAKcDLwTaVCtlBJcA8zsYeA1YLCZrQjXpZLdRgP/DpxgZm+F29iog8ohvYEXzext4A2CPrinI46pVdJlIiISW6rBiUhsKcGJSGwpwYlIbCnBiUhsKcGJSGwpweURM0uEl2QsMLPHzKz9XhzrfjM7K3z8ezMb2sS+x5nZF5pxjo/M7DN3X2qsfI99tjb1egP7/6eZfT/dGCXelODyy3Z3Hx6ucPIJcEn9F82sWfe5dfeLkqwEchyQdoITiZoSXP56BRgY1q5eMbOngEXhJO9fmNkbZva2mV0MwewDM7vTzN41sxeAnnUHMrOXzGxk+Pg0M5sXrmU2I5xMfwlwVVh7PCa8Uv+J8BxvmNno8L3dzOz5cA203wOW7EOY2Z/N7M3wPRP3eO32sHyGmfUIyw40s+fC97xiZkMy8m1KLOnO9nkorKmdDjwXFo0Ahrn70jBJbHL3z5lZMfCqmT1PsOLHYGAo0AtYBNy3x3F7AP8DjAmP1dXdN5jZPcBWd/9luN8fgdvdfZaZ7QdMAw4GJgGz3P0GM/sikMoMkG+G5ygB3jCzJ9y9AigF5rr7VWb2k/DY3yG4icsl7v6+mX0euAs4oRlfo7QCSnD5pSRcggeCGty9BE3H1919aVh+CnBoXf8a0BkYBIwBHnb3BLDKzP7ewPFHATPrjuXuja2JdxIwNJiSCkCncGWRMcCXw/c+Y2YbU/hMV5jZmeHjfmGsFUAt8GhY/iDwZHiOLwCP1Tt3cQrnkFZKCS6/bA+X4Nkl/EOvql8EXO7u0/bYL5NzRQuAUe6+o4FYUmZmxxEky6PcfZuZvQS0a2R3D89bued3INIY9cHFzzTg0nA5I8zsIDMrBWYC54Z9dL2B4xt472xgjJkNCN/bNSzfAnSst9/zwOV1T8xsePhwJvCVsOx0oEuSWDsDG8PkNoSgBlmnAKirhX6FoOm7GVhqZmeH5zAzOyzJOaQVU4KLn98T9K/Ns+CmOb8jqKn/CXg/fO0BgtVSPsXd1wMTCZqD/2R3E/GvwJl1gwzAFcDIcBBjEbtHc39KkCAXEjRVlyWJ9TmgjZktBm4mSLB1qggWilxA0Md2Q1j+VeDCML6FwLgUvhNppbSaiIjElmpwIhJbSnAiEltKcCISW0pwIhJbSnAiEltKcCISW0pwIhJb/w/YpJ04KDV3SQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#### results for lowest loss model ####\n",
      "Accuracy of: 0.5885\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "####################################################\n",
      "# RESULTS FOR SUBJECT C\n",
      "####################################################\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at saved_variables/8/moredata/EEGNet/newsubject/subjectC/trained_model_lowest_loss_model.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\fast_files\\GitHub\\VUB-BCI-thesis\\code\\paper-notebooks\\8-further-improvements.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/fast_files/GitHub/VUB-BCI-thesis/code/paper-notebooks/8-further-improvements.ipynb#X63sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m best_base_model_filename \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msaved_variables/8/moredata/EEGNet/newsubject/subject\u001b[39m\u001b[39m{\u001b[39;00msubject_id\u001b[39m}\u001b[39;00m\u001b[39m/trained_model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/fast_files/GitHub/VUB-BCI-thesis/code/paper-notebooks/8-further-improvements.ipynb#X63sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# Open models from file\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/fast_files/GitHub/VUB-BCI-thesis/code/paper-notebooks/8-further-improvements.ipynb#X63sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m lowest_loss_model \u001b[39m=\u001b[39m TF_tools\u001b[39m.\u001b[39;49mload_lowest_loss_model(filepath\u001b[39m=\u001b[39;49m best_base_model_filename)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/fast_files/GitHub/VUB-BCI-thesis/code/paper-notebooks/8-further-improvements.ipynb#X63sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m highest_accuracy_model \u001b[39m=\u001b[39m TF_tools\u001b[39m.\u001b[39mload_highest_accuracy_model(filepath\u001b[39m=\u001b[39m best_base_model_filename)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/fast_files/GitHub/VUB-BCI-thesis/code/paper-notebooks/8-further-improvements.ipynb#X63sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Get test data session\u001b[39;00m\n",
      "File \u001b[1;32mc:\\fast_files\\GitHub\\VUB-BCI-thesis\\code\\paper-notebooks\\../utils\\TF_tools.py:70\u001b[0m, in \u001b[0;36mload_lowest_loss_model\u001b[1;34m(filepath, custom_objects)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[39mLoads a previously stored lowest loss model.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39mSuffixes provided path with '_lowest_loss_model.hdf5'.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39mFor custom models, it might be needed to supply extra custom objects.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     69\u001b[0m filepath \u001b[39m=\u001b[39m filepath \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_lowest_loss_model.hdf5\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m keras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(filepath, custom_objects\u001b[39m=\u001b[39;49mcustom_objects)\n",
      "File \u001b[1;32mc:\\Users\\Lennert\\.conda\\envs\\bci-master-thesis\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Lennert\\.conda\\envs\\bci-master-thesis\\lib\\site-packages\\keras\\saving\\save.py:204\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    203\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 204\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    206\u001b[0m   \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    207\u001b[0m     \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(filepath_str, \u001b[39mcompile\u001b[39m, options)\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at saved_variables/8/moredata/EEGNet/newsubject/subjectC/trained_model_lowest_loss_model.hdf5"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# RESULTS\n",
    "####################################################\n",
    "\n",
    "# Configure global parameters for all experiments\n",
    "subject_ids_to_test = [\"B\", \"C\", \"E\"] # Subjects with three recordings\n",
    "start_offset = -1 # One second before visual queue\n",
    "end_offset = 1 # One second after visual queue\n",
    "baseline = None # Baseline correction using data before the visual queue\n",
    "\n",
    "# Loop over all found results\n",
    "for subject_id in subject_ids_to_test:\n",
    "    print()\n",
    "    print(\"####################################################\")\n",
    "    print(f\"# RESULTS FOR SUBJECT {subject_id}\")\n",
    "    print(\"####################################################\")\n",
    "    print()\n",
    "    \n",
    "    ################### load data ###################\n",
    "    # Names for model\n",
    "    best_base_model_filename = f\"saved_variables/8/moredata/EEGNet/newsubject/subject{subject_id}/trained_model\"\n",
    "    \n",
    "    # Open models from file\n",
    "    lowest_loss_model = TF_tools.load_lowest_loss_model(filepath= best_base_model_filename)\n",
    "    highest_accuracy_model = TF_tools.load_highest_accuracy_model(filepath= best_base_model_filename)\n",
    "    \n",
    "    # Get test data session\n",
    "    with io.capture_output():\n",
    "        # Get test data\n",
    "        mne_raw = CLA_dataset.get_last_raw_mne_data_for_subject(subject_id)\n",
    "        \n",
    "        # Get epochs for test MNE raw\n",
    "        mne_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw,\n",
    "                                                             start_offset= start_offset,\n",
    "                                                             end_offset= end_offset,\n",
    "                                                             baseline= baseline)\n",
    "        \n",
    "        # Only keep epochs from the MI tasks\n",
    "        mne_epochs = mne_epochs['task/neutral', 'task/left', 'task/right']\n",
    "\n",
    "        # Load epochs into memory\n",
    "        mne_epochs.load_data()\n",
    "        \n",
    "        # Get the labels\n",
    "        y_test = mne_epochs.events[:, -1]\n",
    "        \n",
    "        # Get a half second window\n",
    "        X_test = mne_epochs.get_data(tmin= 0.1, tmax= 0.6)\n",
    "        \n",
    "        # Fix scaling sensitivity as MNE stores as data * 10e-6\n",
    "        X_test = X_test * 1000000\n",
    "        \n",
    "        # Delete resedual vars for training data\n",
    "        del mne_raw\n",
    "        del mne_epochs\n",
    "        \n",
    "    # Get OHE from file\n",
    "    with open(f\"saved_variables/8/moredata/EEGNet/newsubject/subject{subject_id}/ohe-encoder.pickle\", 'rb') as f:\n",
    "        ohe = pickle.load(f)\n",
    "        \n",
    "    # Get history from file\n",
    "    with open(f\"saved_variables/8/moredata/EEGNet/newsubject/subject{subject_id}/fitting_history.pickle\", 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "    \n",
    "    ################### history stats ###################\n",
    "    print(\"#### results of training ####\")\n",
    "    print(f\"Best training accuracy (max) {np.round(np.max(history['accuracy']), 4)} @ epoch {np.argmax(history['accuracy']) + 1}\")\n",
    "    print(f\"Best training loss (min) {np.round(np.min(history['loss']), 4)} @ epoch {np.argmin(history['loss']) + 1}\")\n",
    "    print()\n",
    "    print(f\"Best validation accuracy (max) {np.round(np.max(history['val_accuracy']), 4)} @ epoch {np.argmax(history['val_accuracy']) + 1}\")\n",
    "    print(f\"Best validation loss (min) {np.round(np.min(history['val_loss']), 4)} @ epoch {np.argmin(history['val_loss']) + 1}\")\n",
    "    \n",
    "    ################### highest accuracy model ###################\n",
    "    print(\"\\n#### results for highest accuracy model ####\")\n",
    "    # Get predictions from lowest loss model and convert back to labels\n",
    "    y_pred = highest_accuracy_model.predict(X_test)\n",
    "    y_pred = ohe.inverse_transform(y_pred)\n",
    "    \n",
    "    # Get accuracy score and print it\n",
    "    accuracy =  accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy of: {np.round(accuracy, 4)}\")\n",
    "    \n",
    "    # Show CM\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    ################### lowest loss model ###################\n",
    "    print(\"\\n#### results for lowest loss model ####\")\n",
    "    # Get predictions from lowest loss model and convert back to labels\n",
    "    y_pred = lowest_loss_model.predict(X_test)\n",
    "    y_pred = ohe.inverse_transform(y_pred)\n",
    "    \n",
    "    # Get accuracy score and print it\n",
    "    accuracy =  accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy of: {np.round(accuracy, 4)}\")\n",
    "    \n",
    "    # Show CM\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "    plt.show()\n",
    "    \n",
    "    ################### cleanup ###################\n",
    "    # remove unused vars\n",
    "    del best_base_model_filename\n",
    "    del lowest_loss_model\n",
    "    del highest_accuracy_model\n",
    "    del f\n",
    "    del X_test\n",
    "    del y_test\n",
    "    del history\n",
    "    del ohe\n",
    "    del y_pred\n",
    "    del accuracy\n",
    "\n",
    "# Remove unsused variables\n",
    "del subject_ids_to_test\n",
    "del subject_id\n",
    "del baseline\n",
    "del end_offset\n",
    "del start_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d19dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f92ed28e6a5fe026f22555c18fed88052bb861e5576fb72d2ac78e2247fef331"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
