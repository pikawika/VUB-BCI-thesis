{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337221df",
   "metadata": {},
   "source": [
    "# Deep Learning based classification\n",
    "\n",
    "In the previous notebooks `4-CSP-based-classification` and `5-CSP-params-new-subject`, we used CSP as a way to engineer feautures from raw EEG data and used common ML classifiers to use those features for classification.\n",
    "This had very varying results.\n",
    "As said by Kostas et al ([2021](https://doi.org/10.3389/fnhum.2021.653659)): \n",
    ">Deep Neural Network (DNN) models used for classifying EEG data thus need to both develop useful features from EEG signals and subsequently classify those features.\n",
    ">This frames both the promise and the challenge of using DNNs for supervised EEG classification. \n",
    ">On the one hand, it promises to almost entirely circumvent the need for feature engineering, but on the other hand, both feature discovery and classification need to be learned from a limited supply of (relevant) high-dimensional data.\n",
    "\n",
    "\n",
    "In this notebook we will explore 3 common Deep Learnging (DL) algorithms for EEG classifications: [EEGNet V2](http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta), [DeepConvNet](https://doi.org/10.1002/hbm.23730) and [ShallowConvNet](https://doi.org/10.1002/hbm.23730).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5341c6d",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- Checking requirements\n",
    "  - Correct anaconda environment\n",
    "  - Correct module access\n",
    "  - Correct file access\n",
    "- Loading in data\n",
    "- EEGNet\n",
    "- ShallowConvNet (TODO)\n",
    "- DeepConvNet (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292165d3",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Checking requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f55ad17",
   "metadata": {},
   "source": [
    "### Correct anaconda environment\n",
    "\n",
    "The `bci-master-thesis` anaconda environment should be active to ensure proper support. Installation instructions are available on [the GitHub repository of the BCI master thesis project](https://www.github.com/pikawika/bci-master-thesis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334d5fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active environment: bci-master-thesis\n",
      "Correct environment: True\n",
      "\n",
      "Python version: 3.8.10\n",
      "Correct Python version: True\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CHECKING FOR RIGHT ANACONDA ENVIRONMENT\n",
    "####################################################\n",
    "\n",
    "import os\n",
    "from platform import python_version\n",
    "from pathlib import Path\n",
    "from copy import copy\n",
    "\n",
    "print(f\"Active environment: {os.environ['CONDA_DEFAULT_ENV']}\")\n",
    "print(f\"Correct environment: {os.environ['CONDA_DEFAULT_ENV'] == 'bci-master-thesis'}\")\n",
    "print(f\"\\nPython version: {python_version()}\")\n",
    "print(f\"Correct Python version: {python_version() == '3.8.10'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22166668",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Correct module access\n",
    "\n",
    "The following codeblock will load in all required modules and show if the versions match those that are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab632204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNE version (1.0.2 recommended): 1.0.2\n",
      "PyRieMann version (0.2.7 recommended): 0.2.7\n",
      "Numpy version (1.21.5 recommended): 1.21.5\n",
      "Pandas version (1.4.1 recommended): 1.4.1\n",
      "Scikit-learn version (1.0.2 recommended): 1.0.2\n",
      "TensorFlow version (2.8.0 recommended): 2.8.0\n",
      "Keras version (2.8.0 recommended): 2.8.0\n",
      "Pickle version (4.0 recommended): 4.0\n",
      "Matplotlib version (3.5.1 recommended): 3.5.1\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# LOADING MODULES\n",
    "####################################################\n",
    "\n",
    "# Load util function file\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "import CLA_dataset\n",
    "\n",
    "# Load EEGModels\n",
    "from EEGModels import EEGNet, ShallowConvNet, DeepConvNet\n",
    "\n",
    "# IO functions\n",
    "from IPython.utils import io\n",
    "\n",
    "# Set logging level for MNE before loading MNE\n",
    "os.environ['MNE_LOGGING_LEVEL'] = 'WARNING'\n",
    "\n",
    "# Modules tailored for EEG data\n",
    "import mne; print(f\"MNE version (1.0.2 recommended): {mne.__version__}\")\n",
    "\n",
    "import pyriemann as prm; print(f\"PyRieMann version (0.2.7 recommended): {prm.__version__}\")\n",
    "\n",
    "# Data manipulation modules\n",
    "import numpy as np; print(f\"Numpy version (1.21.5 recommended): {np.__version__}\")\n",
    "import pandas as pd; print(f\"Pandas version (1.4.1 recommended): {pd.__version__}\")\n",
    "\n",
    "# ML libraries\n",
    "import sklearn;  print(f\"Scikit-learn version (1.0.2 recommended): {sklearn.__version__}\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Deep Learning libraries\n",
    "import tensorflow as tf;  print(f\"TensorFlow version (2.8.0 recommended): {tf.__version__}\")\n",
    "\n",
    "import keras; print(f\"Keras version (2.8.0 recommended): {keras.__version__}\")\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Storing files\n",
    "import pickle;  print(f\"Pickle version (4.0 recommended): {pickle.format_version}\")\n",
    "\n",
    "# Plotting\n",
    "import matplotlib; print(f\"Matplotlib version (3.5.1 recommended): {matplotlib.__version__}\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813bb5de",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Correct file access\n",
    "\n",
    "As mentioned, this experimental notebook uses a database provided by [Kaya et al](https://doi.org/10.1038/sdata.2018.211). The CLA dataset in particular. Instructions on where to get the data are available on [the GitHub repository of the BCI master thesis project](https://www.github.com/pikawika/bci-master-thesis). These instructions are under `bci-master-thesis/code/data/CLA/README.md`. FIF files from this same dataset are also made available in [the GitHub repository of the BCI master thesis project](https://www.github.com/pikawika/bci-master-thesis). A check on the availability of these two datasets is performed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caa1d182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Matlab CLA file access: True\n",
      "Full MNE CLA file access: True\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CHECKING FILE ACCESS\n",
    "####################################################\n",
    "\n",
    "# Use util to determine if we have access\n",
    "print(\"Full Matlab CLA file access: \" + str(CLA_dataset.check_matlab_files_availability()))\n",
    "print(\"Full MNE CLA file access: \" + str(CLA_dataset.check_mne_files_availability()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a71dde",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Checking TensorFlow GPU support\n",
    "\n",
    "If you want to use TensorFlow with GPU acceleration, the below codeblock can help you gather insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8d50f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "\n",
      "\n",
      "Num CPUs Available:  1\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "print(\"\\n\\nNum CPUs Available: \", len(tf.config.list_physical_devices('CPU')))\n",
    "print(tf.config.list_physical_devices('CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1629ba2",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## Loading in data\n",
    "\n",
    "In this step, we load the data.\n",
    "The loaded data is that of a specific subject and thus can exist of multiple MNE RAW objects.\n",
    "This list of objects is provided as well as a singular one, namely the first of the list.\n",
    "\n",
    "Remember the meaning of the markers:\n",
    "- 0: “blank” or nothing is displayed in eGUI\n",
    "    - Can be seen as a break between stimuli, thus random EEG data that should probably be ignored\n",
    "- 1: Left hand action\n",
    "    - EEG data for MI of the left hand\n",
    "- 2: Right hand action\n",
    "    - EEG data for MI of the right hand\n",
    "- 3: Passive/neutral\n",
    "    - EEG data for MI of neither left nor right hand but 'focused'\n",
    "- 91: inter-session rest break period\n",
    "- 92: experiment end\n",
    "- 99: initial relaxation period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "399f5c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MNE raws for subject C: 3 files.\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# LOADING RAW MNE DATA AND EPOCS\n",
    "####################################################\n",
    "\n",
    "# The previous notebooks used subject C (best) as well as B and E (worse).\n",
    "subject = \"C\"\n",
    "\n",
    "# Load RAW MNE files and select first as singular MNE file\n",
    "mne_raws = CLA_dataset.get_raw_mne_data_for_subject(subject)\n",
    "mne_raw = mne_raws[0]\n",
    "print(f\"Loaded MNE raws for subject {subject}: {len(mne_raws)} files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26506383",
   "metadata": {},
   "source": [
    "<hr> <hr>\n",
    "\n",
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49eec473",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Global vars\n",
    "####################################################\n",
    "\n",
    "def tensorboard_callback(log_name: str):\n",
    "    return tf.keras.callbacks.TensorBoard('./logs/' + log_name,\n",
    "                                          update_freq=\"batch\",\n",
    "                                          profile_batch=0)\n",
    "\n",
    "def lowest_loss_model_save_callback(filepath: str):\n",
    "    filepath = filepath + \"_lowest_loss_model.hdf5\"\n",
    "    return ModelCheckpoint(filepath=filepath,\n",
    "                           monitor= 'val_loss',\n",
    "                           verbose=1, \n",
    "                           save_best_only=True,\n",
    "                           mode= 'min')\n",
    "    \n",
    "def load_lowest_loss_model(filepath: str):\n",
    "    filepath = filepath + \"_lowest_loss_model.hdf5\"\n",
    "    return keras.models.load_model(filepath)\n",
    "\n",
    "def highest_accuracy_model_save_callback(filepath: str):\n",
    "    filepath = filepath + \"_highest_acc_model.hdf5\"\n",
    "    return ModelCheckpoint(filepath=filepath,\n",
    "                           monitor= 'val_accuracy',\n",
    "                           verbose=1, \n",
    "                           save_best_only=True,\n",
    "                           mode= 'max')\n",
    "    \n",
    "def load_highest_accuracy_model(filepath: str):\n",
    "    filepath = filepath + \"_highest_acc_model.hdf5\"\n",
    "    return keras.models.load_model(filepath)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1960330e",
   "metadata": {},
   "source": [
    "<hr> <hr>\n",
    "\n",
    "## Tensorboard\n",
    "\n",
    "To launch the tensorboard use the following command in the `experimental-notebooks` folder:\n",
    "- Windows: `tensorboard --logdir=./logs/`\n",
    "- MacOS: `tensorboard --logdir='./logs/'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b35576",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "\n",
    "## EEGNet\n",
    "\n",
    "EEGNet is a compact convolutional neural network for EEG-based brain–computer interfaces by Lawhern et al ([2018](https://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta)). There were two proposed version, the latter of which is the referenced published version. Since the latter performs fat better and is the most commonly known EEGNet, this V2 is used here. The EEGModels library provided by the Army Research Laboratory on [GitHub](https://github.com/vlawhern/arl-eegmodels) is used for easy use of this model.\n",
    "\n",
    "### Fixed window classification: Single trial | EEGNet | three class MI task | 100Hz input signal\n",
    "\n",
    "The model recommends using 128 samples.\n",
    "If you remember from the previous notebooks, the data was sampled at 200Hz, which means there are 200 samples per second.\n",
    "In the previous notebook we processed data of 0.5 seconds, thus 100 samples.\n",
    "To get initial results, we will use the model on this 100 samples data.\n",
    "It will be compared to a 128Hz variant later on.\n",
    "\n",
    "The scores are given for the best CSP approach as well as for the trained DL approach.\n",
    "Scores for the DL approach are a combination of the best model based on validation loss / validation accuracy.\n",
    "TensorBoard was used to monitor the behaviour of the model over time, to ensure no overfitting tendencies occur and that enough epochs have happened to learn optimally.\n",
    "\n",
    "**The result on subject `C` are:**\n",
    "\n",
    "\n",
    "| **File index** | **CSP + SVM: train/test accuracy** | **EEGNet: train/test accuracy** |\n",
    "|----------------|------------------------------------|---------------------------------|\n",
    "| 0              | 0.896                              | 0.920 / 0.917                   |\n",
    "| 1              | 0.847                              | 0.917 / 0.917                   |\n",
    "| 2              | 0.719                              | 0.865 / 0.875                   |\n",
    "\n",
    "**The result on subject `B` are:**\n",
    "\n",
    "| **File index** | **CSP + SVM: train/test accuracy** | **EEGNet: train/test accuracy** |\n",
    "|----------------|------------------------------------|---------------------------------|\n",
    "| 0              | 0.465                              | 0.566 / 0.566                   |\n",
    "| 1              | 0.560                              | 0.694 / 0.701                   |\n",
    "| 2              | 0.653                              | 0.795 / 0.778                   |\n",
    "\n",
    "\n",
    "**The result on subject `E` are:**\n",
    "\n",
    "| **File index** | **CSP + SVM: train/test accuracy** | **EEGNet: train/test accuracy** |\n",
    "|----------------|------------------------------------|---------------------------------|\n",
    "| 0              | 0.701                              | 0.771 / 0.778                   |\n",
    "| 1              | 0.580                              | 0.778 / 0.785                   |\n",
    "| 2              | 0.805                              | 0.871 / 0.864                   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14156d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 960 events and 801 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loaded fixed window binary epochs:\n",
      "\n",
      "Extracted labels from epochs: [1 2 1 3 1 3 3 2 3 2]\n",
      "One Hot Encoded labels: [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "Labels match before and after the One Hot Encoding: True\n",
      "Shape of data (epochs, channels, samples): (960, 21, 100)\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# PREPPING THE DATA\n",
    "####################################################\n",
    "\n",
    "# Get the epoch from the RAW limited to MI tasks\n",
    "# Include period before and after to enable filtering possibilities\n",
    "mne_fixed_window_epochs = CLA_dataset.get_usefull_epochs_from_raw(mne_raw, start_offset=-1.5, end_offset=1.5)['task/neutral', 'task/left', 'task/right']\n",
    "\n",
    "# Load the epochs, we don't need filtering since this is what we want to learn!\n",
    "mne_fixed_window_epochs.load_data()\n",
    "print(f\"Loaded fixed window binary epochs:\\n\")\n",
    "\n",
    "# Labels: should be one hot encoded!\n",
    "labels = mne_fixed_window_epochs.events[:, -1]\n",
    "print(f\"Extracted labels from epochs: {labels[:10]}\")\n",
    "\n",
    "# Go to 2D representation\n",
    "labels = labels.reshape(-1, 1)\n",
    "\n",
    "# One Hot Encode the labels\n",
    "ohe = OneHotEncoder()\n",
    "ohe_labels = ohe.fit_transform(labels).toarray()\n",
    "print(f\"One Hot Encoded labels: {ohe_labels[:10]}\")\n",
    "\n",
    "# Show ohe labels\n",
    "np.shape(ohe_labels)\n",
    "ohe_labels[:10]\n",
    "\n",
    "# Validate OHE\n",
    "print(f\"Labels match before and after the One Hot Encoding: {np.array_equal(ohe.inverse_transform(ohe_labels), labels)}\")\n",
    "\n",
    "# Get effective data (half a second)\n",
    "mne_fixed_window_epochs_data = mne_fixed_window_epochs.get_data(tmin=0.2, tmax=0.7)\n",
    "\n",
    "# Delete unused variables\n",
    "del mne_fixed_window_epochs\n",
    "print(f\"Shape of data (epochs, channels, samples): {np.shape(mne_fixed_window_epochs_data)}\")\n",
    "\n",
    "# Remove unused variables\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca901652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 21, 100, 1)]      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 21, 100, 8)        400       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 21, 100, 8)       32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " depthwise_conv2d (Depthwise  (None, 1, 100, 16)       336       \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 1, 100, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1, 100, 16)        0         \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 1, 25, 16)        0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " spatial_dropout2d (SpatialD  (None, 1, 25, 16)        0         \n",
      " ropout2D)                                                       \n",
      "                                                                 \n",
      " separable_conv2d (Separable  (None, 1, 25, 16)        512       \n",
      " Conv2D)                                                         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 25, 16)        64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1, 25, 16)         0         \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 1, 3, 16)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " spatial_dropout2d_1 (Spatia  (None, 1, 3, 16)         0         \n",
      " lDropout2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 48)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 147       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,555\n",
      "Trainable params: 1,475\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# CREATE EEGNET MODEL\n",
    "####################################################\n",
    "\n",
    "# Create the TensorFlow Keras model\n",
    "keras_eegnet_model = EEGNet(\n",
    "    nb_classes = 3, # int, number of classes to classify. \n",
    "    Chans = 21, # number of channels in the EEG data. \n",
    "    Samples = 100, # number of time points in the EEG data. (default: 128)\n",
    "    dropoutRate = 0.5, # dropout fraction. (default: 0.5)\n",
    "    kernLength = 50, # length of temporal convolution in first layer. Suggested: half the sampling rate. (default: 64)\n",
    "    F1 = 8, # number of temporal filters. (default: 8)\n",
    "    F2 = 16, # number of pointwise filters. (default: 16)\n",
    "    D = 2, # number of spatial filters to learn within each temporal convolution. (default: 2)\n",
    "    norm_rate = 0.25, # Normalisation rate. (default: 0.25)\n",
    "    dropoutType = 'SpatialDropout2D' # Either SpatialDropout2D or Dropout, passed as a string. (default: Dropout)\n",
    "    )\n",
    "\n",
    "# Compile the model so it can be fitted\n",
    "# Loss and optimizer from EEGNet paper\n",
    "keras_eegnet_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics=[\"accuracy\"])\n",
    "\n",
    "# Show summary of the model\n",
    "keras_eegnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f898be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for lowest loss model\n",
      "Trained EEGNet on single session using train/test split and got accuracy of: 0.9201388888888888\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Results for highest accuracy model\n",
      "Trained EEGNet on single session using train/test split and got accuracy of: 0.9166666666666666\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################################################\n",
    "# TRAIN EEGNET MODEL\n",
    "####################################################\n",
    "\n",
    "# Configure\n",
    "retrain_model = False\n",
    "tensorboard_name = \"EEGNet_singlesession_C0_100hz\"\n",
    "best_model_filename = f\"./saved_variables/6/{tensorboard_name}\"\n",
    "\n",
    "# Get train/test split of data from one session\n",
    "X_train, X_test, y_train, y_test = train_test_split(mne_fixed_window_epochs_data, ohe_labels, \n",
    "                                                    test_size = 0.3,\n",
    "                                                    shuffle= True,\n",
    "                                                    stratify= ohe_labels,                                                    \n",
    "                                                    random_state=98)\n",
    "\n",
    "\n",
    "# Train on train/test split of data from one session\n",
    "## Note: the model is forced to use GPU, if GPU is not available replace with what is available e.g. /cpu:0\n",
    "if (retrain_model): # Retrain or not\n",
    "    with tf.device('/gpu:0'):\n",
    "        keras_eegnet_model.fit(\n",
    "            x= X_train,\n",
    "            y= y_train,\n",
    "            batch_size= 128, # Default: 32\n",
    "            epochs= 500, # Default: 500 (EEGNet paper)\n",
    "            verbose= 1, # 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "            #callbacks= [tensorboard_callback(\"EEGNet_raw_signal_0.5s_100samps_50kernlen_02nr\")], # To be used for TF Board\n",
    "            callbacks= [tensorboard_callback(tensorboard_name),\n",
    "                        lowest_loss_model_save_callback(best_model_filename),\n",
    "                        highest_accuracy_model_save_callback(best_model_filename)],\n",
    "            validation_split= 0.3,\n",
    "            shuffle= True,\n",
    "            sample_weight= None, # Can be interesting due to time series\n",
    "            use_multiprocessing=True, # Done for faster speed\n",
    "            workers= 4 # Done for faster speed\n",
    "            )\n",
    "\n",
    "# Convert labels back to original\n",
    "y_test = ohe.inverse_transform(y_test)\n",
    "\n",
    "# Get results for best validation loss model\n",
    "print(\"Results for lowest loss model\")\n",
    "keras_eegnet_model = load_lowest_loss_model(best_model_filename)\n",
    "\n",
    "y_pred = keras_eegnet_model.predict(X_test)\n",
    "y_pred = ohe.inverse_transform(y_pred)\n",
    "\n",
    "accuracy =  accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Trained EEGNet on single session using train/test split and got accuracy of: {accuracy}\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "plt.show()\n",
    "\n",
    "# Get results for best validation loss model\n",
    "print(\"\\n\\nResults for highest accuracy model\")\n",
    "keras_eegnet_model = load_highest_accuracy_model(best_model_filename)\n",
    "\n",
    "y_pred = keras_eegnet_model.predict(X_test)\n",
    "y_pred = ohe.inverse_transform(y_pred)\n",
    "\n",
    "accuracy =  accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Trained EEGNet on single session using train/test split and got accuracy of: {accuracy}\")\n",
    "ConfusionMatrixDisplay.from_predictions(y_true= y_test, y_pred= y_pred)\n",
    "plt.show()\n",
    "\n",
    "# Remove unused variables\n",
    "del X_train\n",
    "del X_test\n",
    "del y_train\n",
    "del y_test\n",
    "del accuracy\n",
    "del y_pred\n",
    "del retrain_model\n",
    "del tensorboard_name\n",
    "del best_model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18770e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "# CLEAUP\n",
    "####################################################\n",
    "\n",
    "# delete unused variables\n",
    "del keras_eegnet_model\n",
    "del mne_fixed_window_epochs_data\n",
    "del ohe\n",
    "del ohe_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea0b75a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f92ed28e6a5fe026f22555c18fed88052bb861e5576fb72d2ac78e2247fef331"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
