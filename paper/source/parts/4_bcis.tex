% TODO:
%   - Refs to sections check if truly explained there
%   - Cleanup of text
% ----------  
% Questions:
%   -

% NOTE: Uncomment this if the use of parts is desired
\part{Understanding Brain-computer interfaces}


% NOTE: In a new chapter, reset the GLS to once again use the full version in the first occurrence
\glsresetall

\chapter{Brain-Computer interfaces}
\label{ch:bci}

% ---------------------------------------------- 
% INTRODUCTION
% ---------------------------------------------- 
\section{Introduction to this chapter}
\label{sec:bci_introduction}
% NOTE: "Introduction" exists in each chapter and gives short intro to chapter + what can be expected in chapter

\Glspl{bci} are systems, consisting of hardware and software, that aim to read or even stimulate a user's brain signals for a wide variety of applications.
Whilst many of these applications for \glspl{bci} revolve around providing novel interaction methods for computer applications, they are capable of fulfilling more general tasks as well.
Because of this, \glspl{bci} are also referred to as \glspl{bmi} and can be seen as a special type of the more general \glspl{hmi} and \gls{bc} systems.
A well-known Professor in this field is Jonathan R. Wolpaw who was also the guest editor for the first international meeting devoted to \gls{bci} research and development as part of the IEEE conference on Rehabilitation Engineering.
During that meeting, a first formal definition for \glspl{bci} was given:

\setlength{\epigraphwidth}{0.9\textwidth}
\epigraph{A brain-computer interface is a communication system that does not depend on the brain’s normal output pathways of peripheral nerves and muscles.}{\textit{\citet{first_bci_meeting}}}

Since then, Jonathan R. Wolpaw has (co-)authored a lot of influential papers in the field of \glspl{bci} \citep{bci_rehabilitation, bci_in_medicine, first_bci_meeting} and created a great introductory textbook to the field \citep{bci_book}.
As a board-certified neurologist, Wolpaw's work is often centred around applications in a more medical setting rather than a commercial one. In this medical setting, his opinion on what defines a \textit{perfect} \gls{bci} is often strived for and can be summarized as follows:

\setlength{\epigraphwidth}{0.9\textwidth}
\epigraph{The perfect [medical] \gls{bci} is a safe and affordable system which works all the time, does not require the permanent assistance of a technician or a scientist, restores communication at “normal” speed, is aesthetically acceptable, is reliable and, for the same function, does not require more concentration for a patient user than what it does for an able-bodied person}{\textit{\citet{bci_book, cheap_bci_feasibility}}}


One of the things this thesis aims to study is how far \glspl{bci} have come concerning this definition of a perfect \gls{bci}.
It is noted that the term communication in these definitions simply depicts the exchange of information rather than specific human communication such as speech. For example, a computer mouse could be seen as a communication device that exchanges information about the user's intent to the computer.
Many of these properties for a perfect medical \gls{bci} system would also be beneficial for commercial \gls{bci} systems.

Especially the commercial interest in \glspl{bci} has seen a recent spike, through multiple big-tech companies such as Meta (formerly known as Facebook), Valve (a major gaming company) and Neuralink (an Elon Musk company) showing interest in the field \citep{facebook_bci_blog, bci_valve, neuralink_whitepaper}.
This has given rise to the public interest for potential life-improving \gls{bci} applications as well as some public outrage on more ethical aspects that challenges these systems. 

This first chapter further introduces the main rationale behind \glspl{bci} research by discussing the rise in popularity of both medical and commercial \glspl{bci}, some practical examples of \gls{bci} systems that have been developed and some of the opportunities and obstacles in the field. The chapter ends with a note on some of the ethical challenges for \gls{bci} systems and a discussion of the proposed system for this thesis.
Chapter \ref{ch:biomedical_signals} and \ref{ch:processing_signals} give more depth on the origins and measurability of brain signals and the technologies needed to process them. 
As research on \glspl{bci} is highly multidisciplinary, entering the field as a computer scientist can be rather intimidating due to the steep learning curve of the ideas, technologies, challenges and terminology used in such research.
To lower this initial learning curve, these first three chapters aim to introduce the most important concepts in an easy-to-understand manner for a typical computer scientist student with some \gls{ai} background.
Although no specific procedure for systematic review was followed for these first chapters, special attention was payed to favor papers from reputable sources which have been influential based on both the amount of times the work itself is cited in other papers and the performance of connected papers.
The latter was determined by using the connected papers tool\footnote{\url{https://www.connectedpapers.com/}}.

The interested reader is also referred to the great introductory book on \glspl{bci} by \citet{bci_book} and the review article by \citet{bci_review} when more introductory insight is desired.
Whilst these resources have dated a little and state-of-the-art has changed since then, the main ideas discussed in them remain unchanged.
A more recent, systematic review article by \citet{bci_review_arnau} focuses on current \gls{dl} techniques for use with \glspl{bci} among other \gls{bc} systems.


% ---------------------------------------------- 
% GAINING POPULARITY
% ---------------------------------------------- 

\section{Growing scientific and commercial interest in BCIs}
\label{sec:bci_gaining_popularity}

With brain signal measuring modalities such as \gls{eeg} being over 100 years old, the idea of using those brain signals for a wide variety of use cases has been explored for many decades \citep{human_eeg_discovery, first_eeg, bci_history}.
With feasibility studies of using \glspl{bci} already existing in the 1970s \citep[for example by][]{early_bci} showing that most of the ideas explored today are not new, a clear spike in both scientific and commercial interest can be seen after the 2000s.
It is no coincidence that the first international meeting devoted to \gls{bci} research and development as part of the IEEE conference on Rehabilitation Engineering discussed in section \ref{sec:bci_introduction} was also from this period.

This rise in popularity can be explained by several events.
Perhaps most importantly is the improvement of both brain signal measuring equipment and computational processing equipment in both efficiency, accuracy and portability.
Recent improvements in \gls{ml} and \gls{dl} after some \gls{ai} winters between the 1970s and the 1990s are bound to also have played an important role.
The interest of big tech companies such as Neuralink, Meta and Valve have also introduced unseen amounts of funds further accelerating \gls{bci} research.

This section focuses on discussing these most important contributing factors to the new rise of interest in \gls{bci} research.
These factors are discussed in an arbitrary order, as most of them have influenced each other and it is hard to name a singular reason that explains this recent rise in interest.
For a more in-depth overview of the rich history that \gls{bci} research has, the reader is referred to the work by \citet{bci_history}.

% - - - - - - - - - -
% big tech
% - - - - - - - - - -

\subsection{BCIs have gained big-tech interest and funds}
\label{subsec:bci_gaining_popularity_big_tech}

Big tech has been catching on with the possibilities \glspl{bci} bring, and the amount of money they can earn from it.
Although profitability is an important factor in most medical applications as well, the focus of medical applications lies on improving the life of a patient, whilst the focus of commercial applications can differ greatly.
Since commercial \glspl{bci} are still in their early stages and the idea of constantly wearing a brain-signal recording headset has not been accepted by the wide public yet, many commercially oriented companies start with products that are a cross between medical and commercial applications.

Most noteworthy of these more commercially oriented companies is Neuralink, an Elon Musk company.
Neuralink's initial white paper discusses its aim to create a scalable high-bandwidth \gls{bci} system, focusing on its mechanical achievements \citep{neuralink_whitepaper}.
These mechanical achievements are rather impressive, with state-of-the-art robot surgery inserting ultra-thin sensors directly into the skull allowing for a sleek and visually pleasing package that is mostly hidden from the human eye.
Comparing this to non-invasive methods of recording brain signals, which are methods that don't require inserting machinery into the human body, the signal quality is also expected to be far greater.
However, an invasive approach currently introduces added health risks and more ethical challenges making non-invasive methods often more suited for general use \citep{neuralink_ethics, neuralink_ethics2, bci_review_arnau}.
Since the publication of the Neuralink white paper, the company has held live demos of their \gls{bci} implanted directly into the skulls of animals such as pigs and monkeys.
A video by Neuralink of a monkey playing pong using brain signals as input\footnote{\url{https://youtu.be/rsCul1sp4hQ}} has gathered over 6 million views on YouTube already.
Combined with many news articles, the kind of exposure that Neuralink has gotten is unseen compared to the regular exposure of literature in the field.
This can be questioned, as earlier work by \citet{bci_monkey_arms} demonstrated monkeys taking control over two avatar arms simultaneously, a task that is arguably even harder to accomplish than simply playing pong.
Adding to this, the experiment by \citet{bci_monkey_arms} has an appropriate peer-reviewed paper backing it whilst Neuralink among other commercially oriented companies in the field often lack scientific backing for the claims they make.
Thus, the scientific value of these more commercial demos and applications can be argued for, but the funds for research introduced by these companies and the exposure to the field have accelerated research in the field and helped popularize the field.
Adding to this, the proposed system by Neuralink is one of the most aesthetically pleasing compared to alternative invasive or non-invasive systems on the market, which is one of the properties of Wolpaw's perfect \gls{bci} system given in section \ref{sec:bci_introduction}.

Besides Neuralink, companies like Meta, Valve, Neurable, InteraXon and many more are exploring the commercial possibilities of \glspl{bci} as well.
Some of the companies do this through direct internal research whilst others might provide funds for external projects \citep{facebook_bci_keyboard, valve_bci_interest, neurable_white_paper, interaxon_tests}.
There seem to be two main focuses of the technology in the commercial space.
Either using the new interaction method to perform work more efficiently or using it for recreational purposes.

% | | | | | | | | | | | | |

\subsubsection{Using BCIs to boost work efficiency}
\label{subsubsec:bci_gaining_popularity_big_tech_efficiency}

Meta, formerly known as Facebook, has been playing with the idea of \glspl{bci} for quite a while but has been relatively quiet about it publicly.
In 2021, Meta publicly announced it had provided funds for research on the use of a \gls{bci}-system to restore speech functionalities for people suffering from anarthria \citep{facebook_bci_keyboard, facebook_bci_blog}.
The system by \citet{facebook_bci_keyboard} achieved an average of 15 words per minute, decoded with a median error of 25\%.
Whilst this might not sound impressive, anarthria is a disease which causes patients to not be able to articulate speech at all due to lost control of the muscles required for making sounds.
Adding to this, people suffering from anarthria often suffer from other lost muscle control as well, making alternatives such as keyboard typing or writing impossible.
Taking this into account, these results should be seen as very impressive and such a system can be life-changing for certain patients.
Whilst the system by \citet{facebook_bci_keyboard} was invasive just like Neuralink's system, it was far from visually pleasing.
The patient was fixed in a chair and physically connected to a bulky processing unit in the form of a small server rack, which makes the system non-mobile and makes the user stand out if it were to be used in the real world where discreteness is often desired.

The system by \citet{facebook_bci_keyboard} is an example of one that is backed by the funds that big-tech companies have and which is mainly focused on medical applications whilst the final intention of the funding company is most likely of commercial nature.
Indeed, it is not hard to imagine the commercial interest of Meta in developing a more general \textit{virtual keyboard} to enable fast \textit{thought to speech} or \textit{thought to text} applications usable by the masses.
In fact, during the F8 conference \citep{fb_building8} a couple of years before the paper by \citet{facebook_bci_keyboard}, Meta stated the following:


\setlength{\epigraphwidth}{0.9\textwidth}
\epigraph{Specifically, we have a goal of creating a silent speech system capable of typing 100 words per minute straight from your brain – that’s five times faster than you can type on a smartphone today.}{\textit{\citet{fb_building8}}}


Such a virtual keyboard could replace certain speech-to-text applications already broadly used for commercial purposes.
In the same blog post by \citet{facebook_bci_blog} discussing the funding for the project by \citet{facebook_bci_keyboard}, it is also mentioned that Meta has interest in using \glspl{bci} for high-bandwidth interactions in AR/VR.
However, Meta has been subject to multiple privacy concerns lately \citep{facebook_drama1, facebook_drama2}.
The company's reputation has been damaged from this which doesn't help in selling the concept of them having a \gls{bci} which allows them to read the brain activity of the users.
This could explain why they have recently started to shift their focus from \glspl{bci} towards muscle-based interfaces using \gls{emg} \citep{facebook_bci_blog}.

A recent example of a \gls{bci} being used to boost work efficiency is covered by \citet{bci_nude_detection}.
He discusses how Chinese researchers have been working on a non-invasive and portable system that aims to detect if a user is watching pornographic content through brain signals.
When presenting fifteen male participants aged between 20 and 25 with erotic content and regular content, an accuracy of over 80\% was obtained for determining whether the user was watching erotic content or not.
Such a system should aid in China's content regularisation which often bans such erotic content on their domestic social-media platforms.
Current systems rely on manual evaluation by a reviewer for removing or keeping content that is flagged as inappropriate by either the community or an algorithm. 
Further automating this task through a brain-controlled system could boost the efficiency of this process significantly.


% | | | | | | | | | | | | |

\subsubsection{Using BCIs for recreational use}
\label{subsubsec:bci_gaining_popularity_big_tech_recreational}

Whilst some promising results have been obtained when using \glspl{bci} in commercial settings to boost work efficiency, many of the systems still lack the desired performance to become truly viable. 
And thus, the most prominent type of commercial \glspl{bci} are those focusing on recreational use.
In this regard, the headsets by InteraXon, produced under the Muse brand, are one of the earliest examples, with their first version being released in 2014.
The first iteration of this product was advertised as a meditation aid.
This headset relies on measuring Theta waves in the brain, which are lower frequency waves that suggest a user is meditating.
Section \ref{subsec:biomedical_signals_type_of_signals_brain_wave} talks about these brain wave frequencies in more detail.
The actual accuracy and usefulness of these types of systems are debated, as discussed by \citet{interaxon_tests}.
More recently, a newer version of the InteraXon headset came to market, named Muse 2, which also aids in sleep monitoring.
This relies on detecting Delta waves among other patterns to determine the sleep quality of a user.
Like before, this accuracy and usefulness can be argued for.
A similar commercial product for sleep tracking is available from the company Dreem, under the name Dreem 2.
Dreem has received more funding, as can be seen in figure \ref{fig:bci_money}, but InteraXon, the company behind the Muse headset, has arguably contributed more to the field.
Not only was it one of the first commercial \glspl{bci} that gained media attention, but the company also plays an important role in the commercialisation of \glspl{bci} as their headsets are cheap, non-invasive and visually pleasing whilst also being widely available. 
Adding to this, these headsets have pretty good supporting libraries in Python among other programming languages that allow developers to use these headsets for other purposes as well.
Besides InteraXon, some other companies that specialize in providing commercially usable brain-signal recording headsets exist, as will be further discussed in section \ref{subsec:biomedical_signals_measuring_equipment}.

Perhaps the most promising short-term commercial use of \glspl{bci} is in combination with \gls{vr} and \gls{ar}.
Besides Meta's interest in this region, as discussed earlier in this section, Valve has also said it is actively researching how to use \glspl{bci} as a novel interaction system in \gls{vr} games \citep{valve_bci_interest}.
Valve is the company behind Steam, one of the world's largest game marketplaces and they are specialized in creating games and gaming hardware as well.
To achieve the goals of this project code-named \textit{Galea}, Valve is working together with OpenBCI, a well-respected company in the \gls{bci} research field that has provided open-source hardware and software for use in \gls{bci} systems.
Tobii, a company that specializes in eye-tracking software, is also working on project Galea.
With a final goal of creating an open-source \gls{bci} that can be used in gaming, the anticipation for the headset has been high.
However, just as with deadlines from other companies such as Meta and Neuralink, the project has been postponed multiple times.
This is not surprising as the promises of what a \gls{bci} can do are near endless and initial trials often offer promising results but going to a final product has been proven to be incredibly hard due to several open issues \citep{bci_review_arnau}.

A final stream of money that is important to mention, is coming from militaries around the globe.
The U.S. military among others is known to invest a lot of money in any form of innovation, especially related to devices that can give them a strategic edge when fighting in a war \citep{military_ai_money, military_ai_money_eu}.
Whilst most of this information is classified, it is known that the U.S. Department of Defense and others have shown interest in a wide variety of applications using \glspl{bci} \citep{bci_military}.
Whilst one can only guess what these government organisations are developing, it is likely that over time these applications might become public knowledge and aid the research field of \glspl{bci} in creating even better systems.

% | | | | | | | | | | | | |

\subsubsection{Summary of big-tech using BCIs for commercial applications}
\label{subsubsec:bci_gaining_popularity_big_tech_summary}

To summarize, there have been a lot of big companies showing interest in commercial \gls{bci} applications in the past few years.
Some might contribute directly to the field by funding scientific research, which is often still focused on medical applications but whose results can show potential for certain commercial applications \citep{facebook_bci_blog, facebook_bci_keyboard, neuralink_whitepaper}.
On the other hand, some companies are working on commercial products internally, mostly for improving work efficiency \citep{fb_building8, bci_nude_detection} or for recreational use \citep[Muse and InteraXon headband,][]{valve_bci_interest}.
These commercial products have yet to see truly successful examples, as they are either questionable in delivering what they promise \citep{interaxon_tests}, experience delayed deadlines or are even cancelled in their entirety.
Nonetheless, these companies focusing on commercial applications often have high amounts of funding and a focus on the \gls{ux} of \glspl{bci} which could help accelerate research in the field and make \gls{bci} systems more visually pleasing and accepted by the broader public.
In this way, they also contribute to Wolpaw's vision of a perfect \gls{bci} system as discussed in section \ref{sec:bci_introduction}.

Figure \ref{fig:bci_money} shows the funding of \gls{bci}-related companies founded after 2010 as a rough indication of how much money is spent on start-up companies in the field.
Interestingly, from the companies Neurable, Muse and Neuralink mentioned in this thesis, the funding amount is in proportion to the overall popularity of that company to the wider public, although this is by no means a proven relation.
It also shows that whilst academic research on \glspl{bci} doesn't require huge funding, with open-source datasets and relatively cheap hardware available as is further discussed in section \ref{subsec:biomedical_signals_measuring_equipment} and \ref{subsec:bci_pipeline_training_data_gathering_windowing}, creating an effective commercial product can become an expensive affaire rather quickly.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{images/introduction/funding.png}
    \captionsetup{width=0.9\linewidth}
    \captionsetup{justification=centering}
    \caption{Funding of newer \gls{bci} related companies depicted in millions (USD).\\Figure based on data by \citet{bci_money} from 2019. It is noted this data is limited to companies that were created after 2010 where funding information is made available.}
    \label{fig:bci_money}
\end{figure}

% - - - - - - - - - -
% improved hardware
% - - - - - - - - - -


\subsection{Improved brain-signal measuring facilities}
\label{subsec:bci_gaining_popularity_better_measuring}

\glsreset{bci}
\glsreset{hmi}
\glsreset{ux}

As \glspl{bci} are a type of \gls{hmi} relying solely on brain signals to operate, the measuring facilities for acquiring data of those brain signals have a direct impact on the capability of those systems.

Most \glspl{bci} rely on non-invasive measuring equipment that uses \gls{eeg} as a source of data and this paper will focus mainly on such measuring equipment as well.
Chapter \ref{ch:biomedical_signals} explains in greater detail what \gls{eeg} and some of its alternatives are, the equipment used for acquiring brain-signal data and more.
For this introduction, it suffices to know that non-invasive \gls{eeg} measuring equipment measures the electrical potential difference, often in \gls{mv}, between electrodes placed on the scalp.

Following Wolpaw's definition for a perfect \gls{bci} given in section \ref{sec:bci_introduction}, the recording hardware should ideally be aesthetically acceptable and shouldn't require the assistance of a professional to install.
In recent years, new developments in this hardware have made meeting these criteria more plausible, which are adressed in this section.

% | | | | | | | | | | | | |

\subsubsection{Hardware improvements in non-invasive EEG measuring equipment}
\label{subsubsec:bci_gaining_popularity_better_measuring_hardware}

% TODO: add sketch of measuring hardware with components in different colors for referencing in this paper.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{example-image-a}
    \captionsetup{width=0.9\linewidth}
    \captionsetup{justification=centering}
    \caption{General components of non-invasive EEG measuring equipment.}
    \label{fig:general_eeg_measuring_components}
\end{figure}

Three major hardware distinction made between the electrodes used in non-invasive \gls{eeg} measuring equipment is whether they are wet or dry electrodes, whether they are active or passive electrodes and whether communication to the processing unit happens wirelessly or not.
When considering Wolpaw's definition of a perfect \gls{bci} described in section \ref{sec:bci_introduction}, dry-electrodes with passive amplification that connect wirelessly to the processing unit would be ideal.
However, when looking at data quality, a wired wet-electrode with active amplification is best.
Luckily, recent advancements have made these differences in data quality more acceptable, as will shortly be discussed in what follows.

Wet \gls{eeg} electrodes are electrodes which require an electrolytic gel to be applied between the electrode and the scalp.
This gel functions as a conductor and, as discussed further in section \ref{subsec:biomedical_signals_measuring_equipment}, currently allows wet electrodes to have better data quality compared to dry electrodes \citep{wet_vs_dry, dry_electrode_status, wet_dry_comparison_experiment}.
However, wet electrodes require the assistance of a professional to correctly apply the gel and are far less aesthetically acceptable than dry electrodes.
Adding to this, the electrolytic gel could also cause allergic effects for the user. Due to the viscosity of the electrolytic gel changing over time, artefacts in measurements may also appear \citep{dry_electrode_status}.
These are unwanted properties and conflict with Wolpaw's vision of a perfect \gls{bci}.

Advancements in dry electrodes are making the gap with wet electrodes smaller and smaller \citep{wet_vs_dry, dry_electrode_status, wet_dry_comparison_experiment}.
These dry electrodes don't require the use of an electrolytic gel and given the use of an appropriate headset can be installed on the scalp without the assistance of a professional. 
Both of these properties are in favour of Wolpaw's properties for a perfect \gls{bci}.
The main reason dry-electrodes are becoming more viable to be used in real-life environments is due to improvements in active electrode technology \citep{wet_vs_dry}.

Active electrodes are electrodes which do more than just forwarding their measured voltage fluctuation to the main controller board whilst passive electrodes do just that.
This is often necessary since the measured signal is of such low strength that even a short distance cable from the electrode to the main board can cause a lot of noise due to electromagnetic interference \citep{active_electrode_explained}.
To reduce this noise, a preamplifier is used which additionally amplifies the signal before transmission over the wire as opposed to only being amplified in the main controller board.
This makes the final system less compact and more expensive but is often required in anything but lab environments, especially for wireless dry electrodes, as further discussed by \citet{wet_vs_dry}.

When talking about wireless electrodes, it is not the effective electrode itself that is wireless but rather the communication between the main controller board, a board to which all electrodes are connected by wire, and the processing unit such as a computer.
Whilst a wireless approach allows for the creation of an aesthetically more pleasing system where the measuring hardware and processing hardware are physically separated, a wired connection will always remain more efficient and reliable. 
However, as discussed by \citet{bluetooth_evaluation}, Bluetooth, an open standard for wireless communication, has seen extensions that are more reliable, power efficient and capable of higher transmission speeds.
This has made wireless solutions more appealing in \gls{bci} systems but overall issues with wireless solutions, in general, will prevail.
Most important is the risk of connection loss and a higher latency resulting in a longer time between the point a signal is measured and it is received by the computational unit.

All of these advancements have enabled companies such as Muse, Dreem and OpenBCI to develop non-invasive,  dry-electrode based \gls{eeg} measuring equipment with active amplification in an affordable and often aesthetically acceptable manner.
An example of such an aesthetically pleasing system is given in Figure \ref{fig:example_eeg_measuring_devices_commercial_clean}.
As \glspl{bci} become even more popular, a heavier focus on affordability and visuals with \gls{eeg} measuring equipment is to be expected.
As these two properties were less important in previous medical settings where a patient would wear such equipment only when undergoing a test in the hospital.
Figure \ref{fig:example_eeg_measuring_devices} shows the contrast between a high-end medical-grade \gls{eeg} recording system and one that focuses on \glsfirst{ux}.

% TODO: find appropriate figures
\begin{figure}[ht]
  \begin{minipage}{\textwidth}
    \centering
    \begin{subfigure}{.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{example-image-a}
        \captionsetup{width=0.9\linewidth}
        \captionsetup{justification=centering}
        \caption{Medical \gls{eeg} measuring devices that uses wet electrodes with active amplification over a wired connection.}
        \label{fig:example_eeg_measuring_devices_medical_bulky}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{example-image-b}
        \captionsetup{width=0.9\linewidth}
        \captionsetup{justification=centering}
        \caption{Commercial \gls{eeg} measuring devices that uses dry electrodes with active amplification over a wireless connection.}
        \label{fig:example_eeg_measuring_devices_commercial_clean}
    \end{subfigure}
    \captionsetup{width=0.9\linewidth}
    \captionsetup{justification=centering}
    \caption{The contrast between \gls{eeg} measuring equipment focused on the best possible data quality and one that favours user comfort.}
    \label{fig:example_eeg_measuring_devices}
  \end{minipage}  
\end{figure}

% | | | | | | | | | | | | |

\subsubsection{Algorithmic improvements for non-invasive EEG measuring equipment}
\label{subsubsec:bci_gaining_popularity_better_measuring_software}

Whilst hardware improvements has made the collection \gls{eeg} data more affordable, reliable and accurate, one important issue still remains.
Even with the best active wet electrodes, The contrast between spatial and temporal resolution is enormous.
\Gls{eeg} is known to have a good temporal resolution but rather poor spatial resolution.
A good spatial resolution would mean that the measurement from electrodes corresponds only to a small, known region of the brain, typically underneath that electrode.
Such a correlation is helpful as it reduces noise and increases interpretability of the signal.
It also allows for fewer electrodes to be used if only the activity of certain areas of the brain is of interest.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/introduction/brain_anatomy.png}
    \captionsetup{width=0.7\linewidth}
    \captionsetup{justification=centering}
    \caption{The anatomy of the human head, specifically of the cerebrospinal system. Non-invasive \gls{eeg} measuring equipment is placed on the scalp, causing signals from the brain to be blocked by the skull and \glsfirst{csf} among other structures. Free to use Figure by Blausen.com staff \citep{figure_blausen}.}
    \label{fig:brain_anatomy}
\end{figure}

Thus, many attempts have been made at improving spatial resolution of \gls{eeg} but it has been proven to be a challenging task \citep{spatial_resolution}.
Besides potential noise of the measurements, this is also caused by the anatomy of the human head.
Remember that the electrodes used for non-invasive \gls{eeg} measuring are placed on the scalp, the skin of the human head.
As shown in Figure \ref{fig:brain_anatomy}, besides the scalp, different structures such as the skull and \glsfirst{csf} are in between the electrodes and the actual brain.
These components \textit{blur} and \textit{disperse} the perceived brain-signal, making it hard to track where the measured signal came from when looking at the electrical activity on the scalp.

Whilst increasing the number of electrodes placed on the skull physically limits the region under one single electrode, it doesn't guarantee an improve in spatial resolution.
Indeed, clever processing algorithms are required to correct for overlapping signals between electrodes so that the overlapped signal is correct for and the effective spatial resolution is improved.
Besides this, there is also the issue that decreasing the distance between electrodes introduces the need for placing more electrodes to cover the entire region of the brain.
This increases cost, lowers user comfort and decreases the visual acceptance of the system.
Another issue with increasing the number of electrodes and decreasing the spatial resolution means that the alignment of the electrodes on the skull is now even more prone to errors and change over time, e.g. due to movement of the user.
This makes the need for a professional higher, which is also detrimental with respect to Wolpaw's criteria for a perfect \gls{bci}.

\Citet{spatial_resolution} has found 19-electrode EEG systems to have a highly varying spatial resolution in the 20 to 40 $cm^3$ range.
Systems with 129 electrodes were found to have a spatial resolution of around 6 to 8 $cm^3$ \citep{spatial_resolution} when also using algorithmic tricks to further improve spatial resolution.
However, according to \citet{neurons_book}, around $10^7$ parallel pyramidal neurons reside in each $cm^3$ of the brain cortex.
This means the acquired data is still obtained from a incredibly large number of neurons even in the best spatial resolutions.

Whilst hardware improvements in both electrodes and headsets for better placement might improve the spatial resolution further, the spatial resolution improvements possible through hardware have been plateauing.
As was the case for the comparison between few and many electrode systems by \citet{spatial_resolution}, appropriate algorithms have to be used to effectively increase the spatial resolution.
Recently, these techniques often rely on using Laplacians \citep{improve_eeg_spatial_laplacian1, improve_eeg_spatial_laplacian2, improve_eeg_spatial_laplacian3}, although other approaches using for example \glspl{cnn} have been proposed \citep{improve_eeg_spatial_cnn}.
These techniques also have the added benefit of cleaning the time-varying signal as described by \citet{improve_eeg_spatial_comparison}.

% | | | | | | | | | | | | |

\subsubsection{Invasive BCIs try to combat the issues of EEG}
\label{subsubsec:bci_gaining_popularity_better_measuring_invasive}

The previous parts discussed how non-invasive \gls{eeg} measurements have been improved.
However, alternatives to \gls{eeg} exist for measuring brain signals, some of which are further discussed in section \ref{subsec:biomedical_signals_measuring_modalities}.
Most notable in recent years is measuring modalities that rely on capturing brain signals by equipment directly inserted into the human body, making it an invasive approach.
One such example of an invasive measuring modality is \gls{ecog} and the most popular invasive \gls{bci} at the moment is the one proposed by \citet{neuralink_whitepaper}.
The white paper by \citet{neuralink_whitepaper} has shown that invasive \glspl{bci} could greatly exceed the data quality and visual aesthetics of even the best non-invasive alternatives.
As further discussed in \ref{subsec:biomedical_signals_measuring_invasive}, this invasive method places flexible electrodes directly inside the skull.
These electrodes are invisible to the human eye with the only visual component being a rechargeable wireless transmitter that is magnetically attached to the skull.
Neuralink's final aim is to make the brain-signal measuring equipment completely invisible to the human eye.

\citet{neuralink_whitepaper} has built robots to insert the electrodes inside the skull in a very precise location without the need for an open-skull operation or even anaesthesia.
This allows for a magnitude more electrodes to be installed and is expected to suffer far less from noise resulting in a far greater temporal and spatial resolution compared to \gls{eeg}.
This suggests that invasive systems are superior to non-invasive alternatives, but the fact that they are more permanent, far more expensive and invasive gives rise to technical and ethical questions.
These ethical questions are further discussed in section \ref{sec:bci_ethical}.
From a technical standpoint, maintaining and upgrading a non-invasive \glspl{bci} is far simpler and cheaper.
The fact that you are inserting foreign objects into the brain also introduces far more health risks than non-invasive systems do.
Convincing the user to put on a headset that can be removed will also be far easier than convincing the user to get a \gls{bci} permanently implemented in their skull.

It has also been shown that the theoretical more precise temporal and spatial resolution doesn't linearly correlate with improved \gls{bci} accuracy/control, rather it seems to plateau relatively quickly with current state-of-the-art signal processing and classification techniques \citep{dropping_curve_eeg_lectrodes, more_electrodes_not_better}.
Some critics point to the dropping curve found by \citet{dropping_curve_eeg_lectrodes} to conclude that the increased electrode amount and reachable neurons achieved by \citet{neuralink_whitepaper} don't have a direct impact on the usability of \glspl{bci} in real-world applications.
Because of these aspects, the ease-of-use appeal and far cheaper price for non-invasive alternatives still outweigh the benefits offered by invasive methods for almost all but highly medical applications, at least in the opinion of the writer of this thesis.
Nevertheless, future improvements in signal processing and classification techniques could prove invasive methods to be far superior for \gls{bci} applications and the mechanical achievements so far are not to be underestimated.
An invasive system is also promising concerning Wolpaw's definition of a perfect \gls{bci} discussed in section \ref{sec:bci_introduction}.
Once installed, it would ideally require no more assistance from a professional, is aesthetically acceptable as it can be invisible to the human eye, has signs of being far more reliable than \gls{eeg} and more.

% | | | | | | | | | | | | |

\subsubsection{Summarizing the improvement of measuring facilities}
\label{subsubsec:bci_gaining_popularity_better_measuring_summary}

Since \glspl{bci} rely solely on brain signals to operate, the measuring facilities for acquiring data of those brain signals have a direct impact on the capability of those systems.
As was discussed in this section, the most commonly used modality for non-invasive data acquisition, \gls{eeg}, has benefited from both hardware and software improvements.
From a hardware point of view, the switch to dry electrodes using active amplification and wireless connection to a computational unit has made \glspl{bci} more favourable concerning Wolpaw's criteria for a perfect \gls{bci} \citep{bluetooth_evaluation, wet_vs_dry, active_electrode_explained}.
From a software perspective, clever algorithms have enabled preprocessing of the signal to improve spatial resolution \citep{improve_eeg_spatial_laplacian1, improve_eeg_spatial_laplacian2, improve_eeg_spatial_laplacian3, improve_eeg_spatial_cnn}.
Improving the spatial resolution can also positively affect the temporal resolution due to inherent noise reduction as discussed by \citet{improve_eeg_spatial_comparison}. 
As is further discussed in section \ref{subsec:processing_signals_useful_data_preproc}, other prepossessing techniques have also been introduced and refined further aiding in improving the data quality. 

% - - - - - - - - - -
% better hardware
% - - - - - - - - - -

\subsection{More powerful, affordable and portable equipment}
\label{subsec:bci_gaining_popularity_better_processing}

The improvements in brain signal measuring equipment have likely been influential in the gaining popularity of \glspl{bci} as it provides more precise data more affordably.
However, having the possibility of obtaining clean data is only part of the way to a perfect \gls{bci} system.
Other improvements concerning computational power, affordability and portability have also played an important role in \gls{bci} research, contributing to the rise of popularity in the process.

% | | | | | | | | | | | | |

\subsubsection{The emergence of faster and cheaper hardware}
\label{subsubsec:bci_gaining_popularity_better_processing_cheaper}

As chapter \ref{ch:processing_signals} will discuss in greater detail, working with \gls{eeg} data, or other forms of brain signal data can require computationally very heavy operations to achieve desired processing results of that data.
Luckily, together with the improvements in state-of-the-art measuring equipment, there is also an emerging supply of less accurate but far more affordable and portable \gls{eeg} measuring equipment.
Due to Moore's law \citep{moores_law} and other advancements, \glspl{cpu} and other computational hardware have also seen massive improvements in computational power.
This has made algorithms previously requiring expensive specialized computational hardware possible on the average personal computer.
All of these factors have made \gls{bci} applications, which were previously limited to lab environments with a high financial cost, accessible to a far broader public.
The availability of open-source datasets for common tasks related to brain signals has also allowed computer scientists to experiment in the field without additional hardware cost \citep{eeg_data}.

% | | | | | | | | | | | | |

\subsubsection{Splitting BCIs into multiple major components for portability and reusability}
\label{subsubsec:bci_gaining_popularity_better_processing_split_into_components}

Early attempts at making \glspl{bci} more portable and affordable include those by \citet{early_bci_drowsiness} and \citet{early_bci_multimedia}.
In essence, these applications rely on separating the data acquisition process and data processing into two standalone systems connected over Bluetooth.
Remember from section \ref{subsec:bci_gaining_popularity_better_measuring} that Bluetooth is an open standard for wireless communication that has seen improvement in the last couple of years.
Dividing a \gls{bci} system in a data acquisition and data processing system allows for creating a lightweight measuring device to be placed on the user's head, with a heavier and bulkier computational unit to process the signals which ideally is still pocket-able.
The latter was not a trivial task and introduced the need for custom hardware at the time.
\citet{early_bci_drowsiness} used a custom-made \gls{dsp} for the task whilst \citet{early_bci_multimedia} opted for a more general \gls{fpga} based \gls{dsp}.
Whilst these were great demonstrations of how the technology could be used outside the lab, the actual usage for a bci detecting driver's drowsiness \citep[as proposed in the paper by][]{early_bci_drowsiness} and allowing multimedia control \citep[as proposed in the paper by][]{early_bci_multimedia} was rather limited.
The idea of custom-made and possibly proprietary processing hardware which focuses on a single task is also very limiting, although it does have commercial benefits.

What did stick, was the idea of splitting the hardware into two standalone parts, a wireless \gls{eeg} measuring device and a processing unit.
As discussed in section \ref{subsec:bci_gaining_popularity_better_measuring}, a wireless connection between these two components is also favoured when taking into account Wolpaw's criteria on a perfect \gls{bci}.
It also makes it possible for smaller research teams or even individuals with a certain specialisation to take part in the highly interdisciplinary field by not requiring knowledge of all components but just the one that is of interest.
As an example, it enables computer scientists to purchase off-the-shelve affordable \gls{eeg} measuring hardware and communicate with it through provided libraries for their favourite programming language.
In most cases, the personal computer they already own is powerful enough for the experiments, especially for offline systems.
This allows for reusing existing hardware which is great from a financial perspective.
Section \ref{subsec:biomedical_signals_measuring_equipment} discusses some of the \gls{eeg} measuring equipment available on the market.
It is noted that \gls{eeg} measuring hardware is not strictly needed for a computer scientist as researchers such as \citet{eeg_data} have made excellent free-to-use \gls{eeg} datasets available.

With the introduction of the iPhone in 2007, it didn't take long for researchers to explore the idea of using a mobile phone as a processing unit for a \glspl{bci}.
\citet{early_bci_phone} were one of the first to explore this idea, with a \gls{ssvep}-based \gls{bci}.
Session \ref{sec:biomedical_signals_type_of_signals} will go into further detail on these type of signals.
In essence, such a system relies on a category of brain signals that are often easy to detect but require a specific stimulation.
This type of system can be used for a wide variety of applications.
Imagine an audio-guided tour in a museum where visitors only need to stare at a screen next to an item of interest to start hearing the explanation of that item.
This could be achieved with only a couple of dry electrodes placed on the skull in a headset that also provides the audio to the visitor.
This headset could then be connected over Bluetooth to the visitor's phone running an app for the museum tour.
The technology needed for such a system would lean close to that of so-called \textit{P300 spellers}, which have already been heavily studied \citep{p300_spellers_review, p300_keyboard_flashing, p300_spellers}.
Such a system would also fit perfectly with Wolpaw's definition of a perfect \gls{bci}, albeit oriented to a commercial setting rather than a medical one.

% | | | | | | | | | | | | |

\subsubsection{Making BCIs a one-in-all device again for profitability}
\label{subsubsec:bci_gaining_popularity_better_processing_profitibility}

Whilst the advantages of using the computational power of devices a customer already owns are clear, it also imposes some disadvantages.
For one, the varying type of computational devices is bound to give varying performance results, compatibility issues and overall limits the guarantee of a pleasing \gls{ux}.
Adding to this, the measuring equipment and processing equipment can't be connected from the factory resulting in an experience that is not plug-and-play.
From a commercial perspective, it would be easier if the system was all-inclusive and possibly patentable. 

Recent trends in computing hardware where manufacturers are shifting away from general all-purpose \glspl{cpu} and them developing their own custom \gls{cpu} architectures have shown that custom chips can outperform their general counterparts.
Patenting the architecture of those chips is possible making it commercially interesting.
Apple's mac M series processors announced in 2020 are one such recent example.
These M series processors have a neural engine that is stated to accelerate the time needed for \gls{ml} tasks\footnote{\url{https://nr.apple.com/dH8i4U3v2w}}.
\Glspl{gpu} used for autonomous driving systems also differ from general-purpose \glspl{gpu}.

Because of this, the author of this paper believes custom-made chips could create a future where the headset has a directly integrated processing unit once again.
Whilst this would make for a more attractive package for the customer and give commercial advantages to the manufacturer, it would be disadvantageous for research purposes.
The manufacturer could limit the possibilities of using the \gls{bci} for different purposes, patent promising hardware and more.
Another possible route the author of this paper sees is the use of cloud computing and fast 5G connections to also create a more simple user experience that doesn't require Bluetooth tethering to a close-by processing unit.
This approach would still leave a separation between measuring hardware and processing hardware making changes to any of the two independently easier.
Concerning Wolpaw's criteria of a perfect \gls{bci}, these approaches would also be acceptable.
This belief of switching back to all-in-one devices or using a cloud service for processing the data is further endorsed by the findings of \citet{bci_review_arnau}.
In their systematic review of \gls{bc} systems, eight of the 46 studied papers used embedded hardware and one used cloud solutions.

% | | | | | | | | | | | | |

\subsubsection{Summarizing the improvements on computational power, affordability and portability}
\label{subsubsec:bci_gaining_popularity_better_processing_summary}

To summarize, due to Moore's law \citep{moores_law} and other advancements, \glspl{cpu} among other computational hardware have seen massive improvements in computational power.
This increase in computational power has enabled more advanced processing of the data on more affordable and portable hardware.
Early attempts at making \glspl{bci} more portable and affordable focused on splitting the brain signal measuring equipment from the data processing equipment \citep{early_bci_drowsiness, early_bci_multimedia}.
The system by \citet{early_bci_phone} was one of the earliest examples of a true portable \gls{bci}-system that was affordable and relied on a smartphone as a processing unit.
It showed how working with \glspl{bci} can be done using cheap and general-purpose hardware.
The research was published at a turning point for \glspl{bci} where publication numbers on \gls{bci}-related papers started rising.
This hints that the increased affordability and portability combined with more computational power played an important factor in the rise of interest in \gls{bci}. 
The rise of \gls{bci}-related papers is illustrated in figure \ref{fig:bci_publications} based on data by \citet{bci_progress_overview}.
\Citet{bci_review_arnau} found that papers on \gls{bc} systems using \gls{dl} have seen a steady increase over the last five years as well. 

In the future, as \glspl{bci} see more commercial applications, this separation of a \gls{bci} in a measuring component and processing component might reverse to an all-inclusive device.
This has potential downsides for scientific research but makes commercial sense.
The replacement of physical computational units in close proximity to cloud solutions is another possible evolution.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\linewidth]{images/introduction/papers_on_bci.png}
    \captionsetup{width=0.65\linewidth}
    \captionsetup{justification=centering}
    \caption{Number of \gls{bci}-related papers over time. Based on data by \citet{bci_progress_overview} obtained by searching PubMed using the keyword: "brain computer interface".}
    \label{fig:bci_publications}
\end{figure}


% - - - - - - - - - -
% better software
% - - - - - - - - - -

\subsection{Specialized data processing techniques}
\label{subsec:bci_gaining_popularity_improved_data_processing}

\glsreset{dl}

The previous sections \ref{subsec:bci_gaining_popularity_better_measuring} and \ref{subsec:bci_gaining_popularity_better_processing} discussed how both measuring and computational hardware have seen recent improvements.
Another important part of the puzzle is the algorithms that convert data from the now more user friendly measuring devices to useful actions using the now more powerful, affordable and more portable computational hardware.
Most of these algorithms are data-driven classifiers that use \gls{ml} techniques.
In more recent years, \gls{dl} techniques and alternative approaches have been incorporated in the \gls{bci} pipeline as well, which has been proven to be very successful. 
Chapter \ref{ch:processing_signals} discusses commonly used techniques in more detail and multiple \gls{ml} and \gls{dl} based \gls{bci} pipelines are discussed in later chapters of this thesis.
This section gives a more high-level summary of recent developments in the \gls{ai} field that have likely contributed to the rise in popularity of \glspl{bci}.

% | | | | | | | | | | | | |

\subsubsection{Postponing another AI winter}
\label{subsubsec:bci_gaining_popularity_improved_data_processing_no_ai_winter}

\Glsfirst{ml} and \glsfirst{dl} are techniques that fall under the \gls{ai} umbrella.
These techniques are being used as buzzwords in a whole suite of applications and it seems as if every week there is yet another big promise or threat related to \gls{ai} discussed in major news outlets.
Recent examples that have shown the world what new techniques in this field are capable of include the Go champion beating computer algorithm by \citet{alphago}, the impressive text generation model GPT-3 by \citet{GPT3} and the image generation model DALL-E by \citet{dall_e}.
This abundance of new achievements and an overall high public interest in anything that mentions buzzwords from the \gls{ai} umbrella has caused a long lasting \gls{ai} summer since the last \gls{ai} winter of the late 1980s and early 1990s.
Such an \gls{ai} summer means that there is incredible amount of funding available for improving \gls{ml} and \gls{dl} techniques among others.
This in term causes further advancements in the field of \gls{ml} and \gls{dl} which results in more impressive achievements.

However, an \gls{ai} summer also implies that an \gls{ai} winter will inherently return.
An \gls{ai} winter is a period of time where the interest in the field is reduced and thus funding and research is limited.
As discussed by \citet{new_ai_winter}, such an \gls{ai} winter may be relatively close.
This is in part due to new regulations and public backlash on the more questionable but highly profitable applications \gls{dl} is involved in.
A recent example of this is the controversy surround Clearview AI.
Here, state-of-the-art \gls{dl} image recognition algorithms are used on billions of images collected from all over the internet, including social-media platforms, to recognize almost anyone with a public profile linked to them.
As further discussed by \citet{clearview_ai}, this technology conflicts with many EU laws yet was used by multiple police departments.
Adding to this, new regulatory changes are being proposed to limit the use of algorithms which lack explainability and interpretability \citep{eu_ai_blackbox_report, explainable_ai_policy}.
This challenges many \gls{ml} and \gls{dl} approaches currently used as explained further in section \ref{subsec:processing_signals_common_issues_exaplainable}.

Nevertheless, there is still a high amount of resources being put into \gls{ml} and \gls{dl} research.
Throughout history, these technologies have been linked with the biomedical setting a lot.
As explained by \citet{dl_and_biomedical}, \gls{dl} and biomedical data have directly influenced each other's evolution's since the 1980s.
Because of this, applications that process biomedical data have been an important factor at prolonging the current \gls{ai} summer.
Since \glspl{bci} use biomedical data as well, they have been one of the applications keeping interest in \gls{ml} and \gls{dl} research high.
This is in part due to the science-fiction properties \gls{bci} systems have creating a lot of public interest as already discussed when talking about Elon Musk's Neuralink in section \ref{subsec:bci_gaining_popularity_big_tech}.
Thus, \gls{bci} systems, which rely heavily on \gls{ml} and \gls{dl}, are one of the research areas in these technologies that are so promising they help prolonging the current summer of \gls{ai}.

% | | | | | | | | | | | | |

\subsubsection{Improved and new ML and DL concepts have enabled more capable BCI systems}
\label{subsubsec:bci_gaining_popularity_improved_data_processing_better_ml_dl}

% START HERE; HERSCHRIJVEN NAAR DIE DIVISIONS UIT PPT EN UIT INTRO
%   tekst al ok maar je moet er nog wat extra bijdoen naar aanleiding van lezen arnau bci review

% TODO: cnn meer bespreken a la: The most common type of DL neural networks at this time are the previously described CNNs (LeCun et al 1989). The subsequent application of convolutional layers results in a high-level representation of the input as stipulated by Goodfellow et al (2016). For example, in an object classification task, the network learns to extract primitive shapes from the raw input (a matrix of pixel values) in the first layer and then learns to extract objects from these primitive features in the next layer.
% en dus niet perse laatste layers voor classification maar vaak laatste layers terug mlps oid ipv puur convolutional layer

Most of the main concepts from both \gls{ml} and \gls{dl} are already multiple decades old.
To illustrate this, a general pipeline of a \gls{cad} system used for classification is given in Figure \ref{fig:cad_pipeline} and commonly used techniques are discussed below.
It is noted that besides classification tasks, some regression problems for \gls{cad} systems exist as well.
However, such regression problems are far less common in \gls{bci} systems relying on \gls{eeg} with the systematic review article of \citet{bci_review_arnau} only finding articles on classification problems for such systems.
Because of this, this thesis which focuses primarily on \gls{eeg} based \glspl{bci} also focuses on classification problems.
\gls{cad} systems are used extensively in hospitals for the interpretation of biomedical images and have been studied ever since computers were invented.
The most common example of a \gls{cad} system is the classification of lung images as being either from a lung cancer patient or not, often also highlighting the nodules used for this classification.
These pipelines are very similar to the ones used for \glspl{bci}, which are further discussed in Chapter \ref{ch:processing_signals} and \ref{ch:bci_pipeline}.


\begin{figure}[ht]
  \begin{minipage}{\textwidth}
    \centering
    \begin{subfigure}{0.95\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/introduction/cad_pipeline_ml.png}
        \captionsetup{width=0.9\linewidth}
        \captionsetup{justification=centering}
        \caption{General pipeline for \gls{ml} based \gls{cad} system.}
        \label{fig:cad_pipeline_ml}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.95\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/introduction/cad_pipeline_dl.png}
        \captionsetup{width=0.9\linewidth}
        \captionsetup{justification=centering}
        \caption{General pipeline for \gls{dl} based \gls{cad} system.}
        \label{fig:cad_pipeline_dl}
    \end{subfigure}
    \captionsetup{width=0.9\linewidth}
    \captionsetup{justification=centering}
    \caption{General pipelines of a \gls{cad} system used for classification. A \gls{ml} approach is called a two-step approach as it exists from feature extraction and classification. A \gls{dl} approach is called a one-step approach as it combines both of these steps into a singular classification algorithm.}
    \label{fig:cad_pipeline}
  \end{minipage}  
\end{figure}

A \textit{two-step} approach in \gls{cad} systems denotes the use of regular \gls{ml} for classification.
This means that there is both a feature extraction step and a regular classification step.
Feature extraction is the process of representing the often highly dimensional and unstructured raw data using characteristic properties.
These representations are often chosen by the designer of the system rather than learned from data and can take a significant time to efficiently develop.
These features are then used for learning by the regular \gls{ml} classifier.
Alternatively, a \textit{one-step} approach in \gls{cad} systems denotes the use of \gls{dl} in the pipeline.
\gls{dl} differentiates itself from the previously discussed two-step \gls{ml} approach by working directly on the, optionally preprocessed, data rather than a feature representation of the data.
Intuitively, many \gls{dl} models are created in a way such that earlier layers in the model represent some form of feature extraction whilst later layers are often purely there for classification. 
This approach is interesting as it doesn't require the time-consuming feature extraction process where good features have to be found by the developer of the system.
\gls{dl} approaches in \gls{cad} systems have also been proven to outperform state-of-the-art \gls{ml} approaches \citep{CAD_ml_dl_kbs}.
However, \gls{dl} models are more challanging in terms of explainability and interpretability as further discussed in section \ref{subsec:processing_signals_common_issues_exaplainable}.

Relating this back to \glspl{bci}, which have a very similar pipeline, a typical \gls{ml} approach often relies on a form of \gls{csp} for feature extraction.
This technique is quite old being introduced by \citet{first_csp} around 30 years ago.
Likewise, the regular \gls{ml} classification used is often a type of \gls{svm}.
Once again, this technique was first introduced by \citet{first_svm} around 30 years ago.
Over the years, \gls{csp} has evolved and many extensions such as \gls{fbcsp} by \citet{eeg_model_fbcsp} have been introduced.
Likewise, \gls{svm} has seen many extensions and improvements \citep{svm_extension1, svm_history}.
This has resulted in the combination of these two relatively old techniques, but with recent extensions, performing as state-of-the-art in \gls{bci} applications using \gls{ml} approaches.
Likewise, when using a \gls{dl} approach in the \glspl{bci} pipeline, \glspl{cnn} are often used.
This technique is again a rather old one, being first described by \citet{first_cnn} over 40 years ago.
Just as \gls{csp}, \glspl{cnn} has seen multiple extensions and improvements over the year, just as other \gls{dl} approaches.
For instance, \citet{rl_activation_function_compare} discussed how changing the activation function from CReLU to ReLU6 offered a 35\% performance increase while keeping other components fixed for certain experiments relying on a \gls{nn} in a \gls{rl} setting.
Thus, these improved versions of older concepts have enabled far better performance making it possible to create more capable \gls{bci} systems.

This doesn't mean that all approaches used for processing the data in \glspl{bci} rely on decades-old techniques that have improved over the years.
One interesting and relatively new approach is the use of \gls{tl} from drastically different domains.
Previously, \gls{tl} was mostly used in \glspl{bci} to train a model on data which may originate from different users performing similar but not necessarily identical tasks.
This general model is then further refined on a specific patient and task, transferring the knowledge acquired from the previous data to the new data.
When done correctly, this can provide far better performance compared to learning on the new data alone for problems where data is limited \citep{bci_review_arnau}.
As available data specific to \glspl{bci} applications remains limited, some recent research has gone into transferring knowledge from completely different domains to \gls{bci} specific data.
\Citet{tl_cnn_eeg} used a model pretrained on images and transferred it to \gls{eeg} data for a \gls{mi} task with promising results.
Other attempts at transferring knowledge from other domains, such as natural language, have also been made \citep{thesis_wolf}.

% todo: Semi-supervised learning methods use both labeled and unlabeled data. Their objective is to learn a supervised learning task, even in cases where only a small amount of training data is available. Usually, semi-supervised approaches learn the structure of the training data to become able to generate more (artificial) training points (Aznan et al 2019), that are used for conventional supervised learning in a second learning phase. Self-supervised learning (Jing and Tian 2019) is a similar approach which is currently gaining traction in the larger ML community. This technique was previously used to learn the relevant structure in EEG data by first learning an unsupervised pretext task, after which the model is further trained on the target task with labeled data (Banville et al 2020, Kostaset al 2021). The remainder of this review will focus on supervised learning methods.

% | | | | | | | | | | | | |

\subsubsection{More open-source datasets and code}
\label{subsubsec:bci_gaining_popularity_improved_data_processing_open_source_data_code}

% well discussen dat bij arnau Unfortunately, only five papers fit the ideal profile that we defined for publications on control applications that use DL methods. From a reproducibility perspective, most publications can be reproduced from the provided descriptions. (e.g.  ideal publication profile)

% The most common form of ML is supervised learning, in which we assume that the data is presented as a set of input-output pairs, a dataset, which we call labeled data, as each input is labeled with its corresponding output.

% TODO HIER verder doen, note: teruglinken aan wolpaw's criteria perfect bci

% Kort zeggen dat er nu veel libraries bestaan wat testen en extenden makkelijk maakt
% mss ook link naar https://paperswithcode.com/

%how to gather and share data for biosignal control research. Several publications also do not report their results properly to allow for the reproduction of performed experiments and to provide support that the developed model is suited for real-time decoding in a real-world setting. Evaluation of research prototypes is also insufficient to take the system’s technology readiness level beyond a proof-of-concept (POC).

% Typically, task-specific data should be gathered, as publicly available data is often unsuited for the training of a model for a specific control system. Following the right procedures greatly facilitates the later stages of data processing and ensures better reproducibility of the research if the data used for training a model cannot be shared publicly

% Training a neural network is therefore an optimization problem, for which many well-known algorithms and software libraries exist of which PyTorch7 , in Python and C++, and TensorFlow8 , in Python, are the most well-known.

% Therefore, low-confidence labelled data is often used in a semi-supervised fashion as explained by \citet{deep_learn_low_label}.

%UIT bci_review_arnau

TODO

% old text --

Many great \gls{ml} and \gls{dl} libraries and frameworks exist, perhaps the most famous python \gls{ml} library is scikit-learn by \citet{sklearn}.
MNE by \citet{mne} is a well-known library used for exploring, visualizing and analyzing \gls{eeg} data.
Even many \gls{eeg} classification specific \gls{ml} and \gls{dl} libraries exist \citep{eeg_model_eegnet, eeg_model_esi, eeg_model_fbcsp, eeg_model_hbm, eeg_model_ssvep}.
Publicly available datasets for \gls{eeg} data also exist, the experiments in this paper will use one by \citet{eeg_data}.
Combining these available resources makes it easier than ever to have satisfactory \gls{eeg} classification accuracy in a very reasonable amount of code and time.
These available resources are a massive bonus for the \gls{bci} field when used correctly.
The latter is easier said then done, as section \ref{sec:processing_signals_interpreting_ml} will address further when talking about \gls{ml} in \gls{bci} applications and the issues it has.


% - - - - - - - - - -
% summary
% - - - - - - - - - -

\subsection{Summarizing the cycle of increasing popularity}
\label{subsec:bci_gaining_popularity_summary}

% arnau zegt trend in omhaangde papers dl for bc system wss door improved software en hardware en succes of dl in andere domeinenen dus corresponds +-

% korte samenvatting van section Growing scientific and commercial interest in BCIs in zijn geheel

TODO

% ---------------------------------------------- 
% USE CASES
% ---------------------------------------------- 

\section{Common use cases for BCIs}
\label{sec:bci_common_use_cases}
% some practical examples of \gls{bci} systems that have been developed

% uitleggen er bestaat ook EMG is the most commonly used non-brain signal maar probleem met bv handicap
% uitleggen verschil research dat invasive is en non invasive en dat full control system is met applicatie vs gewoon accuracy scores of medical apps zoals cad voor sleep apnea detection etc (dus validated met real world application)
% van arnau: meest common robot arm control > drone control (a drone can be the well-known quadcopter (Redrovan and Kim 2018), but this can also refer to ground vehicles (Lu et al 2020) and robots (Aznan et al 2019) that can move according to the operator’s commands.) > bci spellers maar ook andere dingen zoals smart home control en virtual reality control en meer
% One publication uses EEG for wheelchair control (Zgallai et al 2019)
% aanpassen naar nu echt use cases bespreken vs linken
% The application that is most common for EEG control is robot arm control
% Figure 4 arnau heel interessant
% reffen naar bci_review_arnau voor betere systematic approach
Previous sections addressed some of the recent commercial applications from \glspl{bci}.
Whilst these are great examples of how the technology can be used by the general population, the medical applications of \glspl{bci} remain very important to the field, if not of most importance.
\gls{eeg} signals originate from the medical field and many of the successes in the field are related to helping people with certain diseases and/or disabilities.
This section will highlight some of the major areas where \glspl{bci} can improve the quality of life for these people.

% - - - - - - - - - -
% diseases
% - - - - - - - - - -

\subsection{Preventing, monitoring and controlling diseases with BCIs}
\label{subsec:bci_common_use_casesdiseases}

% Medical applications, such as sleep staging or pathology detection, that are unrelated to control.

\Gls{eeg} trials are often used to diagnose brain disorders.
Especially seizure-related disorders such as epilepsy are often diagnosed through \gls{eeg} readouts.
But also other neurological disorders such as the locked-in syndrome rely on \gls{eeg} amongst others to be correctly identified.
Even the psychological field uses \gls{eeg} as a physiological measuring tool to aid in the diagnosis and treatment of patients, although psychiatrists should be aware of the limitations \gls{eeg} has for them \citep{eeg_for_psychiatric}.

As \gls{eeg} is used for a wide variety of diagnoses and as input data for most \glspl{bci}, much research has gone into how \glspl{bci} can be used as an aid for medical diseases.
\Citet{bci_applications} gives an overview of the most common use cases for \glspl{bci}.
In general, \glspl{bci} is used for three different reasons in medical applications: prevention, detection/diagnosis and rehabilitation/restoration.

One popular example of prevention relates to traffic accidents.
According to \citet{traffic_deaths}, traffic accidents were the number 1 cause of death for children and young adults.
Whilst many types of equipment are already in place to prevent traffic accidents from occurring, such as speed cameras and breathalyzers, it has been studied how \glspl{bci} can be used as a prevention measure as well.
The earlier discussed research by \citet{early_bci_drowsiness} that was one of the first attempts at a truly portable \gls{bci}, measured driver's drowsiness levels.
Such information can be used to alert or even enforce drivers to take a break from driving when drowsiness levels are too high.
Other research includes that by \citet{eeg_dangerous_situation_car} who has discovered that emergency situations can be classified faster from \gls{eeg} data than the user's response.
This was done through a driving simulation and was found to have an accuracy of about 70\%.
\Citet{eeg_motion_sickness} developed a system that could estimate motion sickness levels, which in turn could again be used as an alert for drivers to take a break from driving.
These three examples show how \glspl{bci} can be used in a variety of ways for the prevention of traffic deaths.
Many more applications exist for the prevention of this phenomenon and others using \glspl{bci}.

\Gls{cade} and \gls{cad} using medical imagery are widely used for diagnosis and treatment monitoring in oncology and other fields.
Comparable systems exist using \gls{eeg} data amongst others for diagnosis aids.
Whilst these do acquire and process brain signals to output a classification, the classification itself is not directly used nor is the output directly connected to other systems.
This makes calling diagnostic systems using \gls{eeg} data a stretch of the definition in some regards.
Nonetheless, the previously given example of the commercial Muse headset for sleep tracking is one example of a detection and diagnostic system that can be classified as a \gls{bci}.
It detects irregular sleep patterns, allows for diagnosing certain sleep disorders and can interact with the user to prevent or suppress the found phenomena in the future.
\Citet{eeg_sleep_apnea} have developed a similar system to detect sleep apnea from \gls{eeg}, but don't call their system a \gls{bci}.
\Citet{bci_sleep_apnea} also developed a system to detect sleep apnea but they do call it a \gls{bci}.
This shows that the definition of a \gls{bci} is not strict.
However, all of these systems make use of similar methodologies compared to more clear \gls{bci} systems.


% reset emg gls
\glsreset{emg}

Restoration of lost mobility and environmental control is where \glspl{bci} shine.
As most prostheses rely on \gls{emg}, a muscle-based \gls{biosignal}, for controlling them, they do not apply to patients who don't have muscle control anymore.
Luckily, \gls{bci} are often used as novel interaction methods using brain signals, which enables such patients to regain previous levels of mobility and control.
Section \ref{subsec:bci_common_use_casesextending_medical_system}, \ref{subsec:bci_common_use_casesprostheses} and \ref{subsec:bci_common_use_casesnovel_interaction} give some more insight on how \glspl{bci} are used regain lost mobility and environmental control.
As \citet{bci_rehabilitation} discuss, \glspl{bci} can also be used to guide patients in rehabilitation through brain plasticity.
Brain plasticity, or neuroplasticity, is the brain's ability to adapt itself based on experience.
\Glspl{bci} could show patients which regions of the brain are used and which types of brain signals are present.
This information could then be relayed to the patient through various means so that it induces neuroplasticity.
Such systems are still in development and require sophisticated neurological expertise that falls outside the scope of this master thesis.
The overview provided by \citet{bci_rehabilitation} provides a great starting point for further literature on this manner.
In a similar manner, pedaling \glsfirst{mi} tasks have been studied recently as they seem to have a great potential for lower-limb recovery.
The works by \citet{pedal_mi_rehabilitation1} and \citet{pedal_mi_rehabilitation2} discuss such systems in greater detail and are also an example of how \glspl{bci} can be used for rehabilitation.

It is noted that many more \gls{bci} applications exist for preventing, monitoring and controlling diseases than those discussed.
The work by \citet{parkinson_stroke_reduction} is another great example of how \gls{bci} can be used for rehabilitation.
The work by \citet{bci_in_medicine} also highlights some related \gls{bci} work in medicine.

% - - - - - - - - - -
% extending medical system
% - - - - - - - - - -

\subsection{Using BCIs to extend existing medical systems}
\label{subsec:bci_common_use_casesextending_medical_system}

\Glspl{bci} can be used in a wide variety of applications.
Even in non-trivial domains, they can find their usages as a standalone system or as an extension to existing systems.
To demonstrates the latter, this section discusses how \glspl{bci} can be used as an extension to classical hearing aids for an improved user experience.
A more trivial extension to existing robotic prostheses and exoskeletons is also addressed.


According to \citet{hearing_aids_noise_reduction} over 450 million people suffer from disabling hearing loss.
Most solutions to hearing loss rely on a microphone to capture environment audio which is then amplified and played through a speaker that is placed in or near the ear.
This microphone can be integrated inside the speakers and thus form a stereo setup located at the ears of the patient.
This is not always ideal when there is a lot of ambient noise.
Sometimes using an external directional microphone placed close to the audio source of interest can form a solution.
This can be a microphone placed on the desk of a professor teaching in a filled room or the speakers connected directly to an audio source such as a television.
However, this solution is not applicable in all situations.
Thus, most hearing aids include some noise suppression on the microphones directly to filter out ambient noise and amplify noise coming from human speech.
\Citet{hearing_aids_noise_reduction_mandarin} evaluated such noise suppression for Mandarin-speaking users and found the results to be good but not ideal.
\Citet{bci_hearing_aid_direction} have shown that a \gls{bci} can be used to determine which speaker a user is listening to by analysing directional queues.
This information is useful, as it can optimize the microphones to pick up speech from that area and algorithms could optimize for the sounds the user is focusing on.
It is noted \citet{bci_hearing_aid_direction} discuss how a long waiting time to determine the area of interest challenges the practical usability of their system as of now.
Nonetheless, it shows one of many non-trivial ways a \gls{bci} could be used as an extension of existing systems to improve them.

% reset emg gls
\glsreset{emg}

Perhaps the most studied and promising extension \glspl{bci} can fulfil in existing medical systems lies in the interaction with robotic prostheses or exoskeletons.
Most of the current robotic prostheses and exoskeletons rely on muscular activity in the body.
This muscular activity can then be measured by \gls{emg}, the data of which can be used to control the robotic prosthetic.
For example, patients who have lost (part of) their arms but have functioning muscular activity in the remaining body part, can use this remaining muscular activity to control robotic prostheses.
\Citet{emg_prosthetics} discuss the design and development of such a system based on \gls{emg}.
Some of the processing techniques are similar to those of \gls{eeg} driven algorithms.
Alternatively, when the limb is still intact but the control over (part of) the limb is lost or extra support is needed, an exoskeleton may be used.
Just like robotic prostheses, most exoskeletons rely on \gls{emg}.
A thesis by the German \citet{emg_exoskeleton} highlights the fundamentals of \gls{emg} based exoskeletons.

As was already touched upon in section \ref{subsec:bci_common_use_casesdiseases}, \gls{emg} measurements are not applicable for all patients.
In particular, people who have neurological diseases limiting the production of the required muscular based \glspl{biosignal} fall outside the scope for these solutions.
However, due to the developments in \glspl{bci}, the viability of robotic prostheses and exoskeletons for these patients has been steadily on the rise.
\Citet{bci_prostheses} give an in-depth systematic review of upper and lower limb exoskeletons and robotic prostheses controlled by \gls{eeg}-based \gls{bci}.
\Citet{bci_prostheses} address the high risk associated with failed instructions for robotic prostheses and exoskeletons.
Indeed, compared to a misclassification with P300 spellers, the risks that can follow from misinterpreted instructions of exoskeletons and robotic prostheses are of such a degree that even high accuracy systems might not be good enough.
\Citet{bci_prostheses} also highlight that whilst multi-label classification of \gls{eeg} is possible with considerable accuracy in an offline lab setting, the number of detectable classes is limited in a real-time and real-life environment.
Because of this, \gls{eeg}-based systems in these applications still have some challenges to overcome to match the precision and reliability of \gls{emg} counterparts.
Whilst improvements regarding these aspects have been made since the work of \citet{bci_prostheses} was published, the main challenges remain to this day, especially when using affordable systems.
Because of this, widespread adoption of \gls{eeg}-based exoskeletons and robotic prostheses is still very limited.

% - - - - - - - - - -
% novel interaction
% - - - - - - - - - -
% TODO: mergen met volgende section note dat nieuwe title dus tekst anders

\subsection{Using BCIs as replacement for unusable interaction methods}
\label{subsec:bci_common_use_cases_bcis_replace_unusable_interaction}

The previous section highlighted how \glspl{bci} can be used to extend existing medical systems.
When working with exoskeletons and robotic prostheses, the \gls{bci} systems provide a novel interaction method for these devices that normally rely on \gls{emg} or other sources for input.
Many of the successful \gls{bci} applications consist of providing novel interaction methods with existing systems.
It could be argued that almost all of the literature proposed \gls{bci} applications boil down to making a novel interaction method of some sort.
Opposed to the discussed \gls{eeg}-based exoskeletons and robotic prostheses, whose risk currently leads to limited real-life applications, less risk imposing \gls{bci} applications do find their use as novel interaction methods in real-life already.

The P300 spellers discussed earlier are examples of novel interaction methods that aim to replace keyboards, especially for those who don't have the required capabilities to operate them \citep{p300_spellers, p300_spellers_review}.
Whilst wrong classifications in a speller application could result in unpleasant situations, it is clear that the risk involved is far smaller than exoskeletons for example.
As the name suggests,  P300 spellers make use of \textit{P300 signals} which are a type of \glsfirst{erp}.
As is further discussed in section \ref{subsec:biomedical_signals_type_of_signals_erp}, a P300 signal is a positive bio-electrical wave measurable with \gls{eeg} around 300ms after a stimulus occurred.
The stimulus used is often a flashing pattern on a monitor, of which there are multiple shown in a matrix form.
The users have to focus on the element of the matrix that they want to select and appropriate algorithms can extract this selection from \gls{eeg} data.
\Citet{p300_speller_real_life} performed a usability study on 20 \gls{als} patients in a real-life like environment.
According to \citet{p300_speller_real_life}, most participants achieved over 70\% accuracy, which is in line with the findings of \citet{p300_spellers_review} and \citet{p300_speller_real_life2} in similar studies amongst other types of patients.
More interestingly, even though the accuracy wasn't extremely high, all participants of the experiment by \citet{p300_speller_real_life} succeeded in the given tasks.
This is in part due to our ability as a human to understand typo's in words and sentences relatively easily.
Another important factor is that most of these systems make use of auto-correct software to help combat faulty classifications.
Besides auto-correct software, state-of-the-art text prediction is also a crucial part of these systems as it can almost double the efficiency of P300 spellers.
\citet{p300_speller_real_life} has found that the use of word predictors raised the mean number of correct symbols per minute from 3.6 to just over 5.
Whilst 5 symbols per minute is still a lot slower compared to regular keyboard input, it enables useful communication for those who can't communicate through regular means.
As \citet{p300_speller_real_life2} have shown, P300 spellers can be used by \gls{als} patients with satisfactory results in a pleasant manner for the user.
\Citet{p300_speller_real_life2} have shown equal results for \gls{dmd} patients.
In general, P300 spellers are often used as they have a low learning curve that can quickly enable a patient to regain some communication skills.
The reason these systems have a low learning curve and can be quickly deployed is due to their simple user interface and a combination of a system that generalizes well and that has been studied thoroughly for the use of \gls{tl}.
Early examples of using \gls{tl} for P300 related \glspl{bci} include those by \citet{p300_speller_tl}.
It is noted that eye-tracking is a viable alternative for P300 spellers in most cases and research has been put into combining the two, such as the work by \citet{p300_eye_tracking_speller}.

The focus on user experience by \citet{p300_speller_real_life2} is an important factor of a real-life case study.
User experience is often overlooked by initial \gls{bci} system proposals, where the focus is often on numerical measures such as accuracy, speed and \gls{fn} or \gls{fp} rates.
However, good working \glspl{bci} can cause psychological burden and other side-effects on the patients using them which an initial \gls{poc} might not reveal.
This gives rise to some ethical challenges, some of which are discussed in section \ref{sec:bci_ethical}.
As time passes, the user might move to a more capable and sophisticated system that has a steeper learning curve, higher cost and is more demanding for the user.

As P300 signals are relatively easy to detect through \gls{eeg}, it is one of the most studied signals from \glspl{erp}.
Many other \gls{bci} applications are based on P300 signals then just spellers.
One such example is the \textit{Facebrain} application by \citet{facebrain}.
Facebrain provides an \gls{eeg}-based novel interaction method with the social media platform Facebook.
In essence, it's a regular P300 speller with the first screen(s) representing possible actions to take on the platform.
When text input is required, a regular P300 speller user interface is presented.
This allows a user to operate almost all of Facebook's functionalities with only a P300-based \gls{bci}.
The application by \citet{facebrain} is one of many that shows the same strategy and classification algorithms as P300 spellers can be used for a wide variety of applications by changing the meaning and functionalities of the shown matrix elements.
The matrix elements could even be overlapped on top of an image to have intuitive motion control, a methodology used by \citet{p300_drone} for their P300 controlled quad-copter.

\glspl{erp} and the measurable signals they produce, such as the P300 signal, are only one of many sources for detectable brain signals.
In general, \gls{erp} related signals are easier to detect reliably, as the stimulus can be controlled, giving a hint when and where to look for signals and what to look for.
However, P300 and \glspl{erp} in general also have their issues and limitations.
The \gls{bci} handbook by \citet[Chapter~26]{bci_handbook} discusses the crowding effect, adjacency problem, repetition blindness and user discomfort amongst other issues \glspl{erp} have.
Most problems arise from the often limited space for sending stimuli without overlap and the changing behaviour of both the brain and participant's experience after a prolonged session where many stimuli have been applied.

An alternative to \glspl{erp} is using a mental phenomenon called \gls{mi} as source of signals for a \gls{bci} system.
\Gls{mi} is the process in which a person generates brain activity in the motor cortex merely by imagining motor movements.
Section \ref{subsec:biomedical_signals_type_of_signals_motor_imagery} explains in further detail how \gls{mi} is not dependent on an external stimuli nor actual motor movements.
This makes \gls{mi}-based \glspl{bci} extra appealing as they don't require external stimuli and are applicable for people with motor disabilities.
\Citet{first_mi} were the first to experiment with the idea of using \gls{mi} in an \gls{eeg} classification task.
Since then, many \gls{mi}-based \glspl{bci} have been proposed.
\Citet{bci_mi_robot_arm} proposed a \gls{mi}-based \gls{bci} to control a robot arm system.
Their research is interesting in two ways.
First, they use only three distinct \gls{mi} classifications: imagined right-hand movement, imagined left-hand movement and imagined foot movement.
These three controls enable the user to select eight different possible actions through a menu where two options are always shown that can be controlled using either an imagined left-hand movement or an imagined right-hand movement.
Scrolling through the menu to show two other possible actions is possible through the imagined foot movement.
This shows that with the right system design few controls can still allow for many actions to be taken.
Secondly, they found that experienced users have better overall classification performance which indicates that \gls{mi} is something that can be trained.

A more recent and more complex \gls{mi}-based \gls{bci} system is the vehicle control system by \citet{bci_mi_four_wheel_drive} which recognizes four possible actions: left, right, throttle and brake.
There are three very interesting aspects in the work by \citet{bci_mi_four_wheel_drive}.
First, they use two distinct classifiers for the \gls{eeg} data.
One makes a distinction between left and right through a typical \gls{mi}-based \gls{bpnn} whilst the other classifies throttle and brake behaviour using the subject’s threshold value of the average band power.
Secondly, an additional system is in place to reduce the risk of wrong classifications in the system.
This additional system is a type of collision detection and avoidance system that uses four ultrasonic wave radars and a camera.
The rationale behind this additional system is that the car would operate more like a semi-autonomous system that is responsible for a safe ride whilst the input of the \gls{bci} system is used to steer this semi-autonomous car in the right direction.
This additional system is required as the accuracy of around 84\% for the throttle and brake classification and 89\% for the left and right classification is not enough for a reliable system.
Finally, they use an interesting data collection method to train the classifiers on a user-per-user basis.
They configured a driving simulator where the user has the freedom to perform any action they want through a classical steering wheel and pedal setup.
The user should synchronously think about the action they want to perform to generate \gls{mi} data and they have to perform the effective action, as to be able to label the data.
Whilst this is an interesting approach, it is limited in the fact that it requires the user to be able to operate a steering wheel and pedals at the same time, which is not the case for classical target users of these systems.

Far more types of brain signals exist for use in \glspl{bci} than those discussed in this section.
Section \ref{sec:biomedical_signals_type_of_signals} will go into further detail on the different types of brain-signals that can be used.
For a more exhaustive list of all different approaches to using \glspl{bci} as novel interaction the reader is advised to consult one of many systematic reviews, books and other materials already available \citep{bci_review_book_chapter, bci_review, bci_in_medicine, bci_history, bci_review_monkey, bci_handbook}.
From the works these materials discuss, it should become apparent that most short-term goals of \glspl{bci} still lie in improving the quality of life for people with disabilities.
However, the rise in popularity of \glspl{bci} in the gaming industry and amongst other big tech companies as discussed in section \ref{subsec:bci_gaining_popularity_big_tech} shows there is a potential future where \glspl{bci} find more real-life use-cases in other fields as well.
Many of the current research also looks into combining multiple technologies to limit risk, increase the number of classification classes, create a more pleasant training experience and more.
It is important to stress that the research field of \glspl{bci} is not as new as some of the more commercial companies and publishers would like to portray it is.
Because of this, some of the claimed breakthroughs should be taken with a grain of salt.
One such example is the use of \glspl{bci} with monkeys.
Neuralink, the earlier discussed Elon Musk company, has published a YouTube video\footnote{\url{https://www.youtube.com/watch?v=rsCul1sp4hQ}} in 2021 demonstrating a monkey playing pong using the \gls{bci} by Neuralink.
The video quickly gained millions of views, far more than most papers in the \gls{bci} field will ever reach.
As a result, this video without a backing paper or proper explanation of the process was covered as highly innovative and groundbreaking by many news outlets.
However, similar setups have already been made in the past.
For example, \citet{bci_monkey_arms} demonstrated monkeys taking control over two avatar arms simultaneously, a task that is arguably even harder to accomplish and has an appropriate peer-reviewed paper backing it.


% merge this below with previous section


It was argued in section \ref{subsec:bci_common_use_casesextending_medical_system} that the risk involved when working with exoskeletons and robotic prostheses is too high for current \gls{bci} systems to be reliably used.
The \gls{bci} controlled car from \citet{bci_mi_four_wheel_drive} discussed in section \ref{subsec:bci_common_use_casesextending_medical_system} demonstrated how risk of a \gls{bci} system can be greatly reduced by using an additional system responsible for only allowing safe actions.
Similar ideas could be used for robotic prostheses to reduce the risk involved.
\Citet{bci_mi_robotic_arm_collision_avoidance} proposed such a hybrid system to control a robotic arm not only through a \gls{mi}-based \gls{bci} but also by using obstacle avoidance algorithms to reduce the risk of harmful contact, computer vision for object detection to get a better idea on the wanted interaction and eye-tracking to gather extra information surrounding user's intention.
Hybrid systems like the one by \citet{bci_mi_robotic_arm_collision_avoidance} are very promising as they can greatly reduce the risk involved in many \gls{bci} systems, such as prostheses related applications, whilst also increasing the overall accuracy of the system.

Whilst limb prostheses such as robotic arms are one of the most common types of prostheses, they are only a fraction of all prostheses in existence.
Everything from dentures and hearing aids to artificial breasts can also be labelled as a type of prostheses.
Visual prostheses such as bionic eyes are another type of prostheses and they are being studied heavily in the \gls{bci} field.
Not only can \gls{bci} systems improve visual prostheses, many of the existing visual prostheses could be seen as a special type of \gls{bci} system as a whole.
Both the works by \citet{bci_blind_assist_review} and \citet{bci_vision_assist_review} give an overview on the progress in visual prostheses in the \gls{bci} field.
These \glspl{bci} are often invasive that can stimulate the brain and other parts of the body, as opposed to only reading brain activity.
Through the simulations or other means, the user can regain some form of vision from these \gls{bci} systems.
Second Sight is one of few companies that has commercially made visual prostheses with \gls{fda} approval.
It is discussed in the overview on \gls{bci}-related vision restoration systems by \citet{bci_vision_assist_review}.
The international trial by \citet{second_sight_trial} on the products of Second Sight shows promising results, although it is noted the study is performed by Second Sight employees and not by an independent research team.
The exact working of visual prostheses or, more specifically, Second Sight products is not of interest for this work, but the recent decisions of Second Sight company reveal one of the largest risks of invasive \glspl{bci} and \glspl{bci} in general.
Due to the discontinuation of some of the Second Sight products, hundreds of users are left without product support for a system that shaped their everyday life.
Besides this, the now non-functioning product is still present inside their body.
The issues and ethical questions this brings to the table are discussed further in section \ref{subsec:bci_ethical_e_waste}.

% - - - - - - - - - -
% other use cases
% - - - - - - - - - -

\subsection{Commercial and other use cases}
\label{subsec:bci_common_use_commrcial_and_other}
% al vermelde porn en vr maar ook andere
TODO

% ---------------------------------------------- 
% SMALL PROJECTS
% ---------------------------------------------- 

\section{Opportunities and obstacles for BCI research}
\label{sec:bci_opportunities_obstacles}
% Hoe verschilt dit met use cases? Wss doordat hier focus op hoe live improvement en challanges etc
% Mss iets a la ups and downs of BCI research noemen? Of attractivenes en ... van BCI met dan hier link naar multidisciplanary ook

As technology evolves, it has often been the case that people with certain disabilities benefit from the evolution as well.
Take the evolution of live captions as a recent example, it has found its way directly into the Android smartphone operating system.
Whilst initially implemented for users to enjoy video content in situations where they can't listen to the audio, people with hearing difficulties now have a direct way to enjoy more content too.
The push for autonomous cars will allow those that are traditionally unable to drive a car to finally enjoy the freedom a car can offer as well without being dependent on others to do so.
Object and scene recognition algorithms made for optimizing smartphone cameras can also be used as a way of describing what is on a photograph for those who have limited vision.

Whilst it is clear from the previous sections that research in \glspl{bci} has its roots in medical applications, more commercial applications are currently being explored as discussed in section \ref{subsec:bci_gaining_popularity_big_tech}.
These commercial applications have a larger potential audience, which will probably result in more sales.
In general, hardware and software that is produced and used on a larger scale cause market competition which in term often lowers prices whilst increasing quality.
This is bound to also make medical-oriented applications of \glspl{bci} more accessible and of better quality.
It would also allow for smaller creators with a limited budget to create meaningful, quality-of-life improving applications.
This has been the case with smartphone applications for a long time.
Simple applications such as a colour picker in the camera app can aid people who have colour blindness in determining whether a banana is ripe or not.
Small applications by individual developers relying on location changes can remind those with short-term memory loss if they have not forgotten essential things such as locking the door.


More and more open-source \glsfirst{dl} libraries tailored towards \gls{eeg} such as the ones by \citet{eeg_model_hbm} and \citet{eeg_model_eegnet} have been introduced.
These \gls{dl} libraries can often work on raw \gls{eeg} data directly, which allows developers who don't have much domain experience to make interesting and good performing classification pipelines or even make new discoveries in the field.
Publicly available \gls{eeg} dataset such as the one by \citet{eeg_data} makes it possible for developers to work on a pipeline without needing the monetary investment in \gls{eeg} measuring equipment.
If desired, the affordable headsets by OpenBCI and others, further compared in section \ref{subsec:biomedical_signals_measuring_equipment}, make it possible to have \gls{eeg} measuring equipment with good open-source libraries for well under 1000 euros.
These smaller projects do not only have the potential to be of big impact for very specific users, they often reveal common issues and interesting alternative approaches in the \gls{bci} field.

% - - - - - - - - - -
% motivating examples
% - - - - - - - - - -

\subsection{Motivating examples using consumer-grade BCIs}
\label{subsec:bci_opportunities_obstacles_motivating_examples}

As discussed above, good open-source libraries, datasets and even measuring hardware have made the entry to the \gls{bci} field easier than ever before.
Some of the open-source \gls{dl} libraries tailored towards \gls{eeg} classification work well on raw \gls{eeg} data, which allows for meaningful classification accuracy without the need of understanding all domain-specific properties of \gls{eeg} data required for classical preprocessing.
The question remains whether which or even if, real-life applications are possible on consumer-grade \gls{bci} systems.
In an ideal world, such applications should be fully configurable and usable by the end-user without the help of a domain expert and the system should be maintainable without exhaustive preliminary knowledge. 
Many works have demonstrated the potential of these \gls{bci} systems but the lack of widespread adoption suggests there are still hurdles to overcome for them to become a reality.
For this reason, this thesis focuses on providing a solid foundation to the \gls{bci} field, a \gls{poc} application to demonstrate how a working system can be implemented and a thorough viability discussion of these systems in their current state.

Multiple studies comparing different aspects of these cheaper consumer-grade systems to the more traditional medical-grade \gls{bci} systems have already been done, as is further discussed in section \ref{sec:biomedical_signals_measuring}.
In general, cheaper systems work with a lower electrode count and those electrodes also have a lower signal quality.
Whilst this means the hardware is of lower quality, cheaper consumer-grade systems can reach usable levels of accuracy as shown by \citet{openbci_vs_medical} and \citet{openbci_eeg_sensor_evaluation} for the Texas Instrument ADS1299 chip, commonly found in consumer-grade hardware such as the offerings from OpenBCI.
Similarly, studies have been done on different types of electrodes as already touched upon in section \ref{subsec:bci_gaining_popularity_better_measuring} and further discussed in section \ref{subsec:biomedical_signals_measuring_equipment}.
These electrode comparison studies have shown that the gap between easy-to-use and affordable dry electrodes and the more superior but harder to use and often more expensive wet electrodes is shrinking \citep{wet_vs_dry, dry_electrode_status, wet_dry_comparison_experiment}.
However, these findings often follow from very controlled experiments in lab-like environments.
This is to be expected, as most comparisons aim to eliminate as many random factors as possible.
However, this means that these experiments don't give great insight into the real-life usability and applicability of these cheaper \gls{bci} systems.
This section will focus on some work that demonstrates which real-life applications are possible on consumer-grade \gls{bci} hardware and how they are possible.
These works were motivational examples for this master thesis.
They give a more thorough vision of what types of applications could be possible with consumer-grade systems in their current form, often highlighting the issues that are still present with them.
Most of these works are centred around OpenBCI hardware, the manufacturer of some of the more successful low-cost \gls{biosignal} measuring devices as further discussed in section \ref{sec:biomedical_signals_measuring}.

% | | | | | | | | | | | | |

\subsubsection{Step-by-step implementation of a binary MI classification model by Peterson et al}
\label{subsubsec:bci_opportunities_obstacles_motivating_examples_binary}

\Citet{cheap_bci_feasibility} aimed to show the feasibility of a complete low-cost consumer-grade \gls{bci} system.
\Citet{cheap_bci_feasibility} did this by discussing the steps required to make an offline binary \gls{mi} classification system using common low-cost consumer-grade hardware.
The classification distinguished the \gls{mi} task of a grasping movement with the participants' dominant hand and a rest condition.
They compare three different approaches in growing complexity: \gls{csp}, \gls{pfbcsp} and \gls{ptfbcsp}.
The work by \citet{cheap_bci_feasibility} has five interesting aspects worth highlighting here.

First, whilst they did use the OpenBCI Cyton and Daisy board they did not use the 3D printable Ultracortex Mark IV headset from OpenBCI.
They argued that this is due to the Ultracortex Mark IV headset becoming uncomfortable quickly due to the use of dry electrodes combined with limited adjustability.
This complaint on user comfort for the Ultracortex Mark IV headset is recurring with other authors including the one from this master thesis.
Because of this, they opted for wet EEG electrodes attached to a very flexible and far more comfortable Electro-Cap.
\Citet{cheap_bci_feasibility}  opting for wet electrodes is slightly odd, considering the user experience of having to apply a conductive gel before each use is not great and therefore not favourable for general real-life \gls{bci} applications.

Secondly, for the data gathering of their system \citet{cheap_bci_feasibility} used a \textit{common office room}, rather than a lab-like environment.
Except for a 3D printed holder for the OpenBCI board, there was no specialized shielding in place to protect the electrodes or OpenBCI boards from unwanted interference.
They argue this makes the data more realistic, and whilst true, it is important to note there is still far less stochasticity than there would be in real life.
The office room and hardware were identical for each of the participants in the data collection stage.
The room was free of external stimulus as it was separated from the experiment organisers and the participant was \textit{left alone} for the entire trial.
All participants were right-handed and thus the dominant hand used for the \gls{mi} task was always the right hand.
Adding to all of this, the dominant hand of the participant was placed inside a box to not allow them to see their hand.
It could be argued these factors still make the data more lab-like than home-like.
Still, \citet{cheap_bci_feasibility} found that the non-shielded regular office caused significant noise.
In one trial the electromagnetic noise amplitude (50 Hz or 60 Hz depending on location) was four times higher than the meaningful EEG data.
Other types of noise were also present, proving their environment was indeed far less ideal than a lab environment, which indeed makes it more realistic.

Third, during the data collection, a \gls{emg} system was also in place.
This \gls{emg} system was used to filter out samples of the collected \gls{mi} data where the movement was also physically performed, meaning it wasn't true \gls{mi} data.
Whilst this forms an interesting approach to data filtering when collecting training samples, the extra needed hardware that is only used during training is probably a tough sell in a commercial application.
However, it does automate the data filtering process used, which is more realistic for widespread use than the expert-based data filtering in most literature. 

Fourth, they used the KVIQ-10 questionnaire by \citet{kviq} to determine how \textit{good} a participant would be in \gls{mi}, a task that is proven to be harder for some individuals.
Interestingly, \citet{cheap_bci_feasibility} found no statistically significant correlation between the KVIQ-10 score of participants and the found classification accuracy.
Thus, whilst they did find significant inter-participant differences in accuracy, determining beforehand if a participant will have pleasant accuracy results beforehand through the KVIQ-10 questionnaire by \citet{kviq} wasn't reliable for \citet{cheap_bci_feasibility}.
This is an issue, as knowing this information beforehand can give a potential buyer a better indication if the system would be fit for them or not.

Finally, even though the data acquisition happened under guidance in the work of \citet{cheap_bci_feasibility}, there were still issues with the recordings.
Out of the 12 participants, there were multiple moments where connection loss with the OpenBCI main board occurred, one participant where a mechanical defect rendered the data useless and one where there were \gls{emg} detected movements of the hand for more than half of the \gls{mi} tasks rendering the trial of that patient useless as well.
Whilst the latter is an issue independent of the hardware used, the other two are probably bigger issues on the cheaper hardware than the more reliable medical-grade hardware.
Part of the reason medical-grade hardware is about 5 to 10 times as expensive for a similar experiment is due to the medical-grade hardware requiring certifications, which also guarantee some form of quality and reliability. 

To conclude, the work by \Citet{cheap_bci_feasibility} discusses the creation of a complete low-cost consumer-grade \gls{bci} system.
This system consists of the OpenBCI measuring equipment where the dry electrodes on the 3D printed Ultracortex Mark IV are replaced with electrodes in a more comfortable Electro-Cap.
The effective classification of the system is a binary \glsfirst{mi} classification on whether or not the participant imagines a grasping movement of the hand or not.
\Citet{cheap_bci_feasibility} achieved an average accuracy between 70\% and 85\%, being higher as the approach used becomes more complex.
It is important to note that the evaluated models are on a patient-per-patient basis.
This means that each patient has their own uniquely trained model and that data from the same patient is used in the evaluation process.
Whilst the binary nature of the system makes it hard to find viable real-life applications, the performance reached is almost identical to those of medical-grade systems and follows from a less lab-like environment than is typically the case.
The system proposed by \Citet{cheap_bci_feasibility} is of less importance in their work, rather the steps and pitfalls highlighted are of value.



% | | | | | | | | | | | | |

\subsubsection{Multiclass classification methods for motor imagery EEG data}
\label{subsubsec:bci_opportunities_obstacles_motivating_examples_mi_classification}

The above discussed paper by \citet{cheap_bci_feasibility} provides great insight on the steps required to develop an \gls{eeg}-based consumer-grade \gls{bci} which uses \gls{mi} related signals.
Since \citet{cheap_bci_feasibility} uses a binary classification model, there are only two possible outputs of the classifier, which is too limited for most applications.
However, the lack of training samples combined with noisy and often high-dimensional data of \gls{eeg} makes multi-class classification considerably harder than binary using any \gls{bci} system.
Adding to this, the consumer-grade hardware suffers even more from noise and \gls{mi} data is notorious for being noise-prone in \gls{eeg} data.
This makes the choice for a binary classifier by \Citet{cheap_bci_feasibility} understandable.
\Citet{cheap_bci_feasibility} also opted for an approach where a model is trained per user.
This is often done in the field as it makes for far higher accuracy for that specific user.
This does however mean that each new user should also undergo a training data collection procedure to have a custom-trained model as well before being able to use the system.
This is less than ideal for commercial \gls{bci} systems and can have a physiological burden in medical applications.

To combat these points, many multi-class classification pipelines have been proposed in literature that work well with \gls{mi} related \gls{eeg} data \citep{fbcnet, eeg_mi_model_mussi, eeg_mi_model_lda_csp, eeg_mi_model_deep_cnn_spatial_filters, eeg_mi_model_image_based, eeg_model_fbcsp, eeg_model_hbm, eeg_model_esi, eeg_model_eegnet}.
These pipelines generally work on both consumer-grade and medical-grade systems, although consumer-grade systems can often benefit more from specific noise-reduction steps in the pipeline.
Some of the proposed pipelines also focus on generalisation to allow a general model which has usable performance for completely new users.
Whilst such models have poorer performance overall, they can be used as an initial model to allow the user to explore the possibilities of the \gls{bci} model without having to undergo the often tedious training data collection process. 

A complete in-depth review of all of the different approaches that can be taken to classify \gls{eeg} data falls outside the scope of this research paper.
\citet{eeg_analysis_methods_epilepsy_review} compared \glsfirst{lr}, \glsfirst{ann}, \glsfirst{svm} and \glsfirst{cnn} for a binary classification task of either being epileptic \gls{eeg} data or not.
Whilst this is again a binary classification that is more tailored towards \glsfirst{cad}, the techniques used in the experiments are also often used in the multi-class classification of \gls{eeg} data for other \gls{bci} purposes.
\Citet{eeg_analysis_methods_epilepsy_review} found that \glspl{ann} performed best for their classification task.
In general, \glspl{ann} and other \gls{dl} models such as \glspl{cnn} have proven to be successful at \gls{eeg} data related tasks.

Because of this, many of the current state-of-the-art models for \gls{eeg} classification rely on \gls{dl} models.
Especially classification pipelines that include \glspl{cnn} have proven to be successful for \gls{eeg} classification.
From the previously referenced pipelines, \citet{fbcnet, eeg_mi_model_mussi, eeg_mi_model_deep_cnn_spatial_filters, eeg_model_hbm, eeg_model_esi, eeg_model_eegnet} make use of \glspl{cnn}.
Although \glspl{cnn} are only part of a good \gls{eeg} classification pipelines.
\Citet{fbcnet, eeg_model_fbcsp} used \glspl{cnn} after a Filter-Bank approached, which has satisfactory accuracy for \gls{eeg} classification and \gls{mi}-related \gls{eeg} data in specific.
Some complex pipelines that rely on \gls{cnn} can be too demanding for real-time classification, something that is needed for an online \gls{bci} system.
Pipelines such as the one by \citet{eeg_model_eegnet} have been developed to use \glspl{cnn} in such a way that real-time classification is possible.

\glsreset{csp}
Other types of pipelines incorporate techniques based on spatial patterns, with \glspl{csp} being a very popular method used for \gls{eeg} data.
The pipelines by \citet{eeg_mi_model_lda_csp, eeg_mi_model_deep_cnn_spatial_filters} use such spatial pattern techniques, as well as the previously discussed work by \citet{cheap_bci_feasibility}.
a \gls{csp} approach is often combined with a \gls{cnn} for classification but can also be combined with more classical \gls{ml} techniques such as a \gls{svm} model or a \gls{lda} \citep{eeg_mi_model_lda_csp}.

As discussed, many approaches to \gls{eeg} data classification exist and not all of them can be listed here.
Some more noteworthy pipelines include the one by \citet{eeg_mi_model_image_based}.
Their approach is interesting in the fact that it visualizes \gls{eeg} data so that an image processing method can be used for classification.
Whilst this yields okay results, it doesn't improve upon the state-of-the-art.
However, other novel approaches such as the one by \citet{eeg_model_esi} which incorporates the technique of \gls{esi} have shown to be as good as or even better than state-of-the-art in specific experiments.



% | | | | | | | | | | | | |

\subsubsection{Connecting the classification model to physical devices}
\label{subsubsec:bci_opportunities_obstacles_motivating_examples_physical_devices}

A complete \gls{bci} system could be thought of as a combination of three different components: a data collection process, the data processing step and the effective performing of actions by the system.
The previously discussed motivating works focus mainly on how to collect \gls{eeg} data, especially for \gls{mi} tasks, and how to process this data to classify it.
Whilst these two steps are already very challenging, a component to go from the classification labels to effective actions should also be in place to form a complete \gls{bci} system.
For this last component, the labels provided by the classifier can be seen as an incoming input stream.
Whilst it is intuitive to link certain labels with specific actions, for example, a left movement is linked to an imagined left-hand squeeze and a right movement is linked to an imaged right-hand squeeze, this isn't strictly required.

One of the challenges with \gls{bci} systems is the limited classification labels that can reliably be extracted.
It is also the case that it is easier to distinguish between imagined left-hand movement and imagined right-hand movement than it is to differentiate between imagined left-hand thumb movement and imagined left-hand index finger movement.
Because of this, less intuitive controls that are easier to classify and offer higher efficiency should often be considered.
To illustrate this, imagine the movement of a robotic arm to pick up objects using \gls{mi} related \gls{eeg} data through a classifier that can distinguish left-hand squeeze, right-hand squeeze and an idle state.
Intuitively, one might want to obtain complete control over the robotic arm but the limited inputs render a direct mapping between the classification label and all possible movements of the arm impossible.
A menu for movement options could be made such as shown in Figure \ref{fig:example_arm_control_bad}.
The imagined right-hand squeeze could be used to scroll through the menu options whilst the left-hand squeeze could be used to select that option.
Stepping away from the idea of wanting to control every movement of the robotic arm can improve the efficiency of the system.
With grasp detection algorithms such as the one proposed by \citet{graspnet}, the detection of objects of interest for the robot arm to interact with can be detected through computer-vision algorithms.
Using such algorithms, another way of controlling the robotic arm could be using the imagined right-hand squeeze to switch between detected objects and using the imagined left-hand squeeze to pick them up, as depicted in Figure \ref{fig:example_arm_control_good}.
Highlighting the item detected by the arm could for example be done by the arm hovering over that specific item.
Since the task of the robotic arm was picking up items, both systems would succeed, but the latter would be more efficient.
Whilst this is a very naive example, it should illustrate that special thought should be put into this last component of the \gls{bci} system to maximize accuracy and efficiency.
% Dus eigenlijk dat context aware systems met variable mapping van classification labels aan actions zorgen voor betere control dan fixed dingen, hoewel soms intuitive moeilijker kan zijn
%  high-level controller that will map a user command to a sequence of device actions or a lowlevel controller that can directly use the output from the decoder model to perform a device action. but allows for a reduction of the number of commands that need decoding when dealing with a high number of degrees of freedom (Kuhner et al 2019). The latter only needs to send the command to the device, but requires an output for each possible degree of freedom of the device (George et al 2020).
% For example, (Kuhner et al 2019) use depth sensing cameras to track object and robot positions, which allows users to think of which object they want to grasp, without communicating the object’s position to the robot control system.


% TODO: make experimental design image
\begin{figure}[ht]
  \begin{minipage}{\textwidth}
    \centering
    \begin{subfigure}{.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{example-image-a}
        \captionsetup{width=0.9\linewidth}
        \captionsetup{justification=centering}
        \caption{\gls{bci} system offering complete control but poor efficiency.}
        \label{fig:example_arm_control_bad}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{example-image-b}
        \captionsetup{width=0.9\linewidth}
        \captionsetup{justification=centering}
        \caption{\gls{bci} system offering limited control but great efficiency.}
        \label{fig:example_arm_control_good}
    \end{subfigure}
    \captionsetup{width=0.9\linewidth}
    \captionsetup{justification=centering}
    \caption{Contrast between a complete control design of a robotic grasping arm that is less efficient to operate and one that is more efficient to operate but has less control. Considering the task of grasping items, both systems would succeed but the more efficient one would likely be more pleasant to use.}
    \label{fig:example_arm_control}
  \end{minipage}  
\end{figure}

As discussed, the field of \gls{bci} is highly interdisciplinary.
The \gls{eeg} data collection part relies heavily on neuroscience for the working of the brain to know what signals can be extracted and where they originate from.
To extract those signals, engineers should develop hardware capable of measuring the tiny electrical current that is \gls{eeg}.
Whilst those engineers also focus on noise reduction, computer scientists are also needed for preprocessing to further reduce this noise.
The data processing is mainly a computer scientist task, although knowledge from neuroscience can be very helpful in this step as well as insight on the flaws of the hardware.
The final component, where effective actions are performed, can relate to a wide variety of sciences once again.
For example, the robotic arm proposed before requires computer vision knowledge for grasp detection, engineering knowledge to make the arm and general computer science knowledge to create an intuitive link between classification labels and action controls.
Because of this, it is often the case that research focuses mainly on improving one of these three components rather than the whole system.
Take for example the \gls{bci} system proposed by \citet{complex_hand_few_classes}.
It has a significantly sophisticated robotic hand that functions almost completely as a human hand does.
The effective hardware used for the complete \gls{bci} system, including the processing unit, are also well detailed and shows thorough knowledge as it proposes a very affordable custom system.
However, the classification algorithms used and the user interface proposed could benefit from future extensions to make the complete \gls{bci} system even better.

This is by no means a criticism to \citet{complex_hand_few_classes} but demonstrates the interdisciplinary nature of \gls{bci} systems and how researchers that are specialized in one of these disciplines will outperform certain aspects of a \gls{bci} system will leaving room for improvement in other aspects.
Likewise, many papers on the data processing and classification algorithms for \gls{eeg} data are from computer scientists.
Those papers often don't even include the final component where effective actions are taken, or the proposed system is limited to simulations because the development of robotics falls outside the scope of their discipline.
This interdisciplinary of the \gls{bci} field is part of what makes it so fascinating yet also sophisticated.
Commercial institutions that can hire many of the required professions will likely accelerate the creation of true complete \gls{bci} systems with state-of-the-art in each component of the system.


% - - - - - - - - - -
% automated learning
% - - - - - - - - - -

\subsection{The potential of an AutoML variant for BCI pipelines}
\label{subsec:bci_opportunities_obstacles_automl}

% Another interesting development in the research and development of ML pipelines is AutoML (He et al 2021). This new approach to the design of ML pipelines allows for automated exploration of alternative methods for the different components of the pipeline. While this has not been developed yet in the context of biosignal control, it has proven to be a valuable tool for researchers and companies that are lacking the expertise to develop the whole pipeline themselves. Companies such as Google are now providing AutoML solutions as part of their cloud infrastructure13. Having such a framework for biosignal decoding pipeline development could significantly boost the deployment of real-world applications.

TODO

% - - - - - - - - - -
% testing issues
% - - - - - - - - - -

\subsection{A lack of standardized testing}
\label{subsec:bci_opportunities_obstacles_lack_of_testing}

% mss weg en  naar 6 bij "common issues" en dan hier maken "other common development issues"

% ook optimistic results

%DL models have many components and hyperparameters that need to be chosen by the implementer. Performance of models can sometimes greatly vary between software and hardware that are used in training and evaluation. Evaluating the performance of a model requires great care in selecting the appropriate metrics to report. Additionally, evaluating the full control system requires more investigating than only assessing the decoding performance of the DL model. Recommendations will be formulated regarding reporting standards in relevant scientific fields.

% this should at least be a basic user study to validate that the control system improves the user experience of the targeted user group compared to alternative approaches. Only a small proportion of publications perform a user study, which emphasizes that there is a clear gap in current evaluation methodologies. The heterogeneity in evaluation methodologies also makes control system designs harder to compare without reimplementing the full control system. Having such guidelines should encourage researchers to adhere to a detailed user evaluation for POC prototypes and allows for the comparison of control systems for the same application types.

% Since user opinions can be subjective, it is essential to have a heterogeneous group of participants, as mentioned in section 4.3.

% dus vooral objective mesaures zoals accuracy nu

% Reviews by Biet al(2019), Rashid et al(2020)and Al-Saegh et al (2021) among others discuss the differences between offline and online systems in more detail. Therefore, stress tests should be performed to evaluate the model under conditions that reflect reallife conditions. Unfortunately, such stress tests have not been developed yet in the context of biosignal control.

% While there are no standardized guidelines regarding the evaluation of prototypes, good-practice examples can serve as a template for the recommended evaluation methods for a biosignal control system. User study is belangrijk, i.e., hoe ervaart persoon het systeem wat soms ook stom evaluated bv; s. However, we noticed that several papers do not evaluate the device on a target population. For example, both Nguyen and Chung (2018) and Kuhner et al (2019) only include able-bodied participants while their applications target paralyzed persons.

%UIT bci_review_arnau

Evaluating and comparing different \gls{bci} systems is not easy.
This is in part due to a \gls{bci} system consisting of different components.
Thus, evaluating a \gls{bci} system purely on the tasks it can achieve and with which accuracy doesn't tell all that much.
Evaluating the system for the above discussed three different components can improve on this, but a lack of standardized testing also makes this rather challenging.

Take for example the comparison and evaluation of the performance of the measuring equipment of a \gls{bci} system.
Many \gls{bci} systems use the noisy \gls{eeg} modality, but others make use of \gls{emg} and other modalities which can be more or less prone to noise. 
Some make use of easy to use dry electrodes, whilst others make use of wet electrodes that require considerable preparation.
One could use the \gls{snr} to compare and evaluate the \gls{eeg} measuring device.
However, this doesn't take into account affordability and user experience.
A higher \gls{snr} but with more predictable noise is also preferred over a lower \gls{snr} with completely stochastic noise.
Comparing the classification accuracy for specific tasks might seem like a better option then, but how do you make a fair classification pipeline for all different headsets.
It should become visible that there is no easy solution to evaluate the (e.g. \gls{eeg}) measuring equipment of a \gls{bci} system.

Similar issues arise for the data processing component.
For starters, whilst relatively complete datasets such as the one by \citet{eeg_data} exist, there is no real \textit{reference dataset} for \gls{bci} systems.
In computer vision, for example, popular datasets such as MNIST \citep{mnist} and ImageNet \citep{imagenet} are often used to train and evaluate image classification algorithms.
But \gls{eeg} classification algorithms are optimised to the input data.
For example, some work better with noisy data whilst others are optimized for \gls{mi} specific classification tasks and so on.
Do you train the models on a single patient and test them on the same patient, or do you test for generalisability?
Do you allow it to run on very capable hardware or limited but very affordable hardware?
Again, it should be apparent that there is no straightforward way of evaluating the data processing step. 

This thesis only aims to highlight the issue that arises when trying to evaluate and compare different \gls{bci} systems.
These problems such as a standardized testing suite are open problems in the field and one that could greatly improve the field's work once a solution is proposed and accepted by the community.
For now, focusing on reproducibility and specifying the data used and potential ways it makes tasks easier or harder is the best most researchers can do.
It becomes apparent that a 90\% accuracy for a model that can be used on any user without re-training is far more impressive than one custom made for a specific user.
Likewise, 80\% accuracy on non-lab environment data with high stochasticity is far more impressive than the same accuracy on the best measuring hardware in the most controlled environment. 

% - - - - - - - - - -
% interdesciplinary issues
% - - - - - - - - - -

\subsection{Challenges from the highly interdisciplinary nature of BCI systems}
\label{subsec:bci_opportunities_obstacles_interdisciplinary}



TODO

% - - - - - - - - - -
% repeatability issues
% - - - - - - - - - -

\subsection{Difficulties with repeatability and reproducibility of experiments}
\label{subsec:bci_opportunities_obstacles_repeatability_reproducibility}

% zoals discussed in section subsubsec:bci_gaining_popularity_improved_data_processing_open_source_data_code Unfortunately, only five papers fit the ideal profile that we defined for publications on control applications that use DL methods. From a reproducibility perspective, most publications can be reproduced from the provided descriptions. maar dus wel al beter maar nog niet ideal

TODO

% - - - - - - - - - -
% variation issues
% - - - - - - - - - -

\subsection{Complex data variability and user-training}
\label{subsec:bci_opportunities_obstacles_training_and_variability}

% An important issue researchers keep getting confronted with is the fact that there are still a lot of mysteries about the brain's inner workings, leaving many of the finer intercepted brain signals unexplained. \citet{brainmapping} states that the progress of mapping the brain and its billions of sensors and connections is accelerating yet still far from finished. This mapping would be a huge step in understanding the brain.

% User-training will also play an important role in the practical deployment of an application (Kuhner et al 2019). Users will not want to use a system that requires a long training time before being usable on a regular basis. Due to the non-stationary nature of the signals, users might have to re-train themselves and re-calibrate their device on every usage. These challenges are highlighted by the Cybathlon competition where one of the events is a race where participants have to complete a BCI task in the shortest time (McFarland and Wolpaw 2018, Perdikis et al 2018, Hehenberger et al 2021). Therefore, user training should be considered when designing the final control system, which is extensively discussed by Roc et al (2021).


% ---------------------------------------------- 
% ETHICAL CHALLENGES
% ---------------------------------------------- 

\section{Ethical challenges for BCIs}
\label{sec:bci_ethical}
% Duidelijk vermelden dat je geen expert bent
% TODO: do after first 3 chapters finished and some code made
% Interesting points: https://www.frontiersin.org/articles/10.3389/fcomp.2021.661300/full

SECTION TO BE COMPLETED IN A LATER STAGE, LOREM IPSUM PLACED FOR APPROXIMATED LENGTH.

TODO

% - - - - - - - - - -
% luddites
% - - - - - - - - - -

\subsection{The return of the Luddites}
\label{subsec:bci_ethical_luddites}

% note: ludites are not against tech, they are against it taking their profession that is hard to learn, look this up and perhaps link with "egoism" of doctors
% making the rich even richer
% https://www.history.com/news/who-were-the-luddites
TODO

% - - - - - - - - - -
% ads
% - - - - - - - - - -

\subsection{Advertisements based on your thoughts}
\label{subsec:bci_ethical_data_mining}

% TODO: Meta and other commercial companies that showed interest link
TODO

% - - - - - - - - - -
% hacking
% - - - - - - - - - -

\subsection{Hacking BCI systems}
\label{subsec:bci_ethical_hacking}

% TODO: https://link.springer.com/article/10.1007/s10586-021-03326-z
TODO

% - - - - - - - - - -
% personal identity
% - - - - - - - - - -

\subsection{Changing peoples personal identities}
\label{subsec:bci_ethical_identity}

% TODO: Discuss how the "blind" and "deaf" culture is a thing and how people that regain these capabilities feel as if they have lost their own culture
TODO

% - - - - - - - - - -
% confrontation
% - - - - - - - - - -

\subsection{Painfully confronting users with their brain}
\label{subsec:bci_ethical_confronting}

% TODO: Link to nature article findings and how user experience is really important
TODO

% - - - - - - - - - -
% e-waste
% - - - - - - - - - -

\subsection{E-waste inside your skull}
\label{subsec:bci_ethical_e_waste}

% TODO: nerdland reference

% second_sight_broken_ethics: https://spectrum.ieee.org/bionic-eye-obsolete
% bci_blind_assist_review: https://www.frontiersin.org/articles/10.3389/fnhum.2021.638887/full
% bci_vision_assist_review: https://link.springer.com/content/pdf/10.1007/s13311-018-0660-1.pdf
TODO

% ---------------------------------------------- 
% CONCLUSION AND PROPOSED SYSTEM
% ---------------------------------------------- 

\section{Chapter conclusions and proposing a three-signal system for basic controls}
\label{sec:bci_concolusion_and_proposing_ours}

% TODO: summary of this chapter
% Also discuss the order of things on paper

% TODO: discuss what system will be made in this paper
% MI instead of P300 due to user comfort and fatigue over time which decreases performance; e.g. https://www.scitepress.org/Papers/2020/88709/88709.pdf
% Robot example https://github.com/NTX-McGill/NeuroTechX-McGill-2019
% die wheelchair example uit thesis arnau?

\textbf{NOTE: this will be edited once the thesis is "finished"}

As discussed, this master thesis focuses on providing a great foundation for the knowledge required for working in the \gls{bci} field as a computer scientist.
The exhaustive literature review from this chapter should provide a great general introduction to the field and current state-of-the-art as well as challenges and promises of the field.
As touched upon in section \ref{subsec:bci_opportunities_obstacles_motivating_examples} and further discussed in section \ref{sec:processing_signals_interpreting_ml} many different pipelines and approaches exists for the data processing component of a \gls{bci} system.
Whilst some of the libraries available which make use of \glsfirst{dl} allow for raw \gls{eeg} input, the author of this paper believes it to be of importance to know the nature of this \gls{eeg} data to some extend.
For this, an introduction to \glspl{biosignal} and how they can be measured is given in the next chapter.
This deeper understanding of the data source ultimately leads to better design decisions in the data processing component.

Next, this thesis aims to give better insight into how a \gls{bci} system can be developed.
To accomplish this, a general \gls{bci} pipeline is discussed in chapter \ref{ch:bci_pipeline} to provide insight on the different components a \gls{eeg}-driven \gls{bci} needs.
Chapter \ref{ch:final_system} extends on this general \gls{bci} pipeline by proposing a three-signal system for live control.
Chapter \ref{ch:using_system} and \ref{ch:conclusion} aim to evaluate this three-signal system, taking into account the lack of generalized evaluation strategies as discussed earlier in section \ref{subsec:bci_opportunities_obstacles_lack_of_testing}