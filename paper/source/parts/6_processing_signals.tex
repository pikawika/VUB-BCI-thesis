% TODO:
%   - Kijk na of titels in header overflowen
% ----------  
% Questions:
%   - XXX


% In a new chapter, reset the GLS to once again use full version in first occurence
\glsresetall

\chapter{Decoding brain signals with machine learning}
\label{ch:processing_signals}

% ---------------------------------------------- 
% INTRODUCTION
% ---------------------------------------------- 
\section{Introduction to this chapter}
\label{sec:processing_signals_introduction}
% NOTE: "Introduction" exists in each chapter and gives short intro to chapter + what can be expected in chapter

The previous chapter, Chapter \ref{ch:biomedical_signals} discussed \gls{biosignal} and how bioelectricity is made in the human body.
Multiple modalities for measuring brain signals were discussed and it was discussed how \gls{eeg} seems like the most promising measuring modality for capturing \gls{elecbiosignal} from the brain in a \gls{bci} setting.
Chapter \ref{ch:biomedical_signals} also discussed that \gls{mi} is one of many methods to induce such \gls{elecbiosignal} activity in the brain, namely by causing \gls{ers} and \gls{erd}.
\gls{mi} and \gls{ers}/\gls{erd} were deemed interesting as it doesn't require the external stimuli that \gls{ep} do and applies to many people, even those with limited mobility.
However, it was also discussed that \gls{ers}/\gls{erd} following from methods such as \gls{mi} require extensive user training and are harder to detect than most \gls{ep} alternatives for inducing such \gls{elecbiosignal} activity in the brain.

This chapter will discuss how brain signals can be decoded using both traditional two-step \gls{ml} and one-step \gls{dl} in a supervised manner.
Whilst Chapter \ref{ch:bci} already highlighted multiple breakthroughs in this regard on an intuitive level, this chapter will provide more technical details.
First, the general pipeline for classifying brain signals and \gls{mi} \gls{eeg} in particular is discussed.
Then the role of \gls{ml} and \gls{dl} in this pipeline and some of the most important concepts from these technologies are discussed.
This chapter then goes over the process of evaluating and using the created and trained pipelines.
The chapter concludes by discussing some of the common issues encountered while creating these pipelines and the conclusions that can be made from this chapter.


% ---------------------------------------------- 
% GENERAL TRAINING PIPELINE
% ---------------------------------------------- 
\section{A general pipeline for classifying brain signals}
\label{sec:processing_signals_general_pipeline}

\begin{sidewaysfigure}
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/pipeline/brain_signal_pipeline_training.pdf}
        \captionsetup{width=0.9\linewidth}
        \captionsetup{justification=centering}
        \caption{Components of general training pipeline for brain signal classification annotated with common examples per component.}
        \label{fig:processing_signals_pipeline_ml}
    \end{subfigure}
    \hfill
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/pipeline/brain_signal_pipeline_predicting.pdf}
        \captionsetup{width=0.9\linewidth}
        \captionsetup{justification=centering}
        \caption{Components of general prediction pipeline for brain signal classification annotated with common examples per component.}
        \label{fig:processing_signals_pipeline_dl}
    \end{subfigure}
    \captionsetup{width=0.9\linewidth}
    \captionsetup{justification=centering}
    \caption{General training pipeline and prediction pipeline used for classifying brain signals.}
    \label{fig:processing_signals_pipeline}
\end{sidewaysfigure}

The general pipeline of classifying brain signals and \gls{eeg}-based \gls{mi} tasks in particular is similar to that of a \gls{cad} systems which was discussed in Section \ref{subsubsec:bci_gaining_popularity_improved_data_processing_better_ml_dl} and shown in Figure \ref{fig:cad_pipeline}.
Whilst the training pipeline and prediction pipeline for classifying brain signals consist of the same components, their input and output are different.
For this reason, this master thesis considers them as two separate pipelines.
The remainder of this section will discuss the components used in these brain signal classification pipelines and the techniques commonly used in each of these components.
Figure \ref{fig:processing_signals_pipeline} provides a visual overview of these pipelines and their components.

% - - - - - - - - - -
% Data acquisition
% - - - - - - - - - -

\subsection{Data source}
\label{subsec:processing_signals_general_pipeline_data_acquisition}

Assuming supervised learning, a \gls{ml} paradigm further discussed in Section \ref{subsec:processing_signals_ml_and_dl_tyes_of_learning_supervision}, input data for the training pipelines should include both the independent variables as wel the dependent variable.
When working with an \gls{eeg} \gls{mi} classification problem, these independent variables are the \gls{eeg} measurements of each channel whilst the dependent variable is the \gls{mi} task performed at a specific time point.
Multiple possibilities exist for providing these variables and the link between them.
Most open-source \gls{mi} \gls{eeg} datasets, such as the one by \citet{eeg_data} used in this master thesis, do this by providing the \gls{eeg} recordings of an entire session as a single 2D matrix (channels x measurement per time point) and the desired labels as an equal width vector containing the marker at any given time point.
The time points are dependent on the sampling frequency and denote the sample number counting from the first sample of the session.
The marker may be the current content of the screen which provides tasks to the user or other event-related information.
Figure \ref{fig:processing_signals_data_source_eeg} combines both the independent and dependent variables into a singular visualisation.

The prediction pipeline only expects the independent variables as its task is to predict the dependent variable.
In theory, these independent variables should be of the same format used during training, but in practice, they might originate from a different source or recording and as such might require additional steps during preprocessing to ensure at least an equal sampling frequency and channel distribution.
This master thesis assumes the device used during training and prediction is identical with equal settings used and as such doesn't require this type of preprocessing.

The prediction pipeline may work in an offline manner, as is the case for the experiments in this master thesis, or in an online manner.
When using offline prediction the data was already recorded and stored before being provided in its totality to the prediction pipeline.
In an online setting, the data is streamed to the prediction pipeline as it is being measured and the prediction pipeline should merge this incoming data to an object that is usable in the next stages itself.
For example, a buffer may be used to collect samples until one second is obtained and pass that to the next step.
In an online setting, windowing is often directly performed on the stream, as discussed next.
Other types of data formatting are possible but they should all provide the same information.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{../images/pipeline/eeg.pdf}
    \captionsetup{width=0.9\linewidth}
    \captionsetup{justification=centering}
    \caption{Visualisation of the \gls{eeg} recording from December 15 2015 overlayed with the provided markers for subject B in the open-source dataset by \citet{eeg_data}. The x-axis depicts the time in seconds, the y-axis depicts which channel of the recording is visualised and the colour overlay represents the active marker.}
    \label{fig:processing_signals_data_source_eeg}
\end{figure}

% - - - - - - - - - -
% Windowing
% - - - - - - - - - -

\subsection{Windowing}
\label{subsec:processing_signals_general_pipeline_windowing}

The data source as described in Section \ref{subsec:processing_signals_general_pipeline_data_acquisition} provides a continous signal over multiple channels.
To process these signals a mechanism has to be in place so that this continuous signal is split into discrete segments.
Such techniques are often referred to as windowing, but the neurophysiological field also refers to it as epoching.
The latter should not be confused with the meaning of epochs in a \gls{ml} setting.
Different types of windowing exist and three common approaches are illustrated in Figure \ref{fig:processing_signals_windowing}.
Using a fixed window surrounding known event points is trivial on the training data and results in the simplest classification task with the most consistent window labels from the three windowing techniques shown in Figure \ref{fig:processing_signals_windowing}.
However, when trying to predict outcomes, the point at which an event occurs has to be known as well.
This information may be known, for example during an offline \gls{mi} classification task or when using a fixed feedback loop in an online manner where actions from the user are accepted at fixed time intervals.

\begin{figure}[ht]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/pipeline/fixed_window.pdf}
        \captionsetup{width=\linewidth}
        \captionsetup{justification=centering}
        \caption{Fixed window surrounding a known event.}
        \label{fig:processing_signals_windowing_non_fixed}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/pipeline/non_overlapping_window.pdf}
        \captionsetup{width=\linewidth}
        \captionsetup{justification=centering}
        \caption{Non-overlapping sliding windows.}
        \label{fig:processing_signals_windowing_non_overlapping}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/pipeline/overlapping_window.pdf}
        \captionsetup{width=\linewidth}
        \captionsetup{justification=centering}
        \caption{Overlapping sliding windows}
        \label{fig:processing_signals_windowing_overlapping}
    \end{subfigure}
    \captionsetup{width=\linewidth}
    \captionsetup{justification=centering}
    \caption{Different types of windowing techniques.}
    \label{fig:processing_signals_windowing}
\end{figure}

A more intuitive but computationally harder windowing technique is using sliding windows.
A non-overlapping sliding window technique is shown in Figure \ref{fig:processing_signals_windowing_non_overlapping} and an overlapping technique is shown in Figure \ref{fig:processing_signals_windowing_overlapping}.
Both are trivial to apply to the independent variables but deciding which dependent variable should be related becomes a difficult task.
How much activity from the event should be included for the training window to be considered a sample of that event?
What happens when a window includes two distinct events?
These are questions that should be answered within the context of the application.
When using sliding windows, singular labels such as "task right" may be split into "task right start", "task right hold" and "task right end".

Many different windowing techniques exist that use far more complex strategies than the ones illustrated in Figure \ref{fig:processing_signals_windowing}, especially for controlling the boundaries of the window.
\citet{complex_windowing} discuss some of these more complex windowing techniques in more detail.
When done right, certain sliding window techniques can improve the performance of a \gls{mi} \gls{eeg} classification pipeline compared to even fixed windowing surround a known event, as shown by \citet{sliding_windows_better}.
However, starting a new sliding window at each time point may cause significant computational overhead, increasing both training and prediction time.
The latter can make the prediction pipeline too complex to be run on affordable, low-energy and portable computational hardware as desired by a \gls{bci} system doing local processing.
This master thesis will consider a fixed window of 0.5 seconds and 1.5 seconds surround a known event for both training and prediction.

% - - - - - - - - - -
% Preprocessing
% - - - - - - - - - -

\subsection{Preprocessing}
\label{subsec:processing_signals_general_pipeline_preprocessing}

Brain signals are non-linear as well as non-stationary signals and exact execution of the performed \gls{mi} tasks are bound to differ per subject as already discussed in section \ref{subsec:biomedical_signals_working_with_eeg_generalisation}.
Combining these properties with the poor \gls{snr} of \gls{eeg}, as discussed in Section \ref{tab:biomedical_signals_modalities}, means that raw \gls{eeg} measurements are hard to intepret, even by machines.
Luckily, as discussed by \citet{bci_review_arnau}, a \gls{dl} approach making use of sufficient layer, nodes and training should be capable of learning any mapping from input to output, including any manual preprocessing that can be done.
As such, \gls{dl} approaches can often work directly on this raw \gls{eeg} signal and raw signals in general.
This is one of the most promising aspects of \gls{dl} in multiple fields and it is the reason the one-step \gls{dl} approaches from this master thesis will use no preprocessing besides the \gls{ac} artefact removal that was already performed by the suppliers of the open-source database \citep{eeg_data}.
Traditional two-step \gls{ml} approaches do not have this property of being able to learn any mapping from input to output and as such require at least minimal preprocessing of the data to obtain usable results.
For this reason, many libraries providing the most basic \gls{eeg} preprocessing steps have been developed with MNE by \citet{mne} being the most popular for Python and used in this master thesis.
Some automated pipelines specifically for \gls{eeg} preprocessing have also been proposed, such as the PREP pipeline by \citet{prep_pipeline}. 

% | | | | | | | | | | | | |

\subsubsection{Frequency filtering}
\label{subsubsec:processing_signals_general_pipeline_preprocessing_filter}

One of the most common preprocessing operations done to \gls{eeg} signals is frequency filtering.
Frequency filters come in four main categories: low-pass filters, high-pass filters, band-pass filters and band-stop filters.
The working of these filters in the frequency domain is shown in Figure \ref{fig:processing_signals_filters}.
Again, many variants on how to exactly perform the filter exist.
Some use a harsh filter with no transition band whilst others use a transition band as visualised in Figure \ref{fig:processing_signals_filters}.
As further discussed by \citet{fir_iir_filter}, a first distinction is made between \gls{fir} and \gls{iir} filters.
Most common filter operations are using a band-stop filter to cancel out the \gls{ac} artefacts discussed in Section \ref{subsec:biomedical_signals_working_with_eeg_artefacts} and to filter out frequencies not of interest for the application.
Since these operations are so common they are often included directly in \gls{eeg} equipment with a hardware filter.
This master thesis uses a \gls{fir} filter design using the Blackman window method in some of its experiments to band-pass filter the signal to only include the \gls{mi} frequencies as discussed in Section \ref{subsec:biomedical_signals_working_with_eeg_brain_waves}.
Further details of this exact filter are not of interest for this master thesis and the MNE library supplied functionality is used to obtain the desired filter \citep{mne}.


\begin{figure}[t]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/pipeline/lowpass_filter.pdf}
        \captionsetup{width=\linewidth}
        \captionsetup{justification=centering}
        \caption{Low-pass filter.}
        \label{fig:processing_signals_filters_lowpass}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/pipeline/bandpass_filter.pdf}
        \captionsetup{width=\linewidth}
        \captionsetup{justification=centering}
        \caption{Band-pass filter.}
        \label{fig:processing_signals_filters_bandpass}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/pipeline/highpass_filter.pdf}
        \captionsetup{width=\linewidth}
        \captionsetup{justification=centering}
        \caption{High-pass filter.}
        \label{fig:processing_signals_filters_highpass}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/pipeline/bandstop_filter.pdf}
        \captionsetup{width=\linewidth}
        \captionsetup{justification=centering}
        \caption{Band-stop filter.}
        \label{fig:processing_signals_filters_bandstop}
    \end{subfigure}
    \captionsetup{width=\linewidth}
    \captionsetup{justification=centering}
    \caption{Different types of filtering techniques.}
    \label{fig:processing_signals_filters}
\end{figure}

% | | | | | | | | | | | | |

\subsubsection{Baseline correction}
\label{subsubsec:processing_signals_general_pipeline_preprocessing_baseline_correction}

Another common preprocessing operation is baseline correction on a window.
Baseline correction consists of taking a baseline period and determining the mean voltage of each electrode's measurements during that baseline.
This baseline is most often one or more seconds before an event occurs.
This mean voltage is then subtracted from the remaining signal of each respective channel.
Doing this normalizes each window such that it has a centre closer to zero.
This can help in reducing the non-stationary problem and is used for the traditional two-step \gls{ml} experiments in this master thesis with a baseline period of one second before the event.

% | | | | | | | | | | | | |

\subsubsection{Channel and data downsampling or upsampling}
\label{subsubsec:processing_signals_general_pipeline_preprocessing_subsampling}

Another type of preprocessing is channel subsampling and augmentation through interpolation.
This consists of removing channels not of interest as discussed in Section \ref{subsec:biomedical_signals_working_with_eeg_anatomy} or adding augmented channels by clever interpolation or other approaches from the existing channels.
When a certain channel is known to be bad or artefacts described in Section \ref{subsec:biomedical_signals_working_with_eeg_artefacts} are detected, it may be replaced by an augmented channel during the artefact period as a way of resolving the artefact.
Likewise, if the sampling frequency of \gls{eeg} equipment is too high or low, data subsampling or upsampling may be performed.

% | | | | | | | | | | | | |

\subsubsection{Other preprocessing techniques and preprocessing ordering}
\label{subsubsec:processing_signals_general_pipeline_preprocessing_orders}

There exist many other preprocessing techniques for signals and \gls{mi} \gls{eeg} signals in particular but these fall outside the scope of this master thesis.
Preprocessing can happen in other places of the pipeline than the one shown in Figure \ref{fig:processing_signals_pipeline}, for example, channel subsampling reduces dimensionality and is thus often done as soon as possible to limit unneeded computational overhead.
It is important to note that multiple preprocessing steps may be performed in sequence.
This means that the output of a previous preprocessing step is used in the next and as such the ordering of preprocessing steps can be important depending on the techniques used in the sequence.
It is also important to note that certain preprocessing techniques which learn parameters from the training data should use the same parameters for the prediction pipeline, as redetermining them on the prediction data may alter the data in a way unknown by the already trained classifier later in the pipeline.
Whilst often not the case for preprocessing techniques, this is a subtility of great importance in feature engineering, the next step in the pipeline.



% - - - - - - - - - -
% Feature
% - - - - - - - - - -

\subsection{Feature engineering}
\label{subsec:processing_signals_general_pipeline_features}

Feature engineering, or feature extraction, is the process of representing raw or preprocessed data by numerical features that carry information from the original data related to the problem.
The goal of feature extraction is to simplify a complex data structure by representing it as one or many features that are easier to interpret and/or learn.
This step is crucial in traditional two-step \gls{ml} classification approaches as even the preprocessed data is often too complex for traditional \gls{ml} classifiers to directly learn from.
This differs from preprocessing which aimed to improve the raw data quality, although for some of the discussed preprocessing techniques it could be debated that they are also a type of feature extraction.
As already addressed in Section \ref{subsec:processing_signals_general_pipeline_preprocessing}, some features rely on learned parameters, such as the $\mathbf{W}$ matrix for spatial filters discussed later in this section, these learned parameters should be reused in the prediction pipeline and not redetermined on the prediction data, as this will confuse the classification model and produce unwanted behaviour.

A simple but poor feature extraction technique for \gls{eeg} data would be representing the channels' measurements not by their raw data but by their minimum, maximum, median, first quartile and third quartile, much like a boxplot would.
Whilst this would be easy to interpret, it would carry too little information for a classifier to effectively learn anything but the simplest problems.
Finding appropriate feature extraction techniques is a hard task which has taken years of refinement and has ongoing refinement in many fields, including \gls{eeg} classification and other medical imaging fields \citep{CAD_ml_dl_kbs}.
\gls{eeg} feature extraction methods can be categorized by the domain they work in, namely the time domain, frequency domain, time-frequency domain or spatial domain.
The experiments in this master thesis will only consider \gls{csp} for feature extraction in the traditional \gls{ml} classification approaches, a spatial filtering technique closely related to \gls{pca} used for mainly spatial domain feature extraction.
As discussed in Section \ref{subsec:bci_gaining_popularity_improved_data_processing}, \gls{csp} derived features are commonly used in traditional two-step \gls{ml} classification and the \gls{csp} technique has seen many extensions over the years.
\gls{csp} is further discussed together with its extensions in Section \ref{sec:offline_bci_system_two_step_ml}.

The remainder of this section briefly discusses the feature extraction possibilities in each domain but a more detailed explanation falls outside the scope of this master thesis.
The reader is reffered to chapter 7 of the \gls{bci} book by \citet{bci_book} for an in-depth overview of many feature extraction techniques for \gls{bci} applications in far greater detail.
\Citet{eeg_features} compares the performance of multiple feature extraction techniques for epileptic seizure detection using \gls{eeg}.
\Citet{time_domain_eeg_features} compares multiple feature extraction methods for \gls{eeg}-based \gls{bci} applications in the time domain whilst \citet{timefreq_domain_eeg_features} does the same for feature extraction methods in the frequency and time-frequency domain.


% | | | | | | | | | | | | |

\subsubsection{Time domain feature extraction}
\label{subsubsec:processing_signals_general_pipeline_features_timedomain}

Temporal feature extraction methods work in the time domain, where the \gls{eeg} data is analysed as a time series of voltage measurements per channel.
This is most likely the representation of the data as it comes from the previous preprocessing step in the pipeline and as such doesn't require an additional transformation.
\Citet{time_domain_eeg_features} describes some relatively simple feature extraction methods in the time domain, namely the windows's \gls{mav} per electrode, the amount of times a \gls{zc} and \gls{ssc} occurs per channel and the cumulative \gls{wl}.
When all four of these relatively simple features are combined, surprisingly good accuracies are obtained through intrasession testing \citep{time_domain_eeg_features}.

Many more time domain feature extraction techniques exist and some more examples are given by \citet{eeg_features}.
\citet{eeg_features} discusses some other simple features, including those used by \citet{time_domain_eeg_features}.
For example, the \gls{wl} feature described by \citet{time_domain_eeg_features} is called \textit{total line length} by \citet{eeg_features} and provided in Equation \ref{eq:processing_signals_line_length}.
\Citet{eeg_features} also details more complex features based on the entropy of the signal such as \gls{pe}, \gls{apen}, \gls{fuzzen} and more.

\begin{equation}
    \label{eq:processing_signals_line_length}
    L(X) = \sum_{i=1}^{N-1} |X[i] - X[i - 1]|
\end{equation}


% | | | | | | | | | | | | |

\subsubsection{Frequency domain feature extraction}
\label{subsubsec:processing_signals_general_pipeline_features_freqdomain}

As the name suggests, frequency domain feature extraction happens in the frequency domain.
The frequency domain represents the measured \gls{eeg} signals in terms of frequency rather than time as was the case for the time domain.
To extract features in the frequency domain, the signal represented in the time domain must first be transformed to its frequency domain representation.
The most common way of going from the time domain to the frequency domain is through the use of a \gls{ft} \citep{fourier_transform}.
A  \gls{ft} has the nice property that it can be converted back to the time domain by using the \gls{ift}.
The theoretical \gls{ft} and \gls{ift} make use of integrals from $-\inf$ to $\inf$ and as such can't be directly used on real data.
Many methods have been proposed to estimate this full integral solution, with the \gls{dft} and \gls{idft} being the most common.
The \gls{dft} and \gls{idft} equations are given in Equation \ref{eq:processing_signals_dft} and \ref{eq:processing_signals_idft} respectively.
The output of the \gls{dft} ($X_k$) is a complex number that represents the amplitude and phase of a sinusoidal wave, representing the signal in the frequency domain.
The frequency of this sinusoidal wave is $\frac{k}{N}$ derived from Euler's formula.
\Citet{fast_fourier_explained} discusses the \gls{ft}, \gls{ift}, \gls{dft} and \gls{idft} in more detail.
\Citet{fast_fourier_explained} also discusses that the computation of \gls{dft} can be too complex for many applications and introduces the \gls{fft}, a faster variant of \gls{dft}.
\Gls{fft} is the algorithm that is most commonly used for effective conversion between the time and frequency domain in computer applications.

\begin{equation}
    \label{eq:processing_signals_dft}
    X_k = \sum_{n=O}^{N-1} x_n e^{\frac{-2 \pi i k n}{N}}
\end{equation}

\begin{equation}
    \label{eq:processing_signals_idft}
    x_n = \frac{1}{N} \sum_{k=O}^{N-1} X_k e^{\frac{2 \pi i k n}{N}}
\end{equation}

Once the signal is represented in the frequency domain, most of the frequency domain features are extracted from the \gls{psd}.
The \gls{psd} is a visualisation of the power levels of the frequency component present in the signal.
Figure \ref{fig:processing_signals_psd} show the \gls{psd} of the \gls{eeg} signals previously shown in  Figure \ref{fig:processing_signals_data_source_eeg}.
Note the sharp trough present at 50\gls{hz} due to the \gls{ac} artefact removal that is done by a band-stop filter at that frequency.
As discussed further by \citet{eeg_features}, the features extracted from the \gls{psd} include the energy, \gls{iwmf} and \gls{iwbw} among others.

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{../images/pipeline/psd.pdf}
    \captionsetup{width=0.9\linewidth}
    \captionsetup{justification=centering}
    \caption{\Glsfirst{psd} for the \gls{eeg} signal previously shown in Figure \ref{fig:processing_signals_data_source_eeg}. Only the C3, Cz and C4 channels are shown.}
    \label{fig:processing_signals_psd}
\end{figure}

% | | | | | | | | | | | | |

\subsubsection{Time-frequency domain feature extraction}
\label{subsubsec:processing_signals_general_pipeline_features_timefreqdomain}

Whilst it is possible to extract features from both the time and frequency domain and rely on the classifier to learn a mapping between them, attempts have been made at combining both domains.
For example, when further windowing the time domain signal into short time segments and using a \gls{ft} on those shorter time segments, a \gls{stft} is obtained.
\Gls{stft} assumes that those shorter time segments are stationary, even if the complete signal from which those time segments are taken was non-stationary.
This allows for using frequency-domain feature extraction on those shorter \gls{ft} signals.
This will result in features that represent frequency domain characteristics but are ordered in a time respective order.
These features could then be seen as individual data points in the time domain and thus can be further processed with time-domain feature extraction techniques.

However, the use of \gls{stft} in \gls{eeg} applications is limited as finding a balance between long enough time segments such that the \gls{ft} is meaningful but short enough so that enough time domain information is retained has been proven challenging.
A better alternative is using \gls{wt}, a technique that has been proven powerful in image compression and many other fields \citep{wavelet_transform_uses}.
Compared to the \gls{ft} that works with sinusoidal waves, \gls{wt} works with wavelets.
These wavelets are characterised by their scale and location.
The scale relates to the frequency domain whilst the location relates to the time domain, showing a clear link with the time-frequency domain.
Compared to \gls{stft}, \gls{wt} does not make any assumptions about stationarity.
The book by \citet{book_wavelet} discusses \gls{wt} in detail.
The technical details and related feature extraction methods of which fall outside the scope of this master thesis.

% | | | | | | | | | | | | |

\subsubsection{Spatial domain feature extraction}
\label{subsubsec:processing_signals_general_pipeline_features_spatialdomain}

As discussed in Section \ref{subsec:biomedical_signals_measuring_brain_modalities}, \gls{eeg} has a relatively poor spatial resolution.
This would suggest that feature extraction based on the spatial domain is bound to perform poorly as well, bet this is not the case.
Many \gls{bci} systems rely on features extracted from \gls{eeg} signals that were spatially filtered with techniques such as \gls{pca}, \gls{ica} and \gls{csp} \citep{bci_book}.
To understand spatial filters, it should be repeated that \gls{eeg} channels don't represent the value of a singular electrode but rather the output of applying a differential amplifier on two channels, as was discussed in Section \ref{subsec:biomedical_signals_measuring_brain_modalities}.
If all these channels have one electrode in common, an alternative set of channels can be created by weighing and combining the original channels \citep{bci_book}.
This is the main idea behind spatial filtering and can be mathematically represented as the matrix equation shown in Equation \ref{eq:processing_signals_spatial_filter}.
In this equation, $\mathbf{X}$ represents the 2D matrix of $N$ channels and $P$ samples.
$\mathbf{W}$ represents the weight matrix with $M$ spatial filters and $N$ channel weights.
Finally, $\mathbf{Y}$ represents the alternative set of channels with $M$ spatially filtered channels and $P$ samples.

There are both data-independent and data-dependent techniques for determining the weight matrix $\mathbf{W}$ of Equation \ref{eq:processing_signals_spatial_filter}.
In some regards, the average reference montage shown in Figure \ref{fig:biomedical_signals_eeg_montages} can be considered a data-independent spatial filter, as it uses a fixed, data-independent $\mathbf{W}$ matrix, namely one that averages all channels.
A more complex but comparable data-independent spatial filter is using one of many variants of surface Laplacian spatial filtering.
Intuitively, these types of Laplacian filters use only the electrodes at a certain spatial distance for determining the average.
Simple variants may consider each electrode in the region of interest equally important whilst others might use a weighted average based on the spatial distance of the electrode.
Surface Laplacian spatial filtering has proven successful in improving the source localisation capabilities of \gls{eeg} by filtering out the signals present in multiple electrodes and keeping only those unique to the electrode of interest \citep{improve_eeg_spatial_laplacian1, improve_eeg_spatial_laplacian2, improve_eeg_spatial_laplacian3}.


\begin{equation}
    \label{eq:processing_signals_spatial_filter}
    \begin{bmatrix} 
        y_{11} & y_{12} & \dots \\
        \vdots & \ddots & \\
        y_{M1} &        & y_{MP} 
    \end{bmatrix} = 
    \begin{bmatrix} 
        w_{11} & w_{12} & \dots \\
        \vdots & \ddots & \\
        w_{M1} &        & w_{MN} 
    \end{bmatrix}
    \begin{bmatrix} 
        x_{11} & x_{12} & \dots \\
        \vdots & \ddots & \\
        x_{N1} &        & x_{NP} 
    \end{bmatrix}
\end{equation}


However, by far the most commonly used spatial domain feature extraction happens on data after a data-dependent spatial filter such as \gls{pca}, \gls{ica} or \gls{csp} has been applied.
These data-dependent spatial filters optimize the $\mathbf{W}$ matrix from Equation \ref{eq:processing_signals_spatial_filter} based on measured \gls{eeg} signals.
\Gls{pca} creates a $\mathbf{W}$ matrix such that the resulting signal has the highest proportion of amplitude variance from the original signals matrix $\mathbf{X}$ \citep{bci_book}.
Whilst this can be successful, \gls{pca} only uses the values from the independent variables for creating the $\mathbf{W}$ matrix and as such the created matrix is not optimized for best discrimination of the dependent variable.
Imagine for example a $\mathbf{X}$ matrix that was not preprocessed to remove the \gls{ac} artefacts described in Section \ref{subsec:biomedical_signals_working_with_eeg_artefacts}.
Since this line current noise is so present, \gls{pca} will consider it as one of the most important \gls{pca} components even though it carries no information for the problem.
\Gls{ica} could be seen as a variant of \gls{pca} that wishes to create a $\mathbf{W}$ matrix such that the resulting signal consists of independent channels.
However, as described by \citet{bci_book}, using \gls{ica} forms multiple challenges in \gls{bci} applications due to its computational cost and often imperative way of determining the number of independent channels to be found.
Besides this, \gls{ica} also only rely on the independent variable and as such is not further considered for this master thesis.

\Gls{csp} is a type of spatial filtering closely related to \gls{pca} that does use the dependent variable to create a set of new channels that are optimized to solve the problem.
This makes \gls{csp} incredibly powerful and studied in \gls{bci} research, as already addressed in Section \ref{subsec:bci_gaining_popularity_improved_data_processing}.
\Gls{csp} will be discussed in further detail together with its extensions in Section \ref{sec:offline_bci_system_two_step_ml}.
\Citet{bci_book} provides a more in-depth overview of all three of these spatial filtering techniques.

% | | | | | | | | | | | | |

\subsubsection{The promise and downfall of feature extraction}
\label{subsubsec:processing_signals_general_pipeline_features_dl_link}

Manual feature extraction is done in what this master thesis refers to as traditional two-step \gls{ml}. 
These traditional two-step \gls{ml} approaches have some attractive properties but also some fundamental limitations.
Manual feature extraction such as the one discussed in this section mostly tries to implement human knowledge about a problem as an algorithm.
Features that are derived are those that an expert deems fit for describing and learning the problem.
This is great in terms of explainability and interpretability, as combined with the right \gls{ml} classification algorithm such as \gls{rf} it can give direct insight into how a prediction pipeline came to its conclusion.
This is desired in many fields, especially the medical one.
As described in Section \ref{subsec:processing_signals_common_issues_exaplainable}, explainability and interpretability could even become a requirement of general \gls{ai} applications.
As such, traditional two-step \gls{ml} still has significant ongoing research as is shown by the many alternatives on \gls{csp} that have been proposed, as further discussed in Section \ref{sec:offline_bci_system_two_step_ml}.

However, as discussed by \citet{CAD_ml_dl_kbs} for medical lung imaging applications, \gls{dl} that learns some form of features from data in an automated manner outperform traditional two-step \gls{ml} classification in many tasks.
This lies in the power of \gls{dl} being able to learn features that might be unknown by experts and thus can't be encoded for manual feature extraction.
Research in disease detection, such as \citet{attia} findings of using a \gls{cnn} to detect \gls{af} from normal sinus rhythm \gls{ecg} has shown just that.
Given the human understanding of the brain is still limited as discussed in Section \ref{subsec:bci_opportunities_obstacles_complex}, it is likely that the right \gls{dl} models will learn features that are far more descriptive of the problem but not yet understood or discovered by experts.
This is also likely the reason that \gls{cnn} based models, such as those by \citet{eeg_model_eegnet} and \citet{eeg_model_hbm}, have matched or even outperformed the capabilities of state-of-the-art traditional two-step \gls{ml} approaches that have taken years of refinement.
The main limiting factor for \gls{dl} is the lack of explainability and interpretability since these approaches are seen as black box approaches.
However, as \ref{subsec:offline_bci_system_one_step_dl_interpreting} will discuss in more detail, attempts have been made at offering some insight into the working of these models.
These attempts at clarifying what a \gls{dl} model learns can provide experts with a deeper understanding of the problem \citep{dl_book}.


% - - - - - - - - - -
% Classification
% - - - - - - - - - -

\subsection{Classification}
\label{subsec:processing_signals_general_pipeline_classification}

The last step of the general pipeline for classifying brain signals is the classification itself.
In the training pipeline, the classification model used will be trained by providing it both the independent variables processed in the previous pipeline steps and the dependent variables.
The goal of the classification model is to learn a mapping from those independent variables to the dependent variable.
As discussed, the independent variable is either the features extracted from preprocessed data in case of traditional two-step \gls{ml} or the minimally preprocessed raw \gls{eeg} signal in case of one-step \gls{dl} approaches.
The dependent variable is the label of the \gls{mi} task that is being performed.
The prediction pipeline uses this trained model to predict the dependent variable based on only the independent variables.

A regression pipeline for processing brain signals would differ in this part, as it would not output the label of \gls{mi} task performed but a continuous value.
Classification and regression are types of supervised learning, the \gls{ml} paradigm assumed by the proposed pipeline.
The difference between regression and classification and why classification is more popular for \gls{bci} applications relying on \gls{mi} \gls{eeg} data is further discussed in Section \ref{subsec:processing_signals_ml_and_dl_tyes_of_learning_supervision}.

Many different classification models exist with the popular traditional \gls{ml} algorithm providing Python library \gls{sklearn} by \citet{sklearn} having over ten different \gls{ml} classifiers each with their own tunable parameters available.
For \gls{dl} classification models, Keras and Tensorflow \citep[Python \gls{dl} libraries by][]{keras, tensorflow} provide tens of layers that all can be combined to create an almost endless amount of unique classification models.
Countless combinations of both these traditional \gls{ml} and \gls{dl} approaches have been tried in \gls{eeg}-based \glspl{bci}.
As such, discussing all these different classification models falls outside the scope of this master thesis.
The interested reader is referred to both the original review paper on classification models for \gls{eeg}-based \glspl{bci} by \citet{eeg_based_bci_classification_models_old} and the updated version \citep{eeg_based_bci_classification_models}.

The traditional two-step \gls{ml} classifiers used in the experiments of this master thesis will be discussed in more detail in section \ref{subsec:processing_signals_ml_and_dl_ml_classifiers}.
In particular, \gls{lda}, \gls{svc} (based on \gls{svm}) and \glsfirst{rf} are discussed.
Likewise, section \ref{subsec:processing_signals_ml_and_dl_dl_classifiers} will discuss the most important concepts of \gls{dl} used for the \gls{dl} experiments in this master thesis.



% ---------------------------------------------- 
% ML AND DL TECHNIQUES
% ---------------------------------------------- 

\section{Machine learning and deep learning for classification}
\label{sec:processing_signals_ml_and_dl}

Machine learning is a broad field in computer science that focuses on algorithms aiming to relate specific data with a task at hand.
Many different \gls{ml} paradigms exist, with this master thesis focusing on supervised learning with classification in particular.
Throughout this master thesis, the terms \textit{traditional two-step \gls{ml}} and \textit{one-step \gls{dl}} were used quite often.
This section will explain how \gls{dl} is a subfield of \gls{ml} and the most important difference between \gls{dl} and \gls{ml} are given.
Three traditional \gls{ml} classifiers are discussed in more detail: \gls{lda}, \gls{svc} and \gls{rf}.
The most important concepts of \gls{dl} for this master thesis will also be discussed, including fully connected layers (as seen in \glspl{ann}), convolutional layers and pooling layers (as seen in \glspl{cnn}) along with various important concepts such as dropout, batch normalization and activation functions.
For even further insights, the interested reader is referred to the \gls{ml} book by \citet{ml_book} and \gls{dl} book by \citet{dl_book} which cover all \gls{ml} and \gls{dl} concepts needed for this master thesis and much more.
The practical book on both traditional two-step \gls{ml} model development using \gls{sklearn} and one-step \gls{dl} model development using Keras and Tensorflow by \citet{ml_dl_book} covers all practical aspects needed to understand the Python implementations of the experiments performed in this master thesis.

% - - - - - - - - - -
% Common regular ML classifiers
% - - - - - - - - - -

\subsection{Machine learning paradigms}
\label{subsec:processing_signals_ml_and_dl_tyes_of_learning_supervision}

% discuss; supervised -> classi en regres maar regres niet common bci mi eeg want te weinig info

% Supervised, Semi-Supervised, Unsupervised, and Self-Supervised Learning

% The most common form of ML is supervised learning, in which we assume that the data is presented as a set of input-output pairs, a dataset, which we call labeled data, as each input is labeled with its corresponding output.

% The most common form of ML is supervised learning, in which we assume that the data is presented as a set of input-output pairs, a dataset, which we call labeled data, as each input is labeled with its corresponding output (Caruana and NiculescuMizil 2006). Alternatively, unsupervised learning techniques do not use outputs for learning, but rather learn the (unknown) structure of the data. Semi-supervised learning methods use both labeled and unlabeled data, usually to learn the structure of the training data to become able to generate more (artificial) training points (Aznan et al 2019), that are used for conventional supervised learning in a second learning phase. Self-supervised learning (Jing and Tian 2019) is a similar approach that is used to learn the relevant structure in EEG data by first learning an unsupervised pretext task, after which the model is further trained on the target task with labeled data (Banville et al 2020, Kostas et al 2021). The remainder of this review will focus on supervised learning methods.

% Semi-supervised learning methods use both labeled and unlabeled data. Their objective is to learn a supervised learning task, even in cases where only a small amount of training data is available. Usually, semi-supervised approaches learn the structure of the training data to become able to generate more (artificial) training points (Aznan et al 2019), that are used for conventional supervised learning in a second learning phase. Self-supervised learning (Jing and Tian 2019) is a similar approach which is currently gaining traction in the larger ML community. This technique was previously used to learn the relevant structure in EEG data by first learning an unsupervised pretext task, after which the model is further trained on the target task with labeled data (Banville et al 2020, Kostaset al 2021). The remainder of this review will focus on supervised learning methods.

% Therefore, low-confidence labelled data is often used in a semi-supervised fashion as explained by \citet{deep_learn_low_label}.

In \gls{ml} four major categories of learning are distinguished: supervised, unsupervised, semi-supervised and reinforcement learning.
The following will briefly discuss the difference between these four major \gls{ml} paradigms.


% | | | | | | | | | | | | |

\subsubsection{Supervised learning}
\label{subsubsec:processing_signals_ml_and_dl_tyes_of_learning_supervision_supervised}

In supervised learning, the dataset used for learning consists of $N$ \textit{labeled samples}: $\{(\textbf{x}_i, y_i)\}^N_{i=1}$.
The feature vector $\textbf{x}_i$ contains the independent variable(s) and $y_i$ contains the label of a specific sample $i$.
The feature vector can contain all sorts of information in all sorts of data structures but the order of elements in the feature vector $\textbf{x}_i$ must be respected for all samples.
For examples, if the second feature of sample $i$ in the feature vector represents the age of a subject $i$ ($\textbf{x}_i^2 = \text{age of subject }i$), it should also represent age for any other subject $j$ ($\textbf{x}_j^2 = \text{age of subject }j$).
The label $y_i$ can also be any data type, although it most belongs to a finite set of classes (e.g. whether an email is considered spam or not expressed as a string or integer) or an infinite set of continuous values (e.g. a decimal denoting the risk of having a disease).

Within supervised learning, a further division can be made between classification and regression.
Classification consists of predicting the class of a sample ($y_i$ is a class) based on its feature vector ($\textbf{x}_i$).
Regression consists of predicting the real-valued label ($y_i$ is a continous value) based on its feature vector ($\textbf{x}_i$).
In both cases, the goal of supervised learning is to find a model that maps the feature vector $\textbf{x}_i$ to the corresponding label $y_i$ as good as possible.

Supervised learning is one of the most commonly studied \gls{ml} paradigms, especially for \gls{eeg}-based \gls{bci} where it is almost exclusively used for classification \citep{bci_review_arnau}.
In the proposed pipeline for \gls{mi} \gls{eeg} data classification from Section \ref{sec:processing_signals_general_pipeline}, the feature vector contains $\textbf{x}_i$ either the features extracted in the feature extraction phase when using two-step \gls{ml} or the minimally preprocessed \gls{eeg} signal when using one-step \gls{dl}.
One sample $i$ corresponds with the data of one window.
The classes possible for $y_i$ are the \gls{mi} tasks that the user is allowed to perform.



% | | | | | | | | | | | | |

\subsubsection{Unsupervised learning}
\label{subsubsec:processing_signals_ml_and_dl_tyes_of_learning_supervision_unsupervised}

In unsupervised learning the dataset only contains the feature vector of samples, it is a collection of unlabeled samples: $\{(\textbf{x}_i)\}^N_{i=1}$.
Multiple goals for unsupervised learning exist, with clustering being the most common.
In clustering, the model is asked to find groupings (clusters) in its data and return the group (cluster) a new sample belongs to.
In a clustering task, the model is expected to find patterns in the data which might reveal interesting outcomes.
Other common unsupervised learning tasks include dimensionality reduction and outlier detection amongst others \citep{ml_book}.
Unsupervised learning is most commonly used in the \gls{bci} field for calibrating an already trained model to a new subject or session without requiring explicit calibration from the user where the user is asked to perform a specific task.
This is a promising technique in the \gls{bci} as it uses the data already collected by a \gls{bci} to further improve itself.
\Citet{unsupervised_learning_bci} reviews and tests this technique in an \gls{erp}-based \gls{bci} setting.


% | | | | | | | | | | | | |

\subsubsection{Semi-supervised learning}
\label{subsubsec:processing_signals_ml_and_dl_tyes_of_learning_supervision_semisupervised}

The above-given example of using unsupervised learning to perform calibration without requiring specific actions from a \gls{bci} user shows that unlabeled data can enhance the quality of what is otherwise a supervised learning problem.
Semi-supervised learning builds on the same idea, both labelled and unlabeled samples are provided for learning what is otherwise a supervised learning goal.
This is especially handy in cases where a large amount of unlabeled data is available but only a small amount of labelled data is present.
Since this is the case for most applications of the \gls{bci} field, this type of learning has seen a growing interest in the field \citep{semi_supervised_bci1, semi_supervised_bci2, semi_supervised_bci3}.
These approaches deliver promising results compared to traditional supervised learning approaches with similar classification results but requiring fewer training samples and thus shorter calibration.
However, more research is needed to ensure the reliability of these methods in learning useful properties from the provided unlabeled data.


% | | | | | | | | | | | | |

\subsubsection{Reinforcement learning}
\label{subsubsec:processing_signals_ml_and_dl_tyes_of_learning_supervision_rl}

\Gls{rl} is a completely different approach to \gls{ml} as those described before.
In \gls{rl} an \textit{agent} ("an algorithm") lives in the real world or a simulation.
The world the agent lives in, albeit simulated or not, is called the environment and the agent can perceive this environment through a feature vector that is called a \textit{state}.
The agent can then perform \textit{actions} in the environment which may change the state.
After a sequence of actions, the agent receives a \textit{reward}, which is comparable to a label and can be dependent on multiple factors including the final state and the time it took to get there.
The goal of the agent is to learn a policy for choosing the best action for each possible state which yields the best reward.
Whilst \gls{rl} is an interesting approach that has yielded algorithms which outperform human experts in multiple games such as Go \citep{alphago}, its usability in the \gls{bci} field is limited as of now and as such this paradigm is not discussed further.


% - - - - - - - - - -
% Difference ML & DL
% - - - - - - - - - -

\subsection{Traditional two-step ML vs one-step DL classifiers}
\label{subsec:processing_signals_ml_and_dl_difference}

Throughout the discussion of the general brain signal classification pipeline in Section \ref{sec:processing_signals_general_pipeline}, it was discussed how \gls{dl} approaches differ from traditional \gls{ml} approaches by being able to learn directly from the raw, or minimally preprocessed, \gls{eeg} signal.
Since \gls{dl} is a subdivision of \gls{ml}, the difference between the two approaches is often emphasized by calling these \gls{ml} classifiers that require explicit feature extraction \textit{tradition two-step \gls{ml}} whilst \gls{dl} approaches who don't require this step are referred to as \textit{one-step \gls{dl}}.

As described by \citet{nn_can_learn_from_raw}, \gls{dl} models are universal function approximaters.
This is the foundational reason why \gls{dl} can learn any preprocessing or feature extraction step from labelled data, given sufficient layer, nodes and training as discussed in Section \ref{subsec:processing_signals_general_pipeline_preprocessing}.
Thus, \gls{dl} models learn some form of feature extraction during training.
As discussed in Section \ref{subsec:processing_signals_general_pipeline_classification} this makes it possible to gain additional knowledge of a problem by interpreting these features created by the \gls{dl} model.
Whilst this is a non-trivial task due to the black-box property of \gls{dl}, it has been achieved for multiple types of \gls{dl} models in multiple fields \citep{eeg_model_hbm, black_box_insight1, black_box_insight2}.
For some of the experiments in this master thesis, the \gls{cnn} based \gls{eeg} classification models DeepConvNet and ShallowConvNet by \citet{eeg_model_hbm} are used. 
For these models, a visualisation of their learned features exists, as further discussed in Section \ref{subsec:offline_bci_system_one_step_dl_interpreting}.

% - - - - - - - - - -
% Common traditional ML classifiers
% - - - - - - - - - -

\subsection{Common traditional two-step ML classifiers}
\label{subsec:processing_signals_ml_and_dl_ml_classifiers}

% To discuss: LDA, SVM and RF
% bekijk ml_strats_used_in_papers

% https://doi.org/10.1145/1143844.1143865 veergelijkt SVM en RF en andere

As discussed in Section \ref{subsec:processing_signals_general_pipeline_classification}, many different tradition two-step \gls{ml} classifiers exist.
The experiments in this master thesis make use of three such classifiers: \gls{lda}, \gls{svc} (based on \gls{svm}) and \gls{rf}.
This section will introduce these \gls{ml} techniques in what follows.
For more theoretical details, the interested reader is referred to the work by \citet{ml_book}.
For more practical implementation details, \citet{ml_dl_book} provides a discussion on how to use these models with \gls{sklearn}, the same Python library used for the experiments in this master thesis \citep{sklearn}.



% | | | | | | | | | | | | |

\subsubsection{Linear Discriminant Analysis (LDA)}
\label{subsubsec:processing_signals_ml_and_dl_ml_classifiers_lda}

As the name suggests, \gls{lda} uses linear decision boundaries to classify data points.
The most attractive feature of \gls{lda} is the fact that it has no hyperparameters to tune.
As discussed in Section \ref{subsec:processing_signals_evaluating_and_using_hyperparameter_tuning}, hyperparameter tuning is a time-consuming process that explodes in possibilities as more tunable components are added to the pipeline.
For this reason, \gls{lda} is often used when already hyperparameter tuning many parameters for the feature extraction components, as eliminating classifier finetuning can speed up to process significantly.
Adding to this, \gls{lda} is inherently multiclass, has an easy-to-compute closed form solution and has been shown to work well with \gls{csp}-based feature extraction \citep{csp_lda1, csp_lda2}.
These are the exact reasons \gls{lda} is used in this master thesis when using complex hyperparameter tuning setups for \gls{csp} and frequency filtering.
However, \gls{lda} assumes that the features from each feature vector $\textbf{x}_i$ have a normal (Gaussian) distribution and thus the data is a multivariate Gaussian.
It also assumes that each feature $\textbf{x}^j_i$ has a comparable variance around their mean on average.
These assumptions are not super strict and as discussed, it has been shown that \gls{lda} works well with \gls{csp}-based feature extraction \citep{csp_lda1, csp_lda2}.

\Gls{lda} was first proposed by \citet{lda_invention} as a dimensionality reduction technique.
It is inspired by \gls{pca} but makes use of both the feature vector $\textbf{x}_i$ and class labels $y_i$, where \gls{pca} only used the feature vector $\textbf{x}_i$.
The dimensionality reduction of \gls{lda} works by maximizing the ratio of the intra-class scatter, given in Equation \ref{eq:processing_signals_lda_intrascatter}, to the inter-class scatter, given in Equation \ref{eq:processing_signals_lda_interscatter} \citep{lda_classification}.
In these equations, $n$ denotes the number of classes, $c_i$ denotes the class $i$, $m_i$ denotes the number of training samples for class $i$, $\mathbf{\bar{x}_i}$ is the mean for class $i$, and $\mathbf{\bar{x}}$ is the total mean vector derived from Equation \ref{eq:processing_signals_lda_total_mean}.
From these values, the linear transformation $\Phi$ can be derived by solving the eigenvalue problem shown in Equation \ref{eq:processing_signals_lda_linear_transform}.
This linear transformation ($\Phi$) can then be used for predicting the class $c_{pred}$ of a new sample $\mathbf{x}_{new}$ in the transformed space by using any arbitrary distance measure $d$ in equation \ref{eq:processing_signals_lda_classificiation}.
\Citet{lda_classification} discusses \gls{lda} classification in further detail.

\begin{equation}
    \label{eq:processing_signals_lda_intrascatter}
    \hat{\Sigma}_w = S_1 + ... + S_n = \sum^n_{i = 1} \sum_{x \in c_i} (\mathbf{x} - \mathbf{\bar{x}_i}) (\mathbf{x} - \mathbf{\bar{x}_i})'
\end{equation}

\begin{equation}
    \label{eq:processing_signals_lda_interscatter}
    \hat{\Sigma}_b = \sum^n_{i = 1} m_i (\mathbf{\bar{x}_i} - \mathbf{\bar{x}}) (\mathbf{\bar{x}_i} - \mathbf{\bar{x}})'
\end{equation}

\begin{equation}
    \label{eq:processing_signals_lda_total_mean}
    \mathbf{\bar{x}} = \frac{1}{m} \sum^n_{i = 1} m_i \mathbf{\bar{x}_i}
\end{equation}

\begin{equation}
    \label{eq:processing_signals_lda_linear_transform}
    \hat{\Sigma}_b \Phi = \lambda \hat{\Sigma}_w \Phi
\end{equation}

\begin{equation}
    \label{eq:processing_signals_lda_classificiation}
    c_{pred} = \underset{j}{\arg\min} d(\mathbf{x}_{new} \Phi, \mathbf{\bar{x}}_j \Phi)
\end{equation}

% | | | | | | | | | | | | |

\subsubsection{Support vector machines (SVM)}
\label{subsubsec:processing_signals_ml_and_dl_ml_classifiers_svm}

\Gls{svm} are a popular supervised \gls{ml} algorithm for classification (\gls{svc}), regression, outlier detection and more \citep{svm_explained}.
The fundamental idea behind \gls{svm} was first introduced by \citet{first_svm} but has since seen some changes to become the algorithm it is known as today \citep{svm_history}.
The general ideas of using \gls{svm} as a classifier will be discussed here.
For a more detailed explanation or more information about the use of \gls{svm} for regression and other tasks, the reader is referred to the work by \citet{svm_explained}.

Just like \gls{lda}, \gls{svm} also uses linear decision boundries, however, it is not inherently multiclass like \gls{lda}.
multiclass classification using \gls{svm} can be established using a wide variety of methods, such as a one-vs-rest scheme or a one-vs-one scheme.
The \gls{sklearn} implementation of the \gls{svm} classifier, \gls{svc}, uses a one-vs-one scheme \citep{sklearn}.
This means that multiple \gls{svm} are made, one for each possible pair of classes, and the prediction of a new sample is made based on a (potentially weighted) majority vote.

There are three important concepts to address about \gls{svm} classifier: linear boundary optimisation, soft margins and the kernel trick.
When a problem is linearly separable there exists not one but many linear decision boundaries, as is shown in Figure \ref{fig:processing_signals_svm_boundary_multiple}.
Whilst intuitively one decision boundary shown in Figure \ref{fig:processing_signals_svm_boundary_multiple} might be better than another, they all separate the training data equally well and without making any assumptions, no \textit{best} decision boundary can be chosen.

\begin{figure}[t]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/pipeline/svm_multiple_boundaries.pdf}
        \captionsetup{width=\linewidth}
        \captionsetup{justification=centering}
        \caption{Multiple equally good linear decision boundaries for the train data. Free figure by Sylenius, CC BY-SA 3.0, via Wikimedia Commons.}
        \label{fig:processing_signals_svm_boundary_multiple}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/pipeline/svm_best_boundary.pdf}
        \captionsetup{width=\linewidth}
        \captionsetup{justification=centering}
        \caption{The decision boundary chosen by SVM is based on the maximized distance to the support vectors. Free figure by Sylenius, CC BY-SA 3.0, via Wikimedia Commons.}
        \label{fig:processing_signals_svm_boundary_best}
    \end{subfigure}
    \captionsetup{width=\linewidth}
    \captionsetup{justification=centering}
    \caption{A linearly separable problem with multiple possibilities for decision boundaries.}
    \label{fig:processing_signals_svm_boundary}
\end{figure}


\Gls{svm} assumes that the best decision boundary is the one which maximizes the distance from the \textit{support vectors} to the decision boundary.
These support vectors are the points closest to the decision boundary.
Figure \ref{fig:processing_signals_svm_boundary_best} shows the decision boundary chosen by \gls{svm} based on the maximized distance from the support vectors circled in blue to the decision boundaries shown in red.
In higher dimensionality, this decision boundary becomes a hyperplane which can be described by Equation \ref{eq:processing_signals_svm_decission_boundary} where $\mathbf{W}$ is the weight vector normal to the hyperplane and $b$ is the bias.
The distance from a point $\mathbf{p}$ to this decision boundary can be calculated using Equation \ref{eq:processing_signals_svm_point_distance}.
$||\mathbf{w}||$ denotes the euclidean norm of the weight vector $\mathbf{W}$.

Since we assume a linear separation is possible, we know that for the training samples $\mathbf{x}_i$ with binary class label $y_i$ that Equation \ref{eq:processing_signals_svm_rules} holds.
Since scaling $y_i (\mathbf{w}^T \cdot \mathbf{x}_i + b)$ won't change the position of the hyperplane, it is possible to state that for a certain set $\mathbf{W}$ and $b$ the minimal value is 1 since the result will always be different from zero due to the linear separability assumption and the possibility of scaling.
As such, the distance to the hyperplane at the support vectors can be simplified from $\frac{y_i (\mathbf{w}^T \cdot \mathbf{x}_i + b)}{||\mathbf{w}||}$ to $\frac{1}{||\mathbf{w}||}$.
Maximizing $\frac{1}{||\mathbf{w}||}$ corresponds to minimzining $||\mathbf{w}||$ which is computationally easier and what is done by the \gls{svm} algorithm in an iterative way.


\begin{equation}
    \label{eq:processing_signals_svm_decission_boundary}
    \mathbf{w} \cdot \mathbf{x} + b = 0
\end{equation}

\begin{equation}
    \label{eq:processing_signals_svm_point_distance}
    \text{Distance to point } \mathbf{p} = \frac{\mathbf{w}^T \cdot \mathbf{p} + b}{||\mathbf{w}||}
\end{equation}

\begin{equation}
    \label{eq:processing_signals_svm_rules}
    \mathbf{w}^T \cdot \mathbf{x}_i + b 
    \begin{cases}
          < 0 & \text{if $y_i$ = -1} \\
          > 0 & \text{if $y_i$ = 1}
    \end{cases}
    \Longleftrightarrow y_i (\mathbf{w}^T \cdot \mathbf{x}_i + b) > 0
\end{equation}

With the decision boundary in place, making predictions is trivial.
However, the calculations shown all assume a perfectly linearly separable problem, which is often not the case with real-world data and especially not with \gls{eeg} data.
When making this assumption, the \gls{svm} approach is reffered to as \textit{hard margin} \gls{svm} classification.
To allow for classifying in non-linearly separable problems, \textit{soft margin} \gls{svm} classification has to be used.
Soft margin \gls{svm} classification assumes the samples that stop the linear separation from being possible are noise and can be ignored.
Mathematically this is done by changing the minimum condition from $y_i (\mathbf{w}^T \cdot \mathbf{x}_i + b) = 1$ to $y_i (\mathbf{w}^T \cdot \mathbf{x}_i + b) = 1 - \xi_i$.
$\xi_i$ is called the slack variable and \citet{svm_explained} explains in greater detail how it can be controlled by the hyperparameter $C$, which makes a tradeoff between the maximizing the margin and the number of misclassification on the training data.

Whilst the slack variable allows non-linearly separable problems to be learned by \gls{svm}, it assumes that the classification errors it makes are noise in the data.
As such, it only works well for data that is \textit{almost} linearly separable.
However, \gls{svm} has a clever mechanism for reducing non-linear problems to (almost) linear problems.
By finding a higher dimensional representation of the data, \gls{svm} can reduce a non-linear problem to a linear one.
This is known as the \textit{kernel trick} and an intuitive example is shown in Figure \ref{fig:processing_signals_svm_kernel}.
The specific transformation done in this figure is from 2D to 3D with the kernel function shown in Equation \ref{eq:processing_signals_svm_kernel_function}.
In practice, much more complex kernels are often used, with the most common ones being the linear kernel, the polynomial kernel and the \gls{rbf} kernel.
From these, the \gls{rbf} kernel is the most notable as its feature space has an infinite number of dimensions \citep{ml_book}.
Equation \ref{eq:processing_signals_svm_rbf} shows the \gls{rbf} kernel function.
By tuning the hyperparameter $\sigma$, the smoothness of the decision boundary in the original space can be controlled.

\begin{equation}
    \label{eq:processing_signals_svm_kernel_function}
    \Phi ((x_1, x_2)) = (x_1, x_2, x_1^2 + x_2^2)
\end{equation}

\begin{equation}
    \label{eq:processing_signals_svm_rbf}
    \Phi ((\mathbf{x}, \mathbf{x}')) = \exp(- \frac{|| \mathbf{x} - \mathbf{x}' ||^2}{2 \sigma^2} )
\end{equation}

\begin{figure}[t]
    \centering
    \includegraphics[width=\linewidth]{../images/pipeline/svm_kernel_trick.pdf}
    \captionsetup{width=0.8\linewidth}
    \captionsetup{justification=centering}
    \caption{An intuitive example of SVM's kernel trick where a 2D non-linearly separable problem is transformed into a 3D problem where it is linearly separable. Free to use Figure by Shiyu Ji, CC BY-SA 4.0, via Wikimedia Commons.}
    \label{fig:processing_signals_svm_kernel}
\end{figure}

% | | | | | | | | | | | | |

\subsubsection{Random forest (RF)}
\label{subsubsec:processing_signals_ml_and_dl_ml_classifiers_rf}

% TODO: start here, with LDA being simple SVM capable byt many hyperparameters and poor explainibility due to high dimension, we opt for RF which ...
% Besrpreken dat je kan visualiseren

TODO 


% - - - - - - - - - -
% Common DL classifiers
% - - - - - - - - - -

\subsection{Common one-step DL classifier layers}
\label{subsec:processing_signals_ml_and_dl_dl_classifiers}

% Shallow vs deep learning uitleggen (!!!)
% Zie file:///Users/lennertbontinck/Library/CloudStorage/OneDrive-VrijeUniversiteitBrussel/SEM%202/Master%20thesis/books/ml_book.pdf


% These approaches have been chosen because of their relevance to this thesis. For a more detailed review of deep learning approaches for EEG classification, the reader is referred to the works of Roy et al. (2019) and Craik et al. (2019). wolf

% TODO: cnn bespreken a la: The most common type of DL neural networks at this time are the previously described CNNs (LeCun et al 1989). The subsequent application of convolutional layers results in a high-level representation of the input as stipulated by Goodfellow et al (2016). For example, in an object classification task, the network learns to extract primitive shapes from the raw input (a matrix of pixel values) in the first layer and then learns to extract objects from these primitive features in the next layer.
% en dus niet perse laatste layers voor classification maar vaak laatste layers terug mlps oid ipv puur convolutional layer

% In practice, neural networks can combine many layers of different kinds. It is not unusual to find neural networks that start with a few convolutional layers, to detect patterns independently of where they are in the input (such as edges in an image, or features in a 1D signal), then have one LSTM layer to be able to make sense of sequences of inputs, followed by a few feed-forward MLP-like layers to map what the LSTM layer learned to actual outputs. In the papers that we review in this article, great care is always given to explain and motivate the choice of neural architecture. Designing a neural network requires experience, as there is no systematic approach. We refer readers interested in knowing more than what we present here to books such as Goodfellow et al (2016) and Aggarwal (2018).


% The dominance of CNN with regard to model choice can be attributed to the relative ease of use and the popularity of this architecture in other research fields that use DL. While RNN architectures have been successful in closely related fields such as speech recognition and natural language processing, they have only seen limited deployment in a biosignal decoding context. Typically, CNNs also have less trainable parameters which makes them less sensitive to small datasets and lower their computational requirements. Other architectures were investigated for biosignal decoding, but state-of-the-art research mostly focuses on CNN architectures (Buongiorno et al 2019, Roy et al 2019).

% nog een pro CNN en waarom wij focussen op CNN: The choice of DL model is highly dependent on the application requirements and how the data is preprocessed. CNNs can often work with raw data that is only cleaned in the preprocessing step, while other models will typically necessitate feature extraction before passing the input to the ANN (Schirrmeister et al 2017). Alternatively, RNNs are also used for biosignal decoding, but these architectures typically need more technical knowledge to deploy and evaluate. The literature review clearly shows that CNN is the most deployed model and that biosignal decoding models are typically rather shallow, which can be attributed to the limited availability of data.


% Designing a neural network requires experience, as there is no systematic approach. More information on neural networks and their architectures is presented in the appendix, section ‘Neural networks’.



% bekijk ml_strats_used_in_papers

TODO
The most important concepts of \gls{dl} with respect to this master thesis will also be discussed, including fully connected layers (as seen in \glspl{ann}), convolutional layers and pooling layers (as seen in \glspl{cnn}) along with various important concepts such as dropout, batch normalization and activation functions.

% Besproken als zijnde hier gezegd
% convolutional layer
% depthwise conv 2D
% seperable conv
% 1D conv 
% dropout & 2D spatial dropout voor overfitting
% batch norm voor internal covariate shift
% lstm (with 1D conv kernel and regular and bidirectional)
% activation: elu

% ---------------------------------------------- 
% EVALUATING AND USING
% ---------------------------------------------- 
\section{Using and evaluating the classification pipeline}
\label{sec:processing_signals_evaluating_and_using}

% link back naar pipeline van cad

% duidelijk bespreken welk ding echt CS en welk ding eigenlijk derden

TODO

% - - - - - - - - - -
% trianing vs prediction
% - - - - - - - - - -

\subsection{Difference between training and prediction pipeline}
\label{subsec:processing_signals_evaluating_and_using_training_vs_prediction}

TODO

% - - - - - - - - - -
% offline vs online
% - - - - - - - - - -

\subsection{Difference between offline and online prediction}
\label{subsec:processing_signals_evaluating_and_using_offline_vs_online}

TODO

% - - - - - - - - - -
% calibration
% - - - - - - - - - -

\subsection{Calibrating a previously trained pipeline}
\label{subsec:processing_signals_evaluating_and_using_calibration}

TODO

% - - - - - - - - - -
% evaluting
% - - - - - - - - - -

\subsection{Evaluating the performance of the pipeline}
\label{subsec:processing_signals_evaluating_and_using_evaluation}

% CM
% acc
% loss
% f1
% ppv npv etc?
% CV 

% TODO: lees dit en dan CM - basic ML metrics - risk assessment - usability (e.g. train/pred time)

Section \ref{subsec:bci_opportunities_obstacles_lack_of_testing} discussed how a lack of standardized methods for both evaluation and reporting in \gls{bc} systems and \glspl{bci} in particular is one of many open issues.
As discussed, the main problem resides in evaluation strategies made for testing specific parts of the \gls{bci} system, such as the classification pipeline, not representing the final performance of the complete system.
However, due to the complexity of proposing a complete \gls{bci} system and performing an in-depth user study of that complete system, it is not feasible for every paper on \gls{bci} related research, including this master thesis, to do such extensive testing on a complete system.

For this reason, it was proposed in section \ref{subsec:bci_opportunities_obstacles_lack_of_testing} that the proposal of a complete \gls{bci} system should happen over at least four distinct papers, each focusing on a specific part.
As discussed, the contents of this master thesis relate most to the second of those four, where classification pipelines are compared and proposed.
As such, most of the evaluation metrics revolve around general \gls{ml} metrics derived from the \gls{cm} on either validation and/or test set.
However, as further discussed by \citet{ml_underspec}, it should be noted that these metrics don't include certain deployment factors and are most often an overestimation of real-world performance.
Besides these general \gls{ml} metrics, some metrics mostly used in testing the performance of medical \gls{ml} can be insightful for evaluating the risks associated with misclassification by the pipeline.
The remainder of this section discusses these topics in more detail.

% | | | | | | | | | | | | |

\subsubsection{The train, validation and test set split}
\label{subsubsec:processing_signals_evaluating_and_using_evaluation_valtest}

To test the performance of a classification pipeline, it is important that testing happens on data that was not used for training.
Intuitively, this has to be done as asking the classifier to classify a sample it has already seen the label for during training, is not going to give any indication of the real-world performance of the algorithm.
A simple 1-nearest neighbour algorithm would score perfectly in such a case and more complex algorithms would be incentivised to overfit to the data rather than learning the problem, an issue discussed in Section \ref{subsec:processing_signals_common_issues_overfitting}.

Most commonly, a complete dataset is split into three distinct sets: a training set, a validation set and a test set.
The difference between this validation and test set is their intended use.
For deciding the right parameters of a model, having some data that was not used for training, allows for testing which parameters are performing better.
The validation set is made for these kinds of assessments.
However, extensive use of the validation set will degrade the effectiveness of this set.
Given enough variations of a model, one is bound to perform well on this validation, even if it doesn't learn anything or it is a completely random one.
As such, another set, the test set, is needed for one \textit{final} performance assessment of the model.
It is important to stress that this test set should only be used once for this final assessment as further changes after obtaining an initial test score to improve this test score results in the test set becoming a validation set.
In medical research, a 7:1:2 ratio for training, validation and test split is relatively common \citep{attia}.
However, this is heavily dependent on the amount of data available and the problem at hand.

One issue with splitting the data into a train, validation and test set is that the obtained split is not representative of the data it is taken from or that it suffers from \textit{data leakage}.
Depending on the dataset, it can be a complex task to combat this.
First, samples should be sampled randomly such that each sample has an equal chance of being selected.
Second, the sampling should happen in a stratified manner such that the distribution of classes or other attributes present in the data is respected.
This will reduce the risk that a certain set contains an unreasonably high or low amount of samples from a certain class or attribute.
Take for example a test set for the \gls{mi} \gls{eeg} data where due to unfortunate random sampling the test set consists of only healthy subjects (attribute) and mostly samples from a certain \gls{mi} task (class) whilst the original dataset was balanced across all classes and had stroke patients included as well.
A stratified approach based on the class label and health status of the subject eliminates such a scenario from happening.
Third, no data leakage should happen, which requires taking into consideration certain groupings present in the data.
Data leakage occurs when the training data contains information that directly helps in classifying samples from the validation or test split that is not present for a true unseen sample.
For example, in a 3D medical lung imaging setting for classifying cancerous patients, having images or slices from the same patient in both the training and validation/test set is a common example of data leakage.
Even though the training set does not contain that specific slice or image, it contains closely related data that would not be present for a true unseen sample in real-world applications.
Grouped splits can solve this issue by ensuring all data of a subject is in the same group.
However, when data is limited, ensuring all three of these things can be challenging or even impossible.
Take for example data where all samples of a certain class are also from the same group, making it impossible to satisfy both the grouped or stratified conditions discussed.
Additionaly the data may contain bias, an issue further discussed in Section \ref{subsec:processing_signals_common_issues_bias}.


% | | | | | | | | | | | | |

\subsubsection{K-fold cross validation}
\label{subsubsec:processing_signals_evaluating_and_using_evaluation_kfold}


Rather than taking a fixed train and validation set, using k-fold \gls{cv} can provide better results.
The intuitive idea behind K-fold \gls{cv} is simple.
Rather than making a train/validation/test split, a train/test split is made using the same reasoning.
This training data is then further divided into K folds, with five to ten being relatively common depending on the number of training samples available. 
The classification pipeline is then trained K times on K-1 of these folds.
The fold that is not used for training, is used as a validation set and this set differs in each of the K training steps.
This results in K different scorings for the validation set and thus allows for determining variance as well.
It should be noted that the folds created have to use the same strategy as a fixed validation split to ensure each split is representative of the data without data leakage.
The algorithm behind K-fold \gls{cv} is given as pseudocode in Algorithm \ref{alg:processing_signals_kfold}.
One major drawback of using K-fold \gls{cv} is that it requires training the classification pipeline K times.
Considering some pipelines can take hours, days or even weeks to train, K-fold \gls{cv} is not always feasible.

\begin{algorithm}
    \caption{K-fold cross-validation}
    \label{alg:processing_signals_kfold}
    \begin{algorithmic}
        \State Divide training data in $K$ folds \Comment{Respecting a certain splitting strategy}
        \State $\text{val\_scores} \gets []$ \Comment{Initialize list of validation scores}
        \For{fold $k_i$ in $K$ folds}
            \State Train model on $K \setminus k_i$
            \State $\text{val\_scores} \gets \text{val\_scores} + $ metrics for validation set $k_i$ 
        \EndFor
        \State process $\text{val\_scores}$ as desired
    \end{algorithmic}
\end{algorithm}


% | | | | | | | | | | | | |

\subsubsection{The confusion matrix and its derived scores}
\label{subsubsec:processing_signals_evaluating_and_using_evaluation_cm} 

\begin{figure}[t]
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/pipeline/cm_binary.pdf}
        \captionsetup{width=\linewidth}
        \captionsetup{justification=centering}
        \caption{Confusion matrix for a universal binary classification problem.}
        \label{fig:processing_signals_cm_binary}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{../images/pipeline/cm_three_class.pdf}
        \captionsetup{width=\linewidth}
        \captionsetup{justification=centering}
        \caption{Confusion matrix for a three-class \gls{mi} classification problem.}
        \label{fig:processing_signals_cm_three}
    \end{subfigure}
    \captionsetup{width=\linewidth}
    \captionsetup{justification=centering}
    \caption{Design of a binary and three-class confusion matrix.}
    \label{fig:processing_signals_cm}
\end{figure}

The \gls{cm} is a simple but powerful tool for visualising the predictions made by a classification pipeline.
The structure of a \gls{cm} for both a universal binary classification problem and a three-class \gls{mi} classification problem is shown in Figure \ref{fig:processing_signals_cm}.
Many of the metrics used for evaluating the performance of a classification pipeline are derived from this \gls{cm}.
Take for example the most commonly used classification accuracy metric, it can be derived by equation \ref{eq:processing_signals_accuracy}.

\begin{equation}
    \begin{aligned} 
        \text{Binary accuracy} &= \frac{TP + TN}{TP + FN + FP + TN} \\\\
        \text{Three-class accuracy} &= \frac{\sum\limits_{x \in \text{classes}} T_x}{\sum\limits_{x \in \text{classes}} F_x}
    \end{aligned}
    \label{eq:processing_signals_accuracy}
\end{equation}

However, reporting on accuracy alone is often not enough as it is also interesting to know what the per-class performance is.
For this, sensitivity (also known as recall) and specificity are also commonly reported.
Their binary formulea are given in Equation \ref{eq:processing_signals_sensitivity} and \ref{eq:processing_signals_specificity} respectively.
Sensitivity gives information on the fraction of true samples being predicted as true whilst specificity provides the fraction of false samples being predicted as false.
For a \gls{cm} where more classes are present, the specificity and sensitivity per class can be calculated similarly.

\begin{equation} % recall
    \text{Binary sensitivity} = \frac{TP}{TP + FN}
    \label{eq:processing_signals_sensitivity}
\end{equation}

\begin{equation}
    \text{Binary specificity} = \frac{TN}{TN + FP}
    \label{eq:processing_signals_specificity}
\end{equation}

Whilst specificity and sensitivity already provide more information, these metrics don't report nicely on unbalanced datasets.
Assume a binary test setting where only 5\% of the samples are of the true class, something that is relatively common for medical conditions such as \gls{af}.
Papers studying the classification of this phenomenon, such as the one by \citet{attia}, will often boast a good specificity and sensitivity, i.e. \citet{attia} reported both to be above 80\%.
However, due to the class imbalance, these metrics are not sufficient on their own or in combination with the classification accuracy.
A mention of the \gls{ppv} and \gls{npv} is also needed.
The binary formulea for which are given in Equation \ref{eq:processing_signals_ppv} and \ref{eq:processing_signals_npv} respectively. 
The \gls{ppv} specifies how many of the samples labelled as true are actually true, the \gls{npv} does the same but for negatives.
Whilst not reported in the previously mentioned paper by \citet{attia}, the \gls{ppv} was found to be under 30\% \citep{ppv_attia}.
In contrast with the high sensitivity and specificity, this would mean that for less than one in three times the model predicted true, the sample was indeed true.
Relating this back to a \gls{bci} system, if the sensitivity and specificity of a risky action are good but the \gls{ppv} is not reported and turns out to be poor due to an imbalance in the testing strategy, the model can not be used in a real-world application as so many unwanted executions of risky actions are not acceptable.
The \gls{ppv} is also referred to as the precision of a model.
The \gls{ppv} and \gls{npv} can also be determined for each class independently in case of a multi-class classification problem.

\begin{equation} % Precision
    \text{PPV} = \frac{TP}{TP + FP}
    \label{eq:processing_signals_ppv}
\end{equation}

\begin{equation}
    \text{NPV} = \frac{TN}{TN + FN}
    \label{eq:processing_signals_npv}
\end{equation}

A final metric that is often reported is the F1 score.
The F1 score is also derived from the idea that sensitivity alone isn't enough for imbalanced data.
To solve this, it provides the harmonic mean of the \gls{ppv} and the sensitivity.
It's binary formula is given in Equation \ref{eq:processing_signals_f1}. 

\begin{equation}
    F1 = 2 * \frac{PPV * \text{sensitivity}}{PPV + \text{sensitivity}}
    \label{eq:processing_signals_f1}
\end{equation}

% | | | | | | | | | | | | |

\subsubsection{The ROC curve and choosing classification thresholds}
\label{subsubsec:processing_signals_evaluating_and_using_evaluation_risk} 

\begin{figure}[t]
    \centering
    \includegraphics[width=0.6\linewidth]{../images/pipeline/ROC.pdf}
    \captionsetup{width=0.7\linewidth}
    \captionsetup{justification=centering}
    \caption{ROC curve with some arbitrary examples. Free to use figure by cmglee, MartinThoma, CC BY-SA 4.0, via Wikimedia Commons.}
    \label{fig:processing_signals_roc_explained}
\end{figure}

Besides the \gls{cm}, the \gls{roc} is also a powerful tool for visualising the performance of a classification pipeline.
The idea behind the \gls{roc} curve is to visualize the model's performance when making a trade-off between sensitivity (also known as the true positive rate) and the false positive rate (1 - sensitivity).
This trade-off can be controlled by changing the threshold at which a prediction made by the model is considered a prediction of the true label.
By default, this is when the model returns a prediction of 0.5 or higher for the true class, but changing this value can yield more preferred behaviour.
For example, lowering the threshold will make the model classify samples as positive more often, resulting in an equal or higher sensitivity (desired) but also an equal or higher true negative rate (not desired).
Lowering the threshold value does the reverse.
Finding the best balance between both is application specific.
An example of this graph with some examples to demonstrate its working is shown in Figure \ref{fig:processing_signals_roc_explained}.
The \gls{roc} curve is often used to determine the optimal threshold value.
The \gls{auc} is also derived from the \gls{roc} curve as a common evaluation metric.


% - - - - - - - - - -
% evaluting
% - - - - - - - - - -

\subsection{Hyperparameter tuning}
\label{subsec:processing_signals_evaluating_and_using_hyperparameter_tuning}

TODO

% ---------------------------------------------- 
% COMMON ISSUES
% ---------------------------------------------- 

\section{Common issues with MI classification pipelines}
\label{sec:processing_signals_common_issues}

TODO

% - - - - - - - - - -
% biased data
% - - - - - - - - - -

\subsection{Biased data}
\label{subsec:processing_signals_common_issues_bias}

TODO

% - - - - - - - - - -
% evaluation
% - - - - - - - - - -

\subsection{Incorrect or ambiguous evaluation}
\label{subsec:processing_signals_common_issues_generalisation}
% e.g. only look at a person we also used in training etc

TODO

% - - - - - - - - - -
% explainability and interpretability
% - - - - - - - - - -

\subsection{No explainability or interpretability}
\label{subsec:processing_signals_common_issues_exaplainable}

TODO

% TOODO
\Gls{dl} often requires significant processing power and time to train, impacting the affordability of \gls{bci} research.
This is especially true when working with many \gls{eeg} sensors and features, and thus a high dimensional setting. 
\Gls{dl} is often also used in a black-box principle.
This means that the trained system lacks explainability and interpretability.
% TODO explain both terms
Recent governmental reports have suggested that laws will be coming in place to require these properties \citep{eu_ai_blackbox_report, explainable_ai_policy}.

% - - - - - - - - - -
% overfitting
% - - - - - - - - - -

\subsection{Overfitting}
\label{subsec:processing_signals_common_issues_overfitting}

% To avoid over-fitting, Batch Normalization (Ioffe and Szegedy 2015) considers the input of every layer in a neural network, and normalizes it so that, in expectation, the inputs of every layer has a zero mean and a unit variance. Dropout (Srivastava et al 2014) does not modify the values that flow through a neural network, but instead randomly disables neurons every time the network is evaluated during training. Both these methods contribute to improving training speed and generalization of the network, and ensure that the model converges to an optimal loss. Both batch normalization (Tayeb et al 2019, Tam et al 2020) and dropout (Gautam et al 2020, Tortora et al 2020a) are often used in biosignal decoding papers, sometimes both at the same time. Other normalization techniques are possible, such as L1- normalization or clipping the gradients (Zhang et al 2019a), but they have been superseded by Batch Normalization and Dropout.

% generalization bespreken: With neural networks, the main avenue to increase generalization is to decrease over-fitting. Over-fitting happens when a neural network remembers exactly what training input should learn which training output, without having actually made sense of the data. The network achieves a training loss close to 0, but produces garbage output on the testing set. It is like a small child that learns how to read words, and remembers that card number 7 is pronounced ‘cat’, without actually looking at the word written on the card, or being able to read at all. Batch normalization (Ioffe and Szegedy 2015) considers the input of every layer in a neural network, and normalizes it so that, in expectation, the inputs of every layer has a zero mean and a unit variance. Intuitively, this normalization prevents ludicrously large or small values from appearing inside the network, which makes it ‘behave better’ or ‘be smoother’ (so, easier to train, and better at generalization). The actual mathematical way in which batch normalization works is however still unknown, with recent papers providing the first insights (Santurkar et al 2018). Dropout (Srivastava et al 2014) does not modify the values that flow through a neural network, but instead randomly disables neurons every time the network is evaluated during training. The main motivation behind Dropout is to avoid one particular neuron in the network to learn how to compensate (and thus cancel out) another particular neuron in the network. When neurons are constantly randomly disabled and re-enabled, they all have to learn independently from each other. More mathematically, Dropout leads to a neural network that is made of a different set of neurons every time it is evaluated. This leads to a large ensemble of ‘sub-networks’, all trained on different datapoints. Ensembles of function approximators such as this are known to help with generalization (Dietterich 2000). Both batch normalization (Tayeb et al 2019, Tam et al 2020) and Dropout (Gautam et al 2020, Tortora et al 2020a) are often used in biosignal decoding papers, sometimes both at the same time. Other normalization techniques are possible, such as L1- normalization or clipping the gradients (Zhang et al 2019a), but they have been superseded by Batch Normalization and Dropout.

% uit bci_review_arnau

TODO

% ---------------------------------------------- 
% CONCLUSIONS OF CHAPTER
% ---------------------------------------------- 
\section{Motivation for offline classification and chapter conclusions}
\label{sec:processing_signals_summary}
% TODO: summary of this chapter

% duidelijk bespreken classificiation echt CS terwijl die contorl vaak een andere (buiten interface ofc) ook link naar die paper division door ons
% bespreken paper division door ons zegt dat on classi model bruikbaar moet zijn maar dit nog net iets anders want offline, dus is eigenlijk nog further subdivision

TODO